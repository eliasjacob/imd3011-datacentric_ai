{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Label Models\n",
    "## IMD3011 - Datacentric AI\n",
    "### [Dr. Elias Jacob de Menezes Neto](https://docente.ufrn.br/elias.jacob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keypoints\n",
    "\n",
    "- **Programmatic Weak Supervision (PWS):** This notebook explores advanced label models regarding PWS, where labeling functions (LFs) are used to generate noisy labels for training data.\n",
    "\n",
    "- **Label Aggregation Challenge:** Combining outputs from multiple LFs, which can be noisy and conflicting, is a central challenge in weak supervision. Label models are designed to address this challenge.\n",
    "\n",
    "- **Majority Label Voter:** A simple baseline label model that predicts labels based on the majority vote of LFs.\n",
    "\n",
    "- **Snorkel MeTaL Label Model:**  An advanced label model from the Snorkel library, used as a comparative baseline.\n",
    "\n",
    "- **Hyper Label Model (HyperLM):** A dataset-agnostic label model using Graph Neural Networks (GNNs) that can be applied to new datasets without retraining. It exists in unsupervised and semi-supervised versions.\n",
    "\n",
    "- **Dawid & Skene Model:** A probabilistic model that uses the Expectation-Maximization (EM) algorithm to estimate the reliability of each LF (acting as annotators) and infer true labels.\n",
    "\n",
    "- **Snorkel Generative Model:**  The predecessor to Snorkel MeTaL, it estimates LF accuracy and correlations to produce probabilistic labels.\n",
    "\n",
    "- **FlyingSquid Model:** A computationally efficient model that uses closed-form solutions based on triplet decomposition and a binary Ising model to aggregate labels.\n",
    "\n",
    "- **Crowdlab Model:** Integrates predictions from LFs with a classifier, estimates LF quality, and can be used to refine LF sets by removing noisy LFs. It leverages confident learning techniques.\n",
    "\n",
    "- **Importance of End Models:**  Label models are often paired with downstream \"end models\" (like SGDClassifier) for effective generalization to new, unseen data. Label models refine noisy labels, and end models learn to generalize from these refined labels.\n",
    "\n",
    "- **Noisy Labeling Functions Removal:** Crowdlab can be used to identify and remove less reliable or noisy LFs based on quality scores, improving overall label quality.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning goals\n",
    "\n",
    "By the end of this class, you will be able to:\n",
    "\n",
    "1. **Explain** the challenges of label aggregation in weak supervision scenarios, particularly when using multiple noisy and potentially conflicting labeling functions.\n",
    "\n",
    "2. **Describe** the fundamental principles, assumptions, and key components of various advanced label models, including Majority Label Voter, Snorkel MeTaL, HyperLM (Unsupervised and Semi-supervised), Dawid & Skene, Snorkel Generative Model, FlyingSquid, and Crowdlab.\n",
    "\n",
    "3. **Execute** and **apply** different label models using Python libraries such as Snorkel and HyperLM to aggregate outputs from a set of labeling functions for a given dataset.\n",
    "\n",
    "4. **Evaluate** and **compare** the performance of different label models in terms of label quality using appropriate metrics like Matthews Correlation Coefficient, and analyze their impact on downstream classification tasks.\n",
    "\n",
    "5. **Utilize** the Crowdlab framework to assess the quality and reliability of individual labeling functions within a weak supervision pipeline.\n",
    "\n",
    "6. **Design and apply** a strategy to refine a set of labeling functions by identifying and removing noisy or less effective LFs based on quality scores provided by Crowdlab.\n",
    "\n",
    "7. **Explain** the cooperative relationship between label models and downstream discriminative \"end models\" in achieving effective generalization in weakly supervised learning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our Dataset\n",
    "\n",
    "During [Notebook 03](Notebook_03.ipynb), we have created 113 labeling functions to label our sentiment classification dataset. We've used the `snorkel` library to create these labeling functions and we've also used the `LabelModel` to combine these labeling functions into a single model.\n",
    "\n",
    "In this notebook, we will use these LFs outputs to dive deeper into other label models. We'll also explore the concept of influence functions and how they can be used to improve our models.\n",
    "\n",
    "Let's load our dataset with the LF outputs and prepare it to be used in the next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.bool = np.bool_\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "import pandas as pd\n",
    "from snorkel.labeling.model import LabelModel, MajorityLabelVoter\n",
    "from snorkel.labeling.model.label_model import LabelModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", 200)\n",
    "pd.set_option(\"display.max_rows\", 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_parquet(\"data/b2w/train.parquet\")\n",
    "df_test = pd.read_parquet(\"data/b2w/test_cleaned_with_labels.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll use 10% of the test data as development data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_valid, df_test = train_test_split(\n",
    "    df_test, train_size=2718, random_state=271828, stratify=df_test[\"label\"]\n",
    ")\n",
    "\n",
    "df_train.reset_index(drop=True, inplace=True)\n",
    "df_valid.reset_index(drop=True, inplace=True)\n",
    "df_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((102326, 3), (2718, 4), (23340, 4))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_valid.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# You can try the list of LFs from Notebook 03. We'll use a smaller set for now.\n",
    "\n",
    "# List of regexes for positive sentiment\n",
    "positive_patterns = [\n",
    "    re.compile(r\"(?<!n[ãa]o\\s)(gostei|gostou|gostar)\", re.IGNORECASE),\n",
    "    re.compile(r\"(?:dentro do|no|antes do) prazo\", re.IGNORECASE),\n",
    "    re.compile(r\"(?<!n[ãa]o\\s)recomend\", re.IGNORECASE),\n",
    "    re.compile(r\"lind[oa]|bonit]oa]|cheiros[oa]|cheirinh|fresc\", re.IGNORECASE),\n",
    "    re.compile(r\"\\bbo[ma]\\b\", re.IGNORECASE),\n",
    "    re.compile(r\"[oó]timo|feliz|\\bbo[am]\\b|resistente|forte\", re.IGNORECASE),\n",
    "    re.compile(\n",
    "        r\"(?<!n[ãa]o\\s)(gostei|legal|atencios[oa]|maravilh|\\bamei\\b|\\bamou\\b)\",\n",
    "        re.IGNORECASE,\n",
    "    ),\n",
    "    re.compile(r\"\\bfeliz|satisf[ae]\"),\n",
    "    re.compile(r\"(?<!n[ãa]o\\s)(plenamente|completamente|inteiramente)\", re.IGNORECASE),\n",
    "    re.compile(r\"(?<!n[ãa]o\\s)(faltou|falta|faltando)\", re.IGNORECASE),\n",
    "    re.compile(r\"\\bcert[ao]\\b|\\bcertinh[oa]\\b\", re.IGNORECASE),\n",
    "    re.compile(r\"\\bshow\\b|\\btop\\b|\\barrasan|\\barrasa\\b\", re.IGNORECASE),\n",
    "]\n",
    "\n",
    "# List of regexes for negative sentiment\n",
    "negative_patterns = [\n",
    "    re.compile(r\"n[aã]o gost\", re.IGNORECASE),\n",
    "    re.compile(r\"(?:fora do|depois do) prazo|atraso|atrasado\", re.IGNORECASE),\n",
    "    re.compile(r\"usado|danificado|problema\", re.IGNORECASE),\n",
    "    re.compile(r\"n[ãa]o recomend\", re.IGNORECASE),\n",
    "    re.compile(r\"nunca mais\", re.IGNORECASE),\n",
    "    re.compile(r\"ruim|p[eé]ssim\", re.IGNORECASE),\n",
    "    re.compile(r\"n[aã]o funciona|\\bquebr[aeo]\", re.IGNORECASE),\n",
    "    re.compile(\n",
    "        r\"ruim|p[eé]ssim[ao]|pior|fr[aá]gil|frac[ao]|horr[ií]vel|horroroso|detest\",\n",
    "        re.IGNORECASE,\n",
    "    ),\n",
    "    re.compile(r\"n[aã]o gostei|ruim|descaso|\\bmal\\b\", re.IGNORECASE),\n",
    "    re.compile(r\"\\btriste|chatead|engan[oa]\", re.IGNORECASE),\n",
    "    re.compile(\n",
    "        r\"proco[nm]|reclam.{1,5}aqui|justi[cç]a|judici[aá]rio|pequenas causas|advogad\",\n",
    "        re.IGNORECASE,\n",
    "    ),\n",
    "    re.compile(\n",
    "        r\"(?:parou|deixou) de funcionar|quebrad[oa]|trincad[oa]|rachad[oa]|amassad[oa]|faltou|faltando|estrag|suj[oa]|\\bmancha\",\n",
    "        re.IGNORECASE,\n",
    "    ),\n",
    "    re.compile(r\"nunca mais|n[aã]o recebi\", re.IGNORECASE),\n",
    "    re.compile(r\"\\bn[ãa]o.{1,8}entreg\", re.IGNORECASE),\n",
    "    re.compile(r\"\\berrad[ao]\", re.IGNORECASE),\n",
    "    re.compile(r\"estorn|devolvi|devolu[cç][aã]o|cancel\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "POSITIVE = 1\n",
    "NEGATIVE = 0\n",
    "ABSTAIN = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LabelingFunction lf_regex_positive_a, Preprocessors: [],\n",
       " LabelingFunction lf_regex_positive_b, Preprocessors: [],\n",
       " LabelingFunction lf_regex_positive_c, Preprocessors: [],\n",
       " LabelingFunction lf_regex_positive_d, Preprocessors: [],\n",
       " LabelingFunction lf_regex_positive_e, Preprocessors: [],\n",
       " LabelingFunction lf_regex_positive_f, Preprocessors: [],\n",
       " LabelingFunction lf_regex_positive_g, Preprocessors: [],\n",
       " LabelingFunction lf_regex_positive_h, Preprocessors: [],\n",
       " LabelingFunction lf_regex_positive_i, Preprocessors: [],\n",
       " LabelingFunction lf_regex_positive_j, Preprocessors: [],\n",
       " LabelingFunction lf_regex_positive_k, Preprocessors: [],\n",
       " LabelingFunction lf_regex_positive_l, Preprocessors: [],\n",
       " LabelingFunction lf_regex_negative_a, Preprocessors: [],\n",
       " LabelingFunction lf_regex_negative_b, Preprocessors: [],\n",
       " LabelingFunction lf_regex_negative_c, Preprocessors: [],\n",
       " LabelingFunction lf_regex_negative_d, Preprocessors: [],\n",
       " LabelingFunction lf_regex_negative_e, Preprocessors: [],\n",
       " LabelingFunction lf_regex_negative_f, Preprocessors: [],\n",
       " LabelingFunction lf_regex_negative_g, Preprocessors: [],\n",
       " LabelingFunction lf_regex_negative_h, Preprocessors: [],\n",
       " LabelingFunction lf_regex_negative_i, Preprocessors: [],\n",
       " LabelingFunction lf_regex_negative_j, Preprocessors: [],\n",
       " LabelingFunction lf_regex_negative_k, Preprocessors: [],\n",
       " LabelingFunction lf_regex_negative_l, Preprocessors: [],\n",
       " LabelingFunction lf_regex_negative_m, Preprocessors: [],\n",
       " LabelingFunction lf_regex_negative_n, Preprocessors: [],\n",
       " LabelingFunction lf_regex_negative_o, Preprocessors: [],\n",
       " LabelingFunction lf_regex_negative_p, Preprocessors: []]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary functions from the helpers.lf module\n",
    "from helpers.lf import int_to_alphabetic_string, create_labeling_functions_from_regex\n",
    "\n",
    "# Initialize an empty list to store the regex patterns along with their corresponding labels and names\n",
    "regex_patterns = []\n",
    "\n",
    "# Iterate over the positive patterns and create tuples with pattern, name, positive label, and abstain label\n",
    "for i, pattern in enumerate(positive_patterns):\n",
    "    # Convert the index to an alphabetic string for naming the labeling function\n",
    "    name = f\"positive_{int_to_alphabetic_string(i + 1)}\"\n",
    "    # Append the tuple to the regex_patterns list\n",
    "    regex_patterns.append((pattern, name, POSITIVE, ABSTAIN))\n",
    "\n",
    "# Iterate over the negative patterns and create tuples with pattern, name, negative label, and abstain label\n",
    "for i, pattern in enumerate(negative_patterns):\n",
    "    # Convert the index to an alphabetic string for naming the labeling function\n",
    "    name = f\"negative_{int_to_alphabetic_string(i + 1)}\"\n",
    "    # Append the tuple to the regex_patterns list\n",
    "    regex_patterns.append((pattern, name, NEGATIVE, ABSTAIN))\n",
    "\n",
    "# Create labeling functions from the regex patterns using the helper function\n",
    "lfs = create_labeling_functions_from_regex(regex_patterns)\n",
    "\n",
    "# Display the list of labeling functions\n",
    "lfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/102326 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102326/102326 [00:59<00:00, 1708.19it/s]\n",
      "100%|██████████| 2718/2718 [00:01<00:00, 1680.29it/s]\n",
      "100%|██████████| 23340/23340 [00:15<00:00, 1542.39it/s]\n"
     ]
    }
   ],
   "source": [
    "from snorkel.labeling import LFAnalysis, PandasLFApplier\n",
    "\n",
    "applier = PandasLFApplier(lfs=lfs)\n",
    "L_train = applier.apply(df=df_train)\n",
    "L_valid = applier.apply(df=df_valid)\n",
    "L_test = applier.apply(df=df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8387995230928601"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LFAnalysis(L=L_train, lfs=lfs).label_coverage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "j",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Polarity",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Coverage",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Overlaps",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Conflicts",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "a0445795-38fa-4cc6-8a2d-ebe7a739372f",
       "rows": [
        [
         "lf_regex_positive_a",
         "0",
         "[1]",
         "0.13420831460234936",
         "0.1300646951898833",
         "0.012860856478314408"
        ],
        [
         "lf_regex_positive_b",
         "1",
         "[1]",
         "0.12590153040283017",
         "0.10265230733147",
         "0.009401325176397005"
        ],
        [
         "lf_regex_positive_c",
         "2",
         "[1]",
         "0.20308621464730373",
         "0.16520727869749624",
         "0.010916091706897562"
        ],
        [
         "lf_regex_positive_d",
         "3",
         "[1]",
         "0.044270273439790474",
         "0.03647166897953599",
         "0.0025604440709106192"
        ],
        [
         "lf_regex_positive_e",
         "4",
         "[1]",
         "0.2623380177081094",
         "0.2623380177081094",
         "0.028291929714832985"
        ],
        [
         "lf_regex_positive_f",
         "5",
         "[1]",
         "0.3991067763813693",
         "0.3541817328929109",
         "0.042237554482731664"
        ],
        [
         "lf_regex_positive_g",
         "6",
         "[1]",
         "0.18480151672106795",
         "0.169859077849227",
         "0.012401540175517464"
        ],
        [
         "lf_regex_positive_h",
         "7",
         "[1]",
         "0.06901471766706409",
         "0.05532318276879777",
         "0.011570861755565546"
        ],
        [
         "lf_regex_positive_i",
         "8",
         "[1]",
         "0.003469303989210953",
         "0.0028243066278365223",
         "0.0012313585989875496"
        ],
        [
         "lf_regex_positive_j",
         "9",
         "[1]",
         "0.021539002794988566",
         "0.01805015343119051",
         "0.01558743623321541"
        ],
        [
         "lf_regex_positive_k",
         "10",
         "[1]",
         "0.02416785567695405",
         "0.020376053007055882",
         "0.003694075796962649"
        ],
        [
         "lf_regex_positive_l",
         "11",
         "[1]",
         "0.016164024783534976",
         "0.012841311103727302",
         "0.0008893145437132302"
        ],
        [
         "lf_regex_negative_a",
         "12",
         "[0]",
         "0.022135136719895237",
         "0.021929910286730647",
         "0.006889744541954146"
        ],
        [
         "lf_regex_negative_b",
         "13",
         "[0]",
         "0.012069268807536697",
         "0.00966518773332291",
         "0.005169751578288998"
        ],
        [
         "lf_regex_negative_c",
         "14",
         "[0]",
         "0.04036119852236968",
         "0.03142896233606317",
         "0.021832183413795125"
        ],
        [
         "lf_regex_negative_d",
         "15",
         "[0]",
         "0.024783534976447825",
         "0.019975372828020248",
         "0.005638840568379493"
        ],
        [
         "lf_regex_negative_e",
         "16",
         "[0]",
         "0.004632253777143639",
         "0.004632253777143639",
         "0.001485448468619901"
        ],
        [
         "lf_regex_negative_f",
         "17",
         "[0]",
         "0.053622735179719716",
         "0.053603189805132616",
         "0.012802220354553095"
        ],
        [
         "lf_regex_negative_g",
         "18",
         "[0]",
         "0.024881261849383343",
         "0.01992650939155249",
         "0.007476105779567265"
        ],
        [
         "lf_regex_negative_h",
         "19",
         "[0]",
         "0.07466333092273714",
         "0.06790063131559916",
         "0.019613783398158825"
        ],
        [
         "lf_regex_negative_i",
         "20",
         "[0]",
         "0.0466254910775365",
         "0.045530950100658676",
         "0.013896761331430916"
        ],
        [
         "lf_regex_negative_j",
         "21",
         "[0]",
         "0.014316986885053652",
         "0.009753141918964876",
         "0.003957938353888552"
        ],
        [
         "lf_regex_negative_k",
         "22",
         "[0]",
         "0.004231573598108007",
         "0.0037136211715497526",
         "0.001026132165822958"
        ],
        [
         "lf_regex_negative_l",
         "23",
         "[0]",
         "0.029093290072904246",
         "0.025907394015206302",
         "0.015909934913902624"
        ],
        [
         "lf_regex_negative_m",
         "24",
         "[0]",
         "0.054336141352149016",
         "0.03193714207532787",
         "0.012811993041846647"
        ],
        [
         "lf_regex_negative_n",
         "25",
         "[0]",
         "0.01924242128100385",
         "0.01277290229267244",
         "0.00513066082911479"
        ],
        [
         "lf_regex_negative_o",
         "26",
         "[0]",
         "0.011512225631804233",
         "0.006762699607137971",
         "0.003049078435588218"
        ],
        [
         "lf_regex_negative_p",
         "27",
         "[0]",
         "0.027666477728045657",
         "0.020454234505404296",
         "0.0064499736137443075"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 28
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lf_regex_positive_a</th>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.134208</td>\n",
       "      <td>0.130065</td>\n",
       "      <td>0.012861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_regex_positive_b</th>\n",
       "      <td>1</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.125902</td>\n",
       "      <td>0.102652</td>\n",
       "      <td>0.009401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_regex_positive_c</th>\n",
       "      <td>2</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.203086</td>\n",
       "      <td>0.165207</td>\n",
       "      <td>0.010916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_regex_positive_d</th>\n",
       "      <td>3</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.044270</td>\n",
       "      <td>0.036472</td>\n",
       "      <td>0.002560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_regex_positive_e</th>\n",
       "      <td>4</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.262338</td>\n",
       "      <td>0.262338</td>\n",
       "      <td>0.028292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_regex_positive_f</th>\n",
       "      <td>5</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.399107</td>\n",
       "      <td>0.354182</td>\n",
       "      <td>0.042238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_regex_positive_g</th>\n",
       "      <td>6</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.184802</td>\n",
       "      <td>0.169859</td>\n",
       "      <td>0.012402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_regex_positive_h</th>\n",
       "      <td>7</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.069015</td>\n",
       "      <td>0.055323</td>\n",
       "      <td>0.011571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_regex_positive_i</th>\n",
       "      <td>8</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.003469</td>\n",
       "      <td>0.002824</td>\n",
       "      <td>0.001231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_regex_positive_j</th>\n",
       "      <td>9</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.021539</td>\n",
       "      <td>0.018050</td>\n",
       "      <td>0.015587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_regex_positive_k</th>\n",
       "      <td>10</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.024168</td>\n",
       "      <td>0.020376</td>\n",
       "      <td>0.003694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_regex_positive_l</th>\n",
       "      <td>11</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.016164</td>\n",
       "      <td>0.012841</td>\n",
       "      <td>0.000889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_regex_negative_a</th>\n",
       "      <td>12</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.022135</td>\n",
       "      <td>0.021930</td>\n",
       "      <td>0.006890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_regex_negative_b</th>\n",
       "      <td>13</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.012069</td>\n",
       "      <td>0.009665</td>\n",
       "      <td>0.005170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_regex_negative_c</th>\n",
       "      <td>14</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.040361</td>\n",
       "      <td>0.031429</td>\n",
       "      <td>0.021832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_regex_negative_d</th>\n",
       "      <td>15</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.024784</td>\n",
       "      <td>0.019975</td>\n",
       "      <td>0.005639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_regex_negative_e</th>\n",
       "      <td>16</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.004632</td>\n",
       "      <td>0.004632</td>\n",
       "      <td>0.001485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_regex_negative_f</th>\n",
       "      <td>17</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.053623</td>\n",
       "      <td>0.053603</td>\n",
       "      <td>0.012802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_regex_negative_g</th>\n",
       "      <td>18</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.024881</td>\n",
       "      <td>0.019927</td>\n",
       "      <td>0.007476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_regex_negative_h</th>\n",
       "      <td>19</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.074663</td>\n",
       "      <td>0.067901</td>\n",
       "      <td>0.019614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_regex_negative_i</th>\n",
       "      <td>20</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.046625</td>\n",
       "      <td>0.045531</td>\n",
       "      <td>0.013897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_regex_negative_j</th>\n",
       "      <td>21</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.014317</td>\n",
       "      <td>0.009753</td>\n",
       "      <td>0.003958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_regex_negative_k</th>\n",
       "      <td>22</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.004232</td>\n",
       "      <td>0.003714</td>\n",
       "      <td>0.001026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_regex_negative_l</th>\n",
       "      <td>23</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.029093</td>\n",
       "      <td>0.025907</td>\n",
       "      <td>0.015910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_regex_negative_m</th>\n",
       "      <td>24</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.054336</td>\n",
       "      <td>0.031937</td>\n",
       "      <td>0.012812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_regex_negative_n</th>\n",
       "      <td>25</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.019242</td>\n",
       "      <td>0.012773</td>\n",
       "      <td>0.005131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_regex_negative_o</th>\n",
       "      <td>26</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.011512</td>\n",
       "      <td>0.006763</td>\n",
       "      <td>0.003049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_regex_negative_p</th>\n",
       "      <td>27</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.027666</td>\n",
       "      <td>0.020454</td>\n",
       "      <td>0.006450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      j Polarity  Coverage  Overlaps  Conflicts\n",
       "lf_regex_positive_a   0      [1]  0.134208  0.130065   0.012861\n",
       "lf_regex_positive_b   1      [1]  0.125902  0.102652   0.009401\n",
       "lf_regex_positive_c   2      [1]  0.203086  0.165207   0.010916\n",
       "lf_regex_positive_d   3      [1]  0.044270  0.036472   0.002560\n",
       "lf_regex_positive_e   4      [1]  0.262338  0.262338   0.028292\n",
       "lf_regex_positive_f   5      [1]  0.399107  0.354182   0.042238\n",
       "lf_regex_positive_g   6      [1]  0.184802  0.169859   0.012402\n",
       "lf_regex_positive_h   7      [1]  0.069015  0.055323   0.011571\n",
       "lf_regex_positive_i   8      [1]  0.003469  0.002824   0.001231\n",
       "lf_regex_positive_j   9      [1]  0.021539  0.018050   0.015587\n",
       "lf_regex_positive_k  10      [1]  0.024168  0.020376   0.003694\n",
       "lf_regex_positive_l  11      [1]  0.016164  0.012841   0.000889\n",
       "lf_regex_negative_a  12      [0]  0.022135  0.021930   0.006890\n",
       "lf_regex_negative_b  13      [0]  0.012069  0.009665   0.005170\n",
       "lf_regex_negative_c  14      [0]  0.040361  0.031429   0.021832\n",
       "lf_regex_negative_d  15      [0]  0.024784  0.019975   0.005639\n",
       "lf_regex_negative_e  16      [0]  0.004632  0.004632   0.001485\n",
       "lf_regex_negative_f  17      [0]  0.053623  0.053603   0.012802\n",
       "lf_regex_negative_g  18      [0]  0.024881  0.019927   0.007476\n",
       "lf_regex_negative_h  19      [0]  0.074663  0.067901   0.019614\n",
       "lf_regex_negative_i  20      [0]  0.046625  0.045531   0.013897\n",
       "lf_regex_negative_j  21      [0]  0.014317  0.009753   0.003958\n",
       "lf_regex_negative_k  22      [0]  0.004232  0.003714   0.001026\n",
       "lf_regex_negative_l  23      [0]  0.029093  0.025907   0.015910\n",
       "lf_regex_negative_m  24      [0]  0.054336  0.031937   0.012812\n",
       "lf_regex_negative_n  25      [0]  0.019242  0.012773   0.005131\n",
       "lf_regex_negative_o  26      [0]  0.011512  0.006763   0.003049\n",
       "lf_regex_negative_p  27      [0]  0.027666  0.020454   0.006450"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LFAnalysis(L=L_train, lfs=lfs).lf_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer  # pip install tf-keras\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "\n",
    "# Define the path to the pre-trained SentenceTransformer model\n",
    "PATH_LM = \"data/bin/assin2_sentence-transformer\"\n",
    "PATH_CACHE = Path(\"outputs/advanced_ws/\")\n",
    "\n",
    "PATH_CACHE.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if not (PATH_CACHE / \"X_train.joblib\").exists():\n",
    "\n",
    "    # Load the SentenceTransformer model from the specified path\n",
    "    model_st = SentenceTransformer(PATH_LM)\n",
    "\n",
    "    # Encode the cleaned training text data using the SentenceTransformer model\n",
    "    # batch_size: number of samples to process at a time\n",
    "    # show_progress_bar: display a progress bar during encoding\n",
    "    # convert_to_tensor: return the encoded data as a NumPy array (False) instead of a PyTorch tensor\n",
    "    X_train = model_st.encode(\n",
    "        df_train.text.values,\n",
    "        batch_size=128,\n",
    "        show_progress_bar=True,\n",
    "        convert_to_tensor=False,\n",
    "    )\n",
    "    X_valid = model_st.encode(\n",
    "        df_valid.text.values,\n",
    "        batch_size=128,\n",
    "        show_progress_bar=True,\n",
    "        convert_to_tensor=False,\n",
    "    )\n",
    "    X_test = model_st.encode(\n",
    "        df_test.text.values,\n",
    "        batch_size=128,\n",
    "        show_progress_bar=True,\n",
    "        convert_to_tensor=False,\n",
    "    )\n",
    "\n",
    "    joblib.dump(X_train, PATH_CACHE / \"X_train.joblib\")\n",
    "    joblib.dump(X_valid, PATH_CACHE / \"X_valid.joblib\")\n",
    "    joblib.dump(X_test, PATH_CACHE / \"X_test.joblib\")\n",
    "\n",
    "else:\n",
    "    X_train = joblib.load(PATH_CACHE / \"X_train.joblib\")\n",
    "    X_valid = joblib.load(PATH_CACHE / \"X_valid.joblib\")\n",
    "    X_test = joblib.load(PATH_CACHE / \"X_test.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2718,), (23340,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid = df_valid.label.values\n",
    "y_test = df_test.label.values\n",
    "\n",
    "y_valid.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the columns of the LFs (Labeling Functions) that abstained on all rows of the training set\n",
    "# This creates a boolean mask where True indicates the LF abstained on all rows\n",
    "all_abstained_lfs = np.all(L_train == -1, axis=0)\n",
    "\n",
    "# Remove the abstained LFs from the list of LFs\n",
    "# This filters out LFs that abstained on all rows by using the boolean mask\n",
    "lfs = [lf for lf, abstained in zip(lfs, all_abstained_lfs) if not abstained]\n",
    "\n",
    "# Remove the abstained LFs from the training and validation label matrices\n",
    "# This keeps only the columns (LFs) that did not abstain on all rows\n",
    "L_train = L_train[:, ~all_abstained_lfs]\n",
    "L_valid = L_valid[:, ~all_abstained_lfs]\n",
    "\n",
    "# Get the rows where all LFs abstained in the training set\n",
    "# This creates a boolean mask where True indicates all LFs abstained for that row\n",
    "all_abstained_rows = np.all(L_train == -1, axis=1)\n",
    "\n",
    "# Remove the rows where all LFs abstained from the training set and feature matrix\n",
    "# This filters out rows where all LFs abstained by using the boolean mask\n",
    "L_train = L_train[~all_abstained_rows]\n",
    "X_train = X_train[~all_abstained_rows]\n",
    "\n",
    "# Update the training DataFrame to reflect the removed rows\n",
    "# This filters out rows in the DataFrame where all LFs abstained and resets the index\n",
    "df_train = df_train.iloc[~all_abstained_rows]\n",
    "df_train.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((85831, 768), (85831, 28), (85831, 3))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, L_train.shape, df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((23340, 768), (23340, 28), (23340, 4))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, L_test.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2718, 768), (2718, 28), (2718, 4))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid.shape, L_valid.shape, df_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "source",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "review_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "45b6a0f4-1144-4905-8043-1e9813c80497",
       "rows": [
        [
         "0",
         "b2w",
         "79d9a98a62d9adff5e2c8e2bed824e4d524695e0a1e2353a9bf995d8732dd7d3_18450635",
         "nao gostei do produto! - o acabamento e muito bom. mas a casa nao fica montada! encaixes frouxos! ja tentei colar com tudo! nao consegui! pelo preco esperava muito mais!"
        ],
        [
         "1",
         "b2w",
         "5177b7800f360f47ccd69afa43def2180777c1f6a3b26d6820808ac8b8a48903_32353831",
         "produto nao funciona - produto nao funcio, veio com problema na saida para instalar a camera de re e tem mais de uma semana que estou tentando trocar o produto e nao consigo, passam de uma empresa para outra e nao resolvem nada. nao recomendo nem comprar mais nesse site, pois nao oferece assistencia."
        ],
        [
         "2",
         "b2w",
         "fc0cc6d9c2e4539762936bcb5b0e855df6b5e08229b00d0d40e75a47dc77e103_28697857",
         "nao recebi, portanto nao conheco o produto - paguei esse produto em 16-02 e ainda nao recebi. parece que houve problema nos correios, mas a vendedora nao me passa noticias do produto."
        ],
        [
         "3",
         "b2w",
         "b3a8b907623ceece9aef15896c82a6ea3d932be9f8a856a581c8ecb89172ba05_132475745",
         "maravilhoso - parabens pela eficiencia na entrega,o produto tambem superou toda expectativa!"
        ],
        [
         "4",
         "b2w",
         "2a4088fd001bddc6b3b3cfc1eacd7df77f365a96c1d4571d6f8be1080ab92872_13958308",
         "produto bom. - demora na entrega. produto bom. * *."
        ],
        [
         "5",
         "b2w",
         "d0a5e8dac701fabfb99998a4662808baf675b19bb46515b6d2aec0057035e29d_9394433",
         "nao recebi o meu produto - comprei a mais de um mes e ate agora nada isto e uma falta de credibilidade com os clientes"
        ],
        [
         "6",
         "b2w",
         "c7b444d96fd106a040934fd1a32777d596f5bfdff927210e3d5e07d0138ad80f_132177650",
         "otimo custo beneficio - bom bonito barato moderno super moderno pode comprar nao vao se arrepender"
        ],
        [
         "7",
         "b2w",
         "b64a24b7feadd7d54a91a105fc234f709fece8f8251da8397ff57ab027f33e8e_20487438",
         "o produto e otimo - o produto e otimo, mas veio errado. comprei 2 cadeados e no site dizia que os mesmos eram com o mesmo segredo, porem os mesmos vieram com segredos diferentes."
        ],
        [
         "8",
         "b2w",
         "2320e5faf9924854a5d4193f2a937adbf26ed8b4fe78f34819d9e55286cb05fb_26480238",
         "o produto muito bom - a americana so deveria analisar mais seus parceiros. tive maior dor de cabeca com a entrega do produto. quase cancelei a compra. tirando isso foi tudo tranquilo."
        ],
        [
         "9",
         "b2w",
         "1a5ae226214b8dd57603833a8f95e6a87132d492e8143046e43b89c3e184d115_116208567",
         "qualidade excelente! - realmente um produto de qualidade excelente. recomendo e compraria mais vezes."
        ],
        [
         "10",
         "b2w",
         "c299fff7aad98dac04afa8655375213f13e01bd035d105516bed01bae338e12b_25238925",
         "muito bom! - comprei de presente para um casal de amigos, gostamos muito!"
        ],
        [
         "11",
         "b2w",
         "4a3524128b80cb0cf4007de34122e462d74bdef55de83283cf9181822ca5e106_127537251",
         "produto veio todo riscado - produto atrasou a entrega e veio todo riscado como se fosse usado como estavamos na vespera do natal e era presente nao deu tempo para pedir troca"
        ],
        [
         "12",
         "b2w",
         "261ce017e98f42a138339bed636e6c74bc2f2c585ad05a51eedc57dc303c5d32_14588595",
         "otima qualidade - chegou antes do prazo. produto de otima qualidade. super recomendo."
        ],
        [
         "13",
         "b2w",
         "1f68949319a7737a648af31efebeda2c6922f4f906ee816b7fca48998381e4d0_132444050",
         "otimo custo beneficio - pelo preco cobrado e um excelente produto. bonito, bom tamanho, boa velocidade de processador e internet, boa memoria, boa bateria, bom som, bom microfone, boa camera, so poderia ser melhor anoite. um celular muito bem equilibrado e acima da media."
        ],
        [
         "14",
         "b2w",
         "3cbb09c3ffc8675cead344bdb6d04eee8add69069e50b5acf32f97323f946831_17370700",
         "ainda nao recebi o produto! - a entrega esta muito atrasada e ainda nao recebi o produto"
        ],
        [
         "15",
         "b2w",
         "ef6075c5a596a9b41f73bd84b4e94604cb38305c9132651a8f1cae2827e79aaf_131526117",
         "nao recebi - nao recebi produto. depois de uma espera de 38 dias, pedi o cancelamento, pois ja tinha passado o passo de entrega. um descaso do consumidor, por colocar lojas parceiras que nao cumprem corretamente com o consumidor."
        ],
        [
         "16",
         "olist",
         "cada78cee5aa0ba52f79151eac8bf65d",
         "ainda estou aguardando a entrega do produto que solicitei, sendo que ja excedeu o prazo previsto para entrega. estou muito insatisfeito."
        ],
        [
         "17",
         "b2w",
         "3accf7d285c45d281b054a49acfb5fe2b79bb3d014f093a6cbb35295c2bd3526_132990587",
         "nota 1000 - jogo incrivel e a entrega rapida. recomendadissimo"
        ],
        [
         "18",
         "b2w",
         "6226bfdd73a73b8af094b8a26b225dbaebcc7ffefbc571538bf1370a51eee22a_20347314",
         "atraso entrega e falta de comprometimento - produto nao foi entregue dentro do prazo acordado. simplesmente falam para aceitar nova data de entrega ou cancelar pedido."
        ],
        [
         "19",
         "b2w",
         "fc05b91007275e72e7e87aad0173157c9fa3a8ec30ba56ef3744ce42141a2c46_132581759",
         "uso apenas de uma semana. - com apenas uma semana de uso, por pessoa adulta e responsavel. o aparelho nao ligou nem carregou mais. esta na assistencia tecnica para avaliacao. outro problema e que o produto chegou dois dias depois do previsto. do mais parece que e um otimo celular, apesar de nao estar encontrando pelicula e capa."
        ],
        [
         "20",
         "b2w",
         "8950f6f29b6bd2ff2f9e425d7ab5b5e6c7d8572d2483a8f526f979d79f439f19_14975314",
         "ruim - veio com a configuracao da operadora oi, o que nao foi dito na descricao do produto"
        ],
        [
         "21",
         "olist",
         "8938594f445ce5e289c7771c03ce892f",
         "ainda estou aguardando minha mercadoria que ja esta fora do prazo,sou cliente stark a anos e basta ver meu historico de compras para ver se sou bom cliente."
        ],
        [
         "22",
         "olist",
         "1d094358bf83e20f50d9ca6a25d28088",
         "super recomendo chegou tudo certinho muito bem embalado"
        ],
        [
         "23",
         "b2w",
         "3d5b7a8cad3075ae681a668f3b7544f16a9cbd7d74255b1faa4da8663a04d030_8369558",
         "excelente - amei o aparador. gostei muito da cor da madeira e do pe retro. e nao foi dificil de montar. meu marido e eu que montamos. ficou lindo na minha sala!"
        ],
        [
         "24",
         "b2w",
         "64f667200eec37b0b21ae8ed14cbc5508753da7a47162214255d3d10b1568d82_26977450",
         "gostei muito - gostei muito, o cabelo e lindo, conforme a foto, somente um ponto negativo nao veio limpo."
        ],
        [
         "25",
         "b2w",
         "de1021356940f10a91f65d8086b53c73ba5f94a449ee978f6c37408b2bbf8e32_132124646",
         "gostei muito do produto! - estou muito satisfeita com a minha tv. chegou muito antes do prazo prometido."
        ],
        [
         "26",
         "b2w",
         "5069b53c687e3ae7e04a504dda1f83cb93b865694cf0d5a2df347c987ab20ad8_11089794",
         "amei ! - excecao produto e excelente oasis da beleza q forneceu o mesmo"
        ],
        [
         "27",
         "b2w",
         "db342477666eb2c4a0081307558cf6900275fa4d8d3c77cf5c1837e6e43756ca_123068591",
         "sensacional - maravilhaaaa foi presente e quem ganhou amou e chegou bem antes da data prevista estou satisfeita com a venda"
        ],
        [
         "28",
         "b2w",
         "8acea307d9f5977ee4501d51a2eaab638eaa2435051feae10347acdff6a8c169_132481707",
         "gostei muito do livro - td ok o livro me surpreendeu,as americanas como sempre maravilhosa chegou antes da data.obg"
        ],
        [
         "29",
         "b2w",
         "a2f2c7d84d0dee39e349d32a7441cc6163d637ef09aa939f21cfee6796d20aaa_132222369",
         "nao recebi o produto - palhacada vou guardar todos esses e-mails, para processar a americanas pela enganacao, avaliar um produto sequer eu recebi, falta de respeito com cliente, ate hoje espero uma posicao do meu produto, alias ja estou pagando a fatura sem ter o produto, bando de irresponsavel que fazem tudo ao contrario que prometem, vou no procon e processar americanas por danos, era presente de aniversario!"
        ],
        [
         "30",
         "b2w",
         "ee3c6a898fe6f76922a6dd84ed906b5046faec020db472535437846d1e7b5ed7_132444092",
         "um sim veio sem funcionar - recebe dois celular mas um dos chip nao funciona , ja tentei falar com alguem mas sem sucesso"
        ],
        [
         "31",
         "b2w",
         "af2d385f406b259910c11cb82f55489258a86b5a7ea403d668d10d3a1fac30b0_28392201",
         "radio relogio - otimo produto . facil manuseio . recomendo a compra ."
        ],
        [
         "32",
         "b2w",
         "337d50709a0ddf1864f2c38bacea78b3464e0c10b2b5e4c5db6aec5ebb3810c3_132569266",
         "maravilhoso! - belo, compacto, potente, confiavel e atualizado com o oreon 8.0 recomendo."
        ],
        [
         "33",
         "b2w",
         "b3df7b34b0673aeb08563bfdeb6af326c9cdba360bbb1e8a698027c395632f1c_9251839",
         "veio incompleta. - comprei essa piscina de bolinha que dizia vim com 1500 bolinha paguei 1.109,00, e so recebi a piscina, entrei em contato, me mandaram enviar fotos, mandei muitas e nada, ja fazem quase 5 meses e nada de resolver, e bom ter mais respeito e compromisso com os compradores, pois paguei e quero as bolinhas."
        ],
        [
         "34",
         "b2w",
         "dcacf13b5817c630eaf5cb4750b4a6223fb4f94f550e3057a408a53af47b393b_7168148",
         "pessima embalagem na entrega - a caixa chegou com duas garrafas quebradas! estou tentando reenvio de uma nova caixa, mas ainda nao obtive o retorno"
        ],
        [
         "35",
         "b2w",
         "12f014ae657dbc57bc5a37fd8c648d1e1461893c8ee10b48b64cdc0f00c7a6a5_14844096",
         "10 - produto muito bom e pratico, alem do que serviu aos meus propositos."
        ],
        [
         "36",
         "b2w",
         "f492cbd70b4169cda2c4ebb158754bbbd5d7418ab818a4da3fce6e06d6ecf540_132215960",
         "ainda nao recebi o produto - paguei o frete rapido e ate agora nao recebi o produto e nem atualizacao de onde esta. ja passou da data de entrega e nada"
        ],
        [
         "37",
         "b2w",
         "4110c1a555eaacb1395bffdd68a5d55b5f10288e8c2013cb1ef27895c4bbd2e5_127370658",
         "excelente - muito bom. nada gruda nessas panelas. excelente para qualquer tipo de alimento."
        ],
        [
         "38",
         "b2w",
         "8465edb139c1c1c363b2ff4c6e78c5f84c329a98aaec761bbefc636dba297f3a_120243525",
         "impressora - produto conforme anuncio do vendedor, entregue no prazo,"
        ],
        [
         "39",
         "b2w",
         "2d43f25b145cab3ed73c7474fb5efa3b667d251951dc00185c5696ffb23c8d73_20572258",
         "uma porcaria - a entrega do meu produto esta atrasada ha quase duas semanas, ninguem me da noticias do produto, pior compra da minha vida"
        ],
        [
         "40",
         "b2w",
         "23c4f88bcc408091d5af723fea263ee39cd3ea06d8c8210ea5d9d18ab9819a09_27550282",
         "muito bom! - produto muito bom. recomendo! x"
        ],
        [
         "41",
         "b2w",
         "9d82ee071f34fe17f10d9bee25ce36ef6a698c8d46e3399d61bac4f7813c8bde_32121048",
         "recomendo - produto de qualidade, estou muito satisfeita. super recomendo!"
        ],
        [
         "42",
         "b2w",
         "a2bad920e748765a28174259db91f4db73d1a69ff436a03dc7eab4269a4598a6_9159468",
         "pessima - decepcionado com a empresa, pois me venderam um produto bridgestone e me mandaram outro de menor qualidade, e ainda com prazo de validade vencida. passaram-me gato por lebre."
        ],
        [
         "43",
         "olist",
         "1665c5e07e2717f9d64744a7813faaa0",
         "muito bom - entrega rapida, produto bonito conforme descrito no site, porem so chegou o lencol ainda nao chegou a saia da cama."
        ],
        [
         "44",
         "olist",
         "90febfe6ab599694729eaba46be1d3ad",
         "ja e a segunda vez que compro nesta loja,super eficiente entrega rapida e antes do prazo contratado, produto bem embalado , nota 10 muito obrigado"
        ],
        [
         "45",
         "b2w",
         "6ae3fe21b60a0f89fdf32934fff39c00e26c0ca2e089a1e9df1ba356f7558f6f_17555460",
         "show - produto muito bom para quem que um som de qualidade mas nao e um som para quem quer tremer tudo"
        ],
        [
         "46",
         "olist",
         "f61ba72fb5f76ecd3eb330310c97f290",
         "muito bom recebi tudo direitinho e dentro do prazo."
        ],
        [
         "47",
         "b2w",
         "e5a004d78cede20eabde36dbf70b34da58babc0a49f8561c7f8e20186e79ffa5_27898163",
         "nao gostei - o carrinho nao funcionou preciso devolver acho que nem testaram."
        ],
        [
         "48",
         "b2w",
         "120b91481322e9d98e220e6a9b5c342b5b2857bdc65278f1be70eab5ef5b84a3_25149342",
         "muito bom - achei interessante , tenho que pegar a receita na net"
        ],
        [
         "49",
         "olist",
         "650f27998c7eb14a72302066cf6f8185",
         "ja faz um bom tempo que compro na americana e nunca aconteceu de atrasar nada mas esse produto foi demais ate agora nao recebi meu produto."
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 85831
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>review_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b2w</td>\n",
       "      <td>79d9a98a62d9adff5e2c8e2bed824e4d524695e0a1e235...</td>\n",
       "      <td>nao gostei do produto! - o acabamento e muito ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b2w</td>\n",
       "      <td>5177b7800f360f47ccd69afa43def2180777c1f6a3b26d...</td>\n",
       "      <td>produto nao funciona - produto nao funcio, vei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b2w</td>\n",
       "      <td>fc0cc6d9c2e4539762936bcb5b0e855df6b5e08229b00d...</td>\n",
       "      <td>nao recebi, portanto nao conheco o produto - p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b2w</td>\n",
       "      <td>b3a8b907623ceece9aef15896c82a6ea3d932be9f8a856...</td>\n",
       "      <td>maravilhoso - parabens pela eficiencia na entr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b2w</td>\n",
       "      <td>2a4088fd001bddc6b3b3cfc1eacd7df77f365a96c1d457...</td>\n",
       "      <td>produto bom. - demora na entrega. produto bom....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85826</th>\n",
       "      <td>b2w</td>\n",
       "      <td>60edcbe9ac5d63cad10f859cd7434940a9cb9968d69f56...</td>\n",
       "      <td>frete - eu sempre compro na internet, porem o ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85827</th>\n",
       "      <td>b2w</td>\n",
       "      <td>8d1a158926a1d0ced1f34e5cca097582628f9ca32705c4...</td>\n",
       "      <td>amei o produto - meu filho ficou encantado, le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85828</th>\n",
       "      <td>olist</td>\n",
       "      <td>64408d18914abe811a12225c1da97beb</td>\n",
       "      <td>chegou antes do prazo, produto de acordo com o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85829</th>\n",
       "      <td>b2w</td>\n",
       "      <td>a24a9e978f550958d912ecc6598d3df5092f8bd0c6d21d...</td>\n",
       "      <td>elogio - estou muito satisfeita com minha comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85830</th>\n",
       "      <td>b2w</td>\n",
       "      <td>ab33f05a6519100d7f74d973db63f07140caa4d519f8f8...</td>\n",
       "      <td>copo goose island - produto bom, otimo acabame...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85831 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      source                                          review_id  \\\n",
       "0        b2w  79d9a98a62d9adff5e2c8e2bed824e4d524695e0a1e235...   \n",
       "1        b2w  5177b7800f360f47ccd69afa43def2180777c1f6a3b26d...   \n",
       "2        b2w  fc0cc6d9c2e4539762936bcb5b0e855df6b5e08229b00d...   \n",
       "3        b2w  b3a8b907623ceece9aef15896c82a6ea3d932be9f8a856...   \n",
       "4        b2w  2a4088fd001bddc6b3b3cfc1eacd7df77f365a96c1d457...   \n",
       "...      ...                                                ...   \n",
       "85826    b2w  60edcbe9ac5d63cad10f859cd7434940a9cb9968d69f56...   \n",
       "85827    b2w  8d1a158926a1d0ced1f34e5cca097582628f9ca32705c4...   \n",
       "85828  olist                   64408d18914abe811a12225c1da97beb   \n",
       "85829    b2w  a24a9e978f550958d912ecc6598d3df5092f8bd0c6d21d...   \n",
       "85830    b2w  ab33f05a6519100d7f74d973db63f07140caa4d519f8f8...   \n",
       "\n",
       "                                                    text  \n",
       "0      nao gostei do produto! - o acabamento e muito ...  \n",
       "1      produto nao funciona - produto nao funcio, vei...  \n",
       "2      nao recebi, portanto nao conheco o produto - p...  \n",
       "3      maravilhoso - parabens pela eficiencia na entr...  \n",
       "4      produto bom. - demora na entrega. produto bom....  \n",
       "...                                                  ...  \n",
       "85826  frete - eu sempre compro na internet, porem o ...  \n",
       "85827  amei o produto - meu filho ficou encantado, le...  \n",
       "85828  chegou antes do prazo, produto de acordo com o...  \n",
       "85829  elogio - estou muito satisfeita com minha comp...  \n",
       "85830  copo goose island - produto bom, otimo acabame...  \n",
       "\n",
       "[85831 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "label",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "source",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "review_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "62428043-6b21-4f5d-a7e4-66cc6324080c",
       "rows": [
        [
         "0",
         "0",
         "b2w",
         "52059e633d1d3d99db67fe9b0dd9ab02313a60c27e47c021a3a50591fc2fba1e_18596056",
         "Fraca - Produto nao aquece o suficiente. Nao atendeu minhas expectativa"
        ],
        [
         "1",
         "1",
         "b2w",
         "99e4bad489afcc355d58f315c7bff6dba6b0547e073447dda65c998830f81671_25337749",
         "Ótima qualidade! - Rodapés prontos para instalação, brancos e lindos. Deixa o ambiente com um acabamento clean e moderno, além disso com um dos melhores valores do mercado."
        ],
        [
         "2",
         "0",
         "b2w",
         "1994c6c30f08b31a3f5024868381595e9f157c3b901638c487d29091601afdf1_7521200",
         "Não foi entregue - Faz mais de um mês que comprei, ja passou o prazo de entrega e nada da geladeira chegar. Fica tanto tempo numa casa sem geladeira é miiyo difícil, isso é um absurdo."
        ],
        [
         "3",
         "1",
         "b2w",
         "326e7e6098b15d792fbf99c4649f0ea6ddca50b0861bdad2f60f78867e1a1f1c_15085392",
         "excelente compra - fiquei muito satisfeito com essa panela que comprei. o produto tem todas as qualidades prometidas pela empresa que o representa."
        ],
        [
         "4",
         "1",
         "b2w",
         "c78621b567856fa2b86f43858c4bfeedb442036b5ac3206ad90c4aaf7da7cb9e_132631701",
         "Praticidade na limpeza da casa! - Amei o produto, exatamente como descrito , o tamanho e menor , mas não atrapalha em nada, muito prático para limpeza da casa , banheiros , cozinha e ... muito bom!"
        ],
        [
         "5",
         "1",
         "b2w",
         "88d103140e9cd6cd53ba0932f582527f2151e992024546fe74d897f5252ea0ac_13001577",
         "Otimo - Muito bom. Tanto a caneta touch, quanto a capa e também a película. Produtos excelentes."
        ],
        [
         "6",
         "1",
         "b2w",
         "cc6a72535dd551c62472c4f9a90871f00383d44820fe9ac6e70eaa50e836e469_132444050",
         "gostei do produto - muito bom o aparelho .era meu sonho e consegui e graças a oportunidadesque vcs me deram obrigado."
        ],
        [
         "7",
         "1",
         "b2w",
         "d0209a233485ed9019d714f16bfb16f212d6d3e54b610f9820077f0b7def0293_22471006",
         "Excelente Produto :) - Atende todas as expectativas , mesmo sendo um smartphone \" basico \" ( de entrada ) ele supre a demanda dentro de suas capacidades , sendo que realmente achei bem mais rapido do que imaginava que seria"
        ],
        [
         "8",
         "0",
         "olist",
         "633538990df4c5fb118483feb8557347",
         "Atraso na entrega - O pedido do produto foi realizado no dia 11/07 com previsão de entrega para o dia 21. A nota fiscal só foi emitida no dia 22; já estamos no dia 24 e o produto sequer saiu para entrega."
        ],
        [
         "9",
         "1",
         "b2w",
         "0f7555170b0f410c122f6ed7c1bfde69faa9a54768161931f8b987c42c44f093_132460201",
         "Muito bom - Smart tv fácil de operar, simples e com ótima imagem, estou bem satisfeito"
        ],
        [
         "10",
         "1",
         "b2w",
         "d6fabf2e2a405600581e3fac9a543652321599ab69f792a849cf4d6ae426f4b4_28336485",
         "Lindo e de qualidade! - A compra chegou muito antes do prazo. O produto além de ser lindo demais é de qualidade!"
        ],
        [
         "11",
         "1",
         "b2w",
         "03cbe4f088a2117807e5a5ec858be295ef7b68350813d52a9226be973b6a75e8_120280369",
         "Aprovação - Brinquedo normal, sem problemas. Recomendo. Entregue no prazo. Preço acessível."
        ],
        [
         "12",
         "1",
         "b2w",
         "986ba68dd237e0c4b019d979fe0baabf93dda8ee57dbd46f2e3a1e574e70b50b_132651745",
         "Recomendo este produto . - A entrega demorou um pouco depende da região, satisfeita com o produto."
        ],
        [
         "13",
         "0",
         "olist",
         "54b8a270796ea170b5d7af617c61859c",
         "O Pedido e pagamento foram efetuados dia 06/10/2016,com entrega em 26 dias,dia 09/11/2016(33 dias após a compra)recebo um Email cancelando por falta no estoque,Um absurdo vender e não ter para entrega"
        ],
        [
         "14",
         "1",
         "b2w",
         "a46b0fff399ab9ec5cc26e9f38396e42032b27a838cb7d6cabd1eb1b082867dd_16818581",
         "Meu filho amou e eu também. - O livro é lindo e desperta bastante o interesse da criança para a leitura.  Recomendo!"
        ],
        [
         "15",
         "1",
         "b2w",
         "650ec67cb61469bc05efe4ee0d1d9ef3f7692bf12b84cae2c305f1122314b379_129591796",
         "Ótimo - Ótimo produto, recomendo a todos e a entrega muita rápida."
        ],
        [
         "16",
         "1",
         "b2w",
         "f26a61bba8e66c97a19a3898bc84e3757320429c5b689056e43b369e1c5ea844_25647461",
         "otimo - adorei, chegou antes do prazo, super recomendo ficou excelente no meu relogio"
        ],
        [
         "17",
         "1",
         "olist",
         "8ce966c8cb7341295ef138ca761fb81d",
         "Excelente , recebi o tel. antes do prazo citado em perfeita ordem , estou muito satisfeito e futuramente irei entrar em contato para solicitar uma bateria suplementar para o tel. obrigado abraço."
        ],
        [
         "18",
         "1",
         "b2w",
         "195a8b968df8cc734de15d673359e834da84e350f8ea01291dcf2d9a93374e7e_132276480",
         "gostei muito do produto - o produto é muito bom, facil de manusear, atende aos meus objetivos claramente"
        ],
        [
         "19",
         "1",
         "olist",
         "147b44e1cc71565624b4439832f41b21",
         "Entregue bem antes do prazo, produto otimo, recomendo como sempre pois sou cliente a muito tempo!"
        ],
        [
         "20",
         "0",
         "olist",
         "d029c26ca5c0758b8cbf1e71a38173bc",
         "Muito fraca - Acho muito fraca está loja."
        ],
        [
         "21",
         "1",
         "b2w",
         "107263df2b68f7314a9d4d054b482d561874b33747efecbde31c92cdf6eb835f_129543938",
         "Celular ótimo. - Muito bom. Rápido, lindo acabamento é ótimo em  custo e benefício na atualidade."
        ],
        [
         "22",
         "1",
         "b2w",
         "f056fbe7d32e737b86326505cd1c9b638f10a7ac52b8f22e211e95da36b4a562_28774628",
         "Maravilhosa! - Depois que comprei, consegui apertar os parafusos aqui de casa com facilidade, vale a pena, só ela aperta tão bem. Parabéns a Tramontina e a Loja Americanas por vender algo tão grandioso. Ela é feita com meteoritos do planeta Vênus, por isso é um pouquinho mais caro, mas vale o investimento. Comprei 6."
        ],
        [
         "23",
         "0",
         "b2w",
         "a7f0ba0f2c2a06eec318d1c18d45f555ec6aa2ede92d48916baf4ee49846b35f_30490565",
         "Produto muito caro pra pouca eficiência! - O produto custa muito caro (1.000 R$) pra pouca diferença de um barbeador convencional de 300 R$. Além disso a caixa veio violada,riscada e amassada! Não recomendo a loja!"
        ],
        [
         "24",
         "0",
         "b2w",
         "c89517a242adee1fbc9e609fbef0ffd287d90c941f38bfa4a16b9f63e95a2868_14948667",
         "Compra péssima! - Fiz a compra deste aparelho e veio uma REPICA com essa loja neste site.  O aparelho não mostra o nome da pessoa agendada no celular, levei ao técnico e ele me falou que o aparelho é REPICA. Espero que a loja soluciona esse problema."
        ],
        [
         "25",
         "1",
         "b2w",
         "aff280432b14ff34badb3bef0ee115699fafd11d941c9c8ccbb662ac4ee8cae3_26688346",
         "Bom produto - Se estiver procurando uma mesa boa com preço baixo vale a pena, a única coisa que recomendo é prestar atenção nas medidas dela antes de comprar, pois achei um pouco pequena. Tirando isso, tudo certo, chegou muito antes do prazo e a montagem foi fácil de realizar."
        ],
        [
         "26",
         "1",
         "b2w",
         "1477a67bdb69264b9cfcd1c668d122665d2b5664cc4916714693474e40658ddd_9376439",
         "Entrega - A entrega se deu no prazo e o produto está de acordo com o que fou comprado"
        ],
        [
         "27",
         "1",
         "b2w",
         "4a3228644b02c71becf769a35cb78bd830a18fea863cbb16e11dd5b0e85e6ee0_8266883",
         "Ótimo - Melhor pendrive que já comprei. capacidade adequada, durabilidade e design de classe!"
        ],
        [
         "28",
         "0",
         "b2w",
         "99848d4c45bcfb54d0aa31d454455447fc40087929dc2bcda7af43616cde750a_132381386",
         "Lento para o que eu queria - Parece ser uma bom computador mas para quem vai ter ele em casa só para abrir e-mails e acessar a internet. Não roda bem o Photoshop, por isso devolvi ele! Estou comprando um i7 para ver se consigo trabalhar bem!"
        ],
        [
         "29",
         "1",
         "b2w",
         "88a60137c1ad74409e830b6e23b5589e880174c1ed05520da9aea7baf331deac_132444771",
         "Ótimo - Ótimo, gostei bastante. Recomendo para outros clientes."
        ],
        [
         "30",
         "1",
         "b2w",
         "26a6d0cd991dc7d28f1307bde573ea2a0cafd84965e77fd5ea2c16b28635b7c5_17467685",
         "Gostei muitoo - Gostei do preço compra rapida entrega rapida. O site tem ofertas e preços acessiveis e muito pratico a forma de comprar pela internet é um conforto e segurança."
        ],
        [
         "31",
         "1",
         "olist",
         "f70608bf9b456e29abc4566f8941602e",
         "Produto entregue com antecedência e preço muito bom."
        ],
        [
         "32",
         "0",
         "b2w",
         "a2b69b6df00dba0ff634b526e47d2609fa0599f761a668791886f78218c2a15c_132488706",
         "Arrependimento - Comprei e me arrependi. O computador apresenta erro de tela azul constante, o atendimento concierge que eles prometem é igual ao normal e já estou há 2 meses sendo enrolada pela Samsung, pois como não existe previsão de conserto (dizem que é incompatibilidade de SO, e que só uma atualização do windows estabilizaria ele) pedi meu dinheiro de volta."
        ],
        [
         "33",
         "1",
         "b2w",
         "c5a8ecd9e32080873d76a905f04e49c6f2b46cc12d2329f6fb04c9ae56f96bd2_27719133",
         "Muito Bom - Produto muito bom, corresponde as descrições do produto, entrega muito rápida!"
        ],
        [
         "34",
         "1",
         "b2w",
         "632da48ebc90856322170b73a05f26a16fd629ef8b368109dc3b54273e75b208_130156337",
         "produto perfeito! - produto maravilhoso! !chegou perfeito no destino muito recomendado! !"
        ],
        [
         "35",
         "1",
         "b2w",
         "0dc8dfaed777cd58308c5df00790e1c04e0335dd0b9bb3f512246c1525d1438d_129966797",
         "Avaliação - Muito boa a qualidade do produto e entregue antes do prazo estabelecido."
        ],
        [
         "36",
         "1",
         "b2w",
         "ac0300f42371ba79df514323a6f5cb8aa909877899faf21eb9a2f59ef0a8a85a_118075622",
         "Ótimo produto. - Achei o designer muito bonito, além de super espaçosa. Superou minhas expectativas no tamanho."
        ],
        [
         "37",
         "1",
         "olist",
         "c7f11f6eb4c0e0d8ef0da8f06b4b54b5",
         "Exatamente o demonstrado no anúncio e entrega rápida."
        ],
        [
         "38",
         "0",
         "olist",
         "2521ded73db8561e0fd8df85eeeaaf5e",
         "O vendedor entrou em contato comigo mas não concluiu a venda"
        ],
        [
         "39",
         "1",
         "b2w",
         "6f12e2443b15d475f396b25581744435947374f854a3b1268ab066e918051ab8_129679157",
         "Muito bom - Recomendo  a todos. Produto muito e entrega antes do prazo."
        ],
        [
         "40",
         "1",
         "b2w",
         "4162efa234b8fd5e541c994c2a475975e78ef849e7b2bb7a22a6473d8dc4d64e_19070411",
         "Perfeito - Comprei pra presentear minha esposa. Ela simplesmente adorou"
        ],
        [
         "41",
         "0",
         "b2w",
         "968990de108beae6f17ce5c53e32cd79caac97170ea7003a4f5a97dd06c0f410_23100736",
         "1 - Não recebi ainda! Não chegou ainda meu produto! Tá demorando muito"
        ],
        [
         "42",
         "1",
         "b2w",
         "5c5343545ca0179fa2dbfc55a54f5b092574adf9e140213a95c59e32919480a3_5057207",
         "Produto de otina qualidade - Produto de otina qualidade, e chegou rápido eu recomendo ."
        ],
        [
         "43",
         "1",
         "b2w",
         "66744eb377e1f77ddcf789035974bd8ae6a7ecef0f6261d5bf5f3f57244c0db8_114063835",
         "Fácil instalação - O kit é de fácil instalação e bem recomendado para quem usa notebooks em suportes, por exemplo."
        ],
        [
         "44",
         "0",
         "olist",
         "62a6fe4b0f0a1d6ccbf96afea383703e",
         "Prazo da entrega já venceu, e até agora n chegou minha mercadoria, 2 meses já."
        ],
        [
         "45",
         "1",
         "b2w",
         "e0e0aba6cc690df8cec65efb9ca5ac437380e1a9bf743ac23ba5f55a0173f826_131778120",
         "Smartphone LG K10 Power - Excelente aparelho, recomendo a aquisição a LG continua a produzir produtos de alta qualidade."
        ],
        [
         "46",
         "1",
         "b2w",
         "c40a6c118f3877ad149016c500a55a5e107ac6c1cca388f713f60c22df08e2b3_15533912",
         "Satisfeito - Acabei de receber, entrega rápida e eficiente.  Por enquanto está funcionando normalmente, nenhum problema encontrado."
        ],
        [
         "47",
         "1",
         "olist",
         "99db72e3d692d14853e108bf9a3fd7e1",
         "Produto chegou rápido e até o presente momento nada a reclamar."
        ],
        [
         "48",
         "1",
         "b2w",
         "5b64bdf3389de85f9e53eb7a375bc7b4ae131fafae2fd6a987b646b1c47939b8_132372640",
         "Exelente produto - Ainda em fase de testes mas até agora não tem nenhuma reclamação. otimo produto, otimo preço. otima smart tv."
        ],
        [
         "49",
         "1",
         "b2w",
         "44b6ff8d9ba086a0ac7700fa1100b508538b0bc7b4174feb82f7ec54ebc0b9f3_132114940",
         "Jogo muito bom para quem gosta de desafios - Jogo muito bom, versão com todas as dlcs  quem gosta de jogo que te desafia aconselho, e tbm a entrega foi rápida chegou até antes do dia"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 2718
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>source</th>\n",
       "      <th>review_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>b2w</td>\n",
       "      <td>52059e633d1d3d99db67fe9b0dd9ab02313a60c27e47c0...</td>\n",
       "      <td>Fraca - Produto nao aquece o suficiente. Nao a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>b2w</td>\n",
       "      <td>99e4bad489afcc355d58f315c7bff6dba6b0547e073447...</td>\n",
       "      <td>Ótima qualidade! - Rodapés prontos para instal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>b2w</td>\n",
       "      <td>1994c6c30f08b31a3f5024868381595e9f157c3b901638...</td>\n",
       "      <td>Não foi entregue - Faz mais de um mês que comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>b2w</td>\n",
       "      <td>326e7e6098b15d792fbf99c4649f0ea6ddca50b0861bda...</td>\n",
       "      <td>excelente compra - fiquei muito satisfeito com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>b2w</td>\n",
       "      <td>c78621b567856fa2b86f43858c4bfeedb442036b5ac320...</td>\n",
       "      <td>Praticidade na limpeza da casa! - Amei o produ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2713</th>\n",
       "      <td>1</td>\n",
       "      <td>b2w</td>\n",
       "      <td>a08a04ac3f59185da24eb3c58237ceb75415e0fd0fc229...</td>\n",
       "      <td>Rápida para preparar as receitas e fácil de li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2714</th>\n",
       "      <td>1</td>\n",
       "      <td>b2w</td>\n",
       "      <td>5dddbb02cc88d1695e16e19aee0bf650163b5157fc843c...</td>\n",
       "      <td>Ótimo livro - Comprei para auxiliar em meu pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2715</th>\n",
       "      <td>0</td>\n",
       "      <td>b2w</td>\n",
       "      <td>fb6e74ccd2b79eafeb2872770dda18eb4626fa4e978eb1...</td>\n",
       "      <td>NÃO CARREGA 1/3 DA BATERIA ORIGINAL - A foto d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2716</th>\n",
       "      <td>1</td>\n",
       "      <td>b2w</td>\n",
       "      <td>95aa3ebeac14c6e8a4c9410feeb14aece55a006f46743a...</td>\n",
       "      <td>Muito bom recomendo - Achei que fosse menor, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2717</th>\n",
       "      <td>1</td>\n",
       "      <td>b2w</td>\n",
       "      <td>20fcf86be395e74469d78a836f61d24e31fbcfb3624839...</td>\n",
       "      <td>Gostei muito do produto. - Super recomendo, ch...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2718 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label source                                          review_id  \\\n",
       "0         0    b2w  52059e633d1d3d99db67fe9b0dd9ab02313a60c27e47c0...   \n",
       "1         1    b2w  99e4bad489afcc355d58f315c7bff6dba6b0547e073447...   \n",
       "2         0    b2w  1994c6c30f08b31a3f5024868381595e9f157c3b901638...   \n",
       "3         1    b2w  326e7e6098b15d792fbf99c4649f0ea6ddca50b0861bda...   \n",
       "4         1    b2w  c78621b567856fa2b86f43858c4bfeedb442036b5ac320...   \n",
       "...     ...    ...                                                ...   \n",
       "2713      1    b2w  a08a04ac3f59185da24eb3c58237ceb75415e0fd0fc229...   \n",
       "2714      1    b2w  5dddbb02cc88d1695e16e19aee0bf650163b5157fc843c...   \n",
       "2715      0    b2w  fb6e74ccd2b79eafeb2872770dda18eb4626fa4e978eb1...   \n",
       "2716      1    b2w  95aa3ebeac14c6e8a4c9410feeb14aece55a006f46743a...   \n",
       "2717      1    b2w  20fcf86be395e74469d78a836f61d24e31fbcfb3624839...   \n",
       "\n",
       "                                                   text  \n",
       "0     Fraca - Produto nao aquece o suficiente. Nao a...  \n",
       "1     Ótima qualidade! - Rodapés prontos para instal...  \n",
       "2     Não foi entregue - Faz mais de um mês que comp...  \n",
       "3     excelente compra - fiquei muito satisfeito com...  \n",
       "4     Praticidade na limpeza da casa! - Amei o produ...  \n",
       "...                                                 ...  \n",
       "2713  Rápida para preparar as receitas e fácil de li...  \n",
       "2714  Ótimo livro - Comprei para auxiliar em meu pro...  \n",
       "2715  NÃO CARREGA 1/3 DA BATERIA ORIGINAL - A foto d...  \n",
       "2716  Muito bom recomendo - Achei que fosse menor, o...  \n",
       "2717  Gostei muito do produto. - Super recomendo, ch...  \n",
       "\n",
       "[2718 rows x 4 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "label",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "source",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "review_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "087beb5a-c44f-4d72-b051-3d8cdaf7d03d",
       "rows": [
        [
         "0",
         "0",
         "olist",
         "10467dc456e818c60bd750271b5d183e",
         "atraso na entrega da mercadoria,não cumpre prazo determinado."
        ],
        [
         "1",
         "1",
         "b2w",
         "9457791296d29bd13b2495f820c64bf55e129447c57af98c78404c3a689c2a3c_132390047",
         "EXCELENTE - EXCELENTE PRODUTO, RECOMENDO SEMPRE Smartphone Samsung Galaxy J5 Pro Dual Chip Android 7.0"
        ],
        [
         "2",
         "1",
         "olist",
         "e4879e4146d2a906e573e7dfdccfe163",
         "Entrega rápida, eficiente, produto de acordo com a compra."
        ],
        [
         "3",
         "0",
         "b2w",
         "c26604478b8cc31f11328e5146746cc1a66e5902f11199bb8dca395dda42537b_29971753",
         "Onde está o produto? - Não posso avaliar um produto que comprei a mais de trinta dias e ainda não foi entregue"
        ],
        [
         "4",
         "0",
         "b2w",
         "e163d49d72091e26cec076edce577dd429cdedd100e7bbc03afd90fffbe19ec6_125952603",
         "Descrição site - O produto parece exelente e o preço também, porém, tomem muito cuidado antes de comprar, no site está com a descrição de colchão de solteito. Só que as medidas do colchão não são para colchão de solteiro e sim para berço 1,50. Infelizmente não li a descrição até o final."
        ],
        [
         "5",
         "1",
         "b2w",
         "6c84ef9f8ebfc5e6a4b9ab50f87ed8ecfcc6532cc8ba68319e6844029d5dddcc_12566848",
         "muito bom - Fiquei muito satisfeita, a encomenda chegou bem antes do prazo previsto."
        ],
        [
         "6",
         "0",
         "olist",
         "f5b889f7357ca0f0939f343f3dab5e61",
         "O produto ficou 10 dias com status de aprovação de pagamento, enviei email duas vezes e não obtive resposta, tive que ligar no SAC para poderem entrar em contato com o vendedor para verem o pq?"
        ],
        [
         "7",
         "0",
         "b2w",
         "42af665aee0bb35568161ebfc37dd3b0a487f100caee296ea85ccc22376a3eb5_126102926",
         "Produto não recebido - Prazo de entrega venceu em 09/01 e até hoje, 21/01, não recebi o produto. A loja sequer disponibilizou código de rastreio. Não recomendo compras nas Lojas Americanas."
        ],
        [
         "8",
         "0",
         "b2w",
         "c692e5e517579382b5557cebcc03a7848eed8f8a843fd4096a34df93e277e81c_132447736",
         "estou muito chateada - o notebook tem dado muitos problemas, muitos mesmo, estou muito contrariada, já vai fazer dois meses que comprei , um mês e pouco que chegou.está cheio de problemas, desliga de repente, ou simplesmente some tudo, ou fica indo e voltando , e às vezes fica passando umas imagens tremidas na tela. sei que está na garantia ,mas estou tão chateada que nem ânimo de ligar lá eu tenho."
        ],
        [
         "9",
         "0",
         "olist",
         "931e0e2f7f73014c599ef5a106dd7cdc",
         "Fiz a compra da capa luxo no tom rosa e veio o dourado. Não gostei."
        ],
        [
         "10",
         "1",
         "b2w",
         "21f436c998bf44585e3e71f324ead55ee9b35e29af823ed5ea46b86cd4118b56_18204207",
         "Faz jus - Cumpre o prometido, excelente produto, recomendo a todos"
        ],
        [
         "11",
         "1",
         "olist",
         "d23e157b78060d3b3f144ffb522e1afb",
         "Veio antes do que eu esperava. recomento a todos"
        ],
        [
         "12",
         "0",
         "b2w",
         "b1f7449ef0f2003cfe2b3337ed8053498995ff57ecdda01044625bb34d72b9c8_21278698",
         "Tive problemas! - Meu produto veio funcionando, porém, as vezes ele não carrega e veio com peça solta."
        ],
        [
         "13",
         "1",
         "b2w",
         "3cfc10d4ecbdd7a1d49baf5af2223cb12b0d492d2d42efcf97d6b3bc8cf54907_126831715",
         "Achei ótimo. - Gosto de assistir minhas séries e esse produto atendeu minhas expectativas, não tenho Smart e ele atua direitinho espelhando a tela do celular."
        ],
        [
         "14",
         "1",
         "b2w",
         "accd333b557b2cf1505972e1a73423f8a073dde4ce52e51419811387ff9424c4_132324664",
         "Muito bom o produto! - Pedimos pelo site e chegou rápido, além do produto ser de ótima qualidade, as coisas ficaram mais rápidas de serem feitas com ela."
        ],
        [
         "15",
         "0",
         "b2w",
         "34703fc53adc8bea88dfd45ad5c14169f02a9cd1e66e802ebd86bb1f9d228e4a_125768056",
         "Precisa avaliar custo benefício - Recepção ruim, internet móvel não pega como deveria comparando com outros celulares no mesmo local. Não recomendo"
        ],
        [
         "16",
         "1",
         "b2w",
         "9b7b1d9ea43bb469ef7806fbd76804dcd997d7cb6089ce5c347a1d993589cb76_17708776",
         "Produto de excelente qualidade. - Excelente produto, econômico, muito bom, recomendo."
        ],
        [
         "17",
         "1",
         "b2w",
         "212d454d2baa26ad2ea430ee20c70db94d7f63d1d7d235bbd12cb78e24cc23b7_128010777",
         "Produto 100% - Produto atendeu as expectativas, muito bonito, bem funcional, estou super satisfeito."
        ],
        [
         "18",
         "0",
         "b2w",
         "51dcc4084d3b6c7b904d2b63cbfbf2a2ceab0de1129f310976db427dd8aa6043_22863937",
         "NAO RECEBI O PRODUTO - Novamente não recebi o produto dentro do prazo previsto, na outra vez, era porque, estava no final de ano . E agora? Qual é a desculpa?"
        ],
        [
         "19",
         "0",
         "olist",
         "f6d5af064375a33947d3e73a395bab1c",
         "a foto no site indicava uma unidade e nao um kit com duas delas. acabei recebendo 2 kits e tenho so 2 portas. um deles chegou entortado"
        ],
        [
         "20",
         "1",
         "b2w",
         "50ace6ec909ced450ebeaaca1bb652aaecb9adc7c25dcaedc1bb7cef91ed57e2_360198",
         "Gostei muito - É lindo, adorei as peças e o preço compatível. Recomendo esse faqueiro Tramontina Malibu 72 peças"
        ],
        [
         "21",
         "1",
         "olist",
         "0b91a4d715c8c90f869df866c4520cac",
         "Produto otimo - Gostei muito do produto e chegou mais rapido doq o esperado !"
        ],
        [
         "22",
         "1",
         "b2w",
         "acea3415f33acfc12e8acc291d2b3923398da9aecfa6703283cfea16f58a003c_131788803",
         "TV LG 43UJ6525 Ultra HD 4K - Excelente definição de imagem, controle fácil e intuitivo, leve, design elegante. Produto chegou dentro do prazo e em perfeito estado. Recomendo a compra!"
        ],
        [
         "23",
         "0",
         "b2w",
         "72c00763a2c7c494044f9fdc080553bd2f913d4aabd9ccb53e848a1494953c3b_132477564",
         "Avaliação Ruim - Esta avaliação dá-se ao fato de que em menos de uma semana o aparelho começou a reiniciar sozinho, o mesmo que meu aparelho anterior da mesma marca. Estou verificando a possibilidade de devolução do produto, pois preciso do equipamento mas que não tenha este problema recorrente na marca. Meu aparelho anterior um Moto Z Power Edition, começou a reiniciar sozinho e zerar a bateria, enviei pra assistência e me devolveram sem arrumar, disseram que não tinham a peça. Por isso adquiri um modelo um pouco acima mas que está acontecendo a mesma coisa."
        ],
        [
         "24",
         "1",
         "b2w",
         "ce8ed2b49bd48dcc815e0bc7422b78d97a42ec85a3184586dea55bde52f2bcc1_126403219",
         "Serve bem ao propósito. - Não é tão estável quando poderia, não fica tãaaao firme. Mas é muito bom. Minha filha se interessou e pede várias vezes para fazer xixi e cocô no vaso só pra usar a escadinha. Mas como não é tão firme, tem que sentar e levantar com cuidado porque sai do lugar."
        ],
        [
         "25",
         "1",
         "b2w",
         "31e4b71e58eec728e18d193e29ad82faadf50a5e7e854741df205651c83a2f30_16935190",
         "Um produto muito bom e de boa qualidade - Espetacular. Chegou na data que avia marcado É sem dúvida recomendo para todos"
        ],
        [
         "26",
         "1",
         "b2w",
         "7952b9d9fc9644cffc50133a459ce381220367be65e7718847204a1898ae6c1a_14615047",
         "Gostei muito do produto - Recomendo sim as pessoas comprarem é bem simples mas. É ótima"
        ],
        [
         "27",
         "1",
         "b2w",
         "15ad1f414216fa7f6e61fa7ccfeba6c51f2533c1c2463fb1204461827ca6a5ee_28779726",
         "Friso lateral gostei muito - Produto muito bom recomendo a todos os interessados"
        ],
        [
         "28",
         "1",
         "b2w",
         "49e5aa11a3484dc4f39b5b839325398443dc2014f03ff421b7643deb8fb9c863_132750701",
         "Muito Bom - Muito bom. Recomendo leitura para os filhos. fácil leitura e engraçado."
        ],
        [
         "29",
         "0",
         "b2w",
         "72df928399427e01675e78baa67b502427ef7e8c3f408cc7edccd407f5b8d564_20726696",
         "Não gostei muito do produto. - A cinta dobra e é  confortável. Não recomendo a compra."
        ],
        [
         "30",
         "1",
         "olist",
         "fc1eca0b5f5062443a7224250e3f4dbe",
         "Recomendo - Utilizei no capacete e eliminou o cheiro de suor.\r\nCompra entregue em 2 dias - muito eficiente quando não utilizado os correios!!!"
        ],
        [
         "31",
         "1",
         "b2w",
         "016bbc8554aac961d49e25bbfec1a34326128a968061a834fc5dbdfccba19827_132538321",
         "Recomendo para usuários casuais - O notebook é muito bom, o Windows 10 ferra um pouco com a velocidade, mas isso é coisa do sistema operacional. Recomendo muito esse produto."
        ],
        [
         "32",
         "1",
         "b2w",
         "26aff124ca55816a34406ad2a468b289a3f95f3bc2becd793a256d685db6591d_129542708",
         "100 % perfeito - Recomendo esse celular com um preço fantástico !!!!"
        ],
        [
         "33",
         "1",
         "b2w",
         "8797a7b267334dc142a863b881467ba36e69940877edfc113ee7c39ca8d9fb4e_22587056",
         "Adorei - Além de bonita acrílico muito e bom preço recomendo!"
        ],
        [
         "34",
         "0",
         "b2w",
         "8d5fcf70ffa34ea3f64b0aea6ed3de58ad7bdd78079868f84a65e34ca8262a8b_29489852",
         "Zero - Não recebi o produto, extraviado, a transportadora directamente b2w. Não conseguiu entregar."
        ],
        [
         "35",
         "0",
         "b2w",
         "291db537b20df073a4dd436a44c01d4d04a4cae134a953f313ec6d7624f58059_121023111",
         "Defeito - A piscina veio furada, tentei fazer a troca e é burocrático demais"
        ],
        [
         "36",
         "0",
         "b2w",
         "00bcdc41d9c1a7b0f83e05561728d7621159129b2a2863b31eb167905628ab34_31265972",
         "produto devolvido - devolvido produto pois encaminharam produto menor do que esperado."
        ],
        [
         "37",
         "1",
         "b2w",
         "4151c6d73c81c8ee14ebf7fe68e76b95ec440dbd15895941573ead0a46d2633e_32073978",
         "EXCELENTE PRODUTO - Recomendo a qualquer um,produto eficiente,esperto,não deve nada a nenhum celular fabricado por aqui.Podem comprar sem medo,o único problema são as capas e a película que são bem mais caras,mas vc acha aqui,ou no Alliexpress."
        ],
        [
         "38",
         "1",
         "b2w",
         "2d815165ca0531f686ea5a88d6a9d5d5ee2b832a5f5937223c998cc558ed0cb4_132381781",
         "Excelente produto - Ótima aquisição, produto de qualidade por um preço razoável."
        ],
        [
         "39",
         "1",
         "b2w",
         "7b76be26b16ed554737ba4e7f80f14712a48f922ec0894a52a3365ed1f2f7ec4_27546828",
         "Superou a expectativa - Amei o produto O produto chegou antes do prazo estipulado. É fácil  para montar. Usei em toda a casa e não  aqueceu."
        ],
        [
         "40",
         "1",
         "b2w",
         "2c66a8c6e50ebf70da334a1ec2d61300b15d2d126d68c27fd4be225f6087fe11_123669409",
         "Apaixonada - Primeiro a entrega bem antes do prazo! Isso só me faz mais feliz em comprar na loja. O livro é maravilhoso! Prende vc do início ao fim, mega feliz!"
        ],
        [
         "41",
         "0",
         "b2w",
         "387807aa94667e4391bb758ca7c34ce41f866cfe7ae75259f8ae5d98fc4a4e0b_29572191",
         "comprei mas ainda nao recebi - Comprei mas deu algum problema na transportadora totalexpress e ainda nao recebi o produto."
        ],
        [
         "42",
         "1",
         "b2w",
         "f9bd69e28981f03a4201c1fb223d2937c95c49447a986b3c8456cfc2f953c168_7260212",
         "Recomendo - Muito bom, não é barulhento, suga bem o cheiro das frituras e o tamanho para um fogão de 6 bocas adapta perfeitamente em um fogão de 4 bocas. Recomendo."
        ],
        [
         "43",
         "0",
         "b2w",
         "d45eab2a26e1e6cf94373e9ed8c948765cfd35bd7ee81d6658f581e51c52dab4_125719140",
         "Não recomendo - A TV tem o tamanho ideal para o que eu queria mas seu som seu volume é extremamente baixo. Nem qd coloquei num som amplificador ficou bom. Ficou com um chiado. Pedi o cancelamento da compra."
        ],
        [
         "44",
         "1",
         "b2w",
         "cb685e1e8951fa208ac780ea9d6bb65cdffdabcd74fb540b907da5c8f0d229d0_130150904",
         "eu amei - o produto é muito bom..................................................................."
        ],
        [
         "45",
         "0",
         "b2w",
         "39ce45c4bea6f841efc0ca2152a9e7de183e05f6b716e05620b8097657614f44_28594500",
         "Cana montessoriano - Hj era a data limite para chegar. Onptifuto nso veio O que devo fazer?"
        ],
        [
         "46",
         "0",
         "b2w",
         "a7bd6ea0bf41648857c0d7ee89d2f3c5a1fe33a625f46c7f61f99928161fbcf2_28434674",
         "cadeira de péssimo acabamento e frágil - não recomendo, com 1 mes de uso ela já quebrou o pistão não trava mais, o braço que faz a regulagem já está quebrado e sem funcionalidade."
        ],
        [
         "47",
         "1",
         "b2w",
         "1bcc3fc5fc31746d0a64c46e3b9aa7ca8e10913f814b6abb8e739b9c92ed3c0f_129542661",
         "Gostei muito do produto - Americana.com faz um excelente trabalho .Entregou a mercadoria antes do prazo."
        ],
        [
         "48",
         "1",
         "b2w",
         "2d8138edfaa0f3b23eb1c22bd8867897485ef8c2f96f62d40c50a439e812a867_23155828",
         "Marreta de Ouro - Essa linha Gourmet da Tramontina é sensacional.  Nitidamente podemos ver que a marreta é feita de ouro.  Comprei pra desempenar vidro. Só encostar que ela desempena. Custo x Benefício sensacional.  O cabo dela tbm é feito de um tipo de madeira encontrado apenas no Tibet, que os monges retiraram apenas 5 árvores por ano."
        ],
        [
         "49",
         "0",
         "olist",
         "653c99c159f7d98d0cd683bdb62eb19e",
         "Um desserviço ao cliente - Comprei dois rolos de papéis de parede conforme anúncio.... Recebi dois rolos de cor caramelo e flores bege (horrorosos de feios).... Totalmente em desconformidade... Abri reclamação... Péssimo !"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 23340
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>source</th>\n",
       "      <th>review_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>olist</td>\n",
       "      <td>10467dc456e818c60bd750271b5d183e</td>\n",
       "      <td>atraso na entrega da mercadoria,não cumpre pra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>b2w</td>\n",
       "      <td>9457791296d29bd13b2495f820c64bf55e129447c57af9...</td>\n",
       "      <td>EXCELENTE - EXCELENTE PRODUTO, RECOMENDO SEMPR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>olist</td>\n",
       "      <td>e4879e4146d2a906e573e7dfdccfe163</td>\n",
       "      <td>Entrega rápida, eficiente, produto de acordo c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>b2w</td>\n",
       "      <td>c26604478b8cc31f11328e5146746cc1a66e5902f11199...</td>\n",
       "      <td>Onde está o produto? - Não posso avaliar um pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>b2w</td>\n",
       "      <td>e163d49d72091e26cec076edce577dd429cdedd100e7bb...</td>\n",
       "      <td>Descrição site - O produto parece exelente e o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23335</th>\n",
       "      <td>1</td>\n",
       "      <td>olist</td>\n",
       "      <td>f2ab136899d66379c081ff7df3a49764</td>\n",
       "      <td>Impecável - Sensacional compra. Tudo perfeito....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23336</th>\n",
       "      <td>1</td>\n",
       "      <td>b2w</td>\n",
       "      <td>86627126f8cd43b0114eebc6b98ccb47031ff935a8c5a1...</td>\n",
       "      <td>bom produto. - cumpre bem  seu papel. samsung ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23337</th>\n",
       "      <td>1</td>\n",
       "      <td>b2w</td>\n",
       "      <td>e91cd2435aa32bb37077e20d5c479f27cc2d94f1f4f5fe...</td>\n",
       "      <td>Ótimo custo benefício - O mais potente de todo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23338</th>\n",
       "      <td>0</td>\n",
       "      <td>olist</td>\n",
       "      <td>2286d30e0344664fb0a24b56a644f9bf</td>\n",
       "      <td>ola pessoal nao entendo porque recebi so os ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23339</th>\n",
       "      <td>1</td>\n",
       "      <td>b2w</td>\n",
       "      <td>6ed38032286333a3a342d92b77a169726575b1cede0783...</td>\n",
       "      <td>Excelente - Gente para tudo!!! S.O.S é maravil...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23340 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label source                                          review_id  \\\n",
       "0          0  olist                   10467dc456e818c60bd750271b5d183e   \n",
       "1          1    b2w  9457791296d29bd13b2495f820c64bf55e129447c57af9...   \n",
       "2          1  olist                   e4879e4146d2a906e573e7dfdccfe163   \n",
       "3          0    b2w  c26604478b8cc31f11328e5146746cc1a66e5902f11199...   \n",
       "4          0    b2w  e163d49d72091e26cec076edce577dd429cdedd100e7bb...   \n",
       "...      ...    ...                                                ...   \n",
       "23335      1  olist                   f2ab136899d66379c081ff7df3a49764   \n",
       "23336      1    b2w  86627126f8cd43b0114eebc6b98ccb47031ff935a8c5a1...   \n",
       "23337      1    b2w  e91cd2435aa32bb37077e20d5c479f27cc2d94f1f4f5fe...   \n",
       "23338      0  olist                   2286d30e0344664fb0a24b56a644f9bf   \n",
       "23339      1    b2w  6ed38032286333a3a342d92b77a169726575b1cede0783...   \n",
       "\n",
       "                                                    text  \n",
       "0      atraso na entrega da mercadoria,não cumpre pra...  \n",
       "1      EXCELENTE - EXCELENTE PRODUTO, RECOMENDO SEMPR...  \n",
       "2      Entrega rápida, eficiente, produto de acordo c...  \n",
       "3      Onde está o produto? - Não posso avaliar um pr...  \n",
       "4      Descrição site - O produto parece exelente e o...  \n",
       "...                                                  ...  \n",
       "23335  Impecável - Sensacional compra. Tudo perfeito....  \n",
       "23336  bom produto. - cumpre bem  seu papel. samsung ...  \n",
       "23337  Ótimo custo benefício - O mais potente de todo...  \n",
       "23338  ola pessoal nao entendo porque recebi so os ta...  \n",
       "23339  Excelente - Gente para tudo!!! S.O.S é maravil...  \n",
       "\n",
       "[23340 rows x 4 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "j",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Polarity",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Coverage",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Overlaps",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Conflicts",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "41bb60a5-9843-4555-a302-1c455248f9f9",
       "rows": [
        [
         "lf_regex_positive_a",
         "0",
         "[1]",
         "0.1600004660320863",
         "0.1550605259172094",
         "0.015332455639570785"
        ],
        [
         "lf_regex_positive_b",
         "1",
         "[1]",
         "0.15009728419801704",
         "0.12238002586478079",
         "0.011208071675734874"
        ],
        [
         "lf_regex_positive_c",
         "2",
         "[1]",
         "0.2421153196397572",
         "0.1969568104764013",
         "0.013013946010182801"
        ],
        [
         "lf_regex_positive_d",
         "3",
         "[1]",
         "0.05277813377451038",
         "0.043480793652642985",
         "0.0030525101653248827"
        ],
        [
         "lf_regex_positive_e",
         "4",
         "[1]",
         "0.31275413312206546",
         "0.31275413312206546",
         "0.03372907224662418"
        ],
        [
         "lf_regex_positive_f",
         "5",
         "[1]",
         "0.4758071093194767",
         "0.4222483718003985",
         "0.050354766925702836"
        ],
        [
         "lf_regex_positive_g",
         "6",
         "[1]",
         "0.22031666880264705",
         "0.20250259230348008",
         "0.014784867938157541"
        ],
        [
         "lf_regex_positive_h",
         "7",
         "[1]",
         "0.0822779648378791",
         "0.06595519101490138",
         "0.013794549754750614"
        ],
        [
         "lf_regex_positive_i",
         "8",
         "[1]",
         "0.0041360347659936385",
         "0.003367081823583554",
         "0.0014680010718737986"
        ],
        [
         "lf_regex_positive_j",
         "9",
         "[1]",
         "0.025678367955633746",
         "0.02151903158532465",
         "0.018583029441577054"
        ],
        [
         "lf_regex_positive_k",
         "10",
         "[1]",
         "0.028812433736062727",
         "0.024291922498864048",
         "0.004404003215621396"
        ],
        [
         "lf_regex_positive_l",
         "11",
         "[1]",
         "0.019270426768883037",
         "0.015309154035255327",
         "0.001060222996353299"
        ],
        [
         "lf_regex_negative_a",
         "12",
         "[0]",
         "0.02638906688725519",
         "0.02614440004194289",
         "0.008213815521198634"
        ],
        [
         "lf_regex_negative_b",
         "13",
         "[0]",
         "0.014388740664794772",
         "0.011522643333993545",
         "0.006163274341438408"
        ],
        [
         "lf_regex_negative_c",
         "14",
         "[0]",
         "0.04811781291141895",
         "0.037468979739255046",
         "0.026027892020365602"
        ],
        [
         "lf_regex_negative_d",
         "15",
         "[0]",
         "0.029546434271999628",
         "0.023814239610397175",
         "0.006722512845009379"
        ],
        [
         "lf_regex_negative_e",
         "16",
         "[0]",
         "0.005522480222763337",
         "0.005522480222763337",
         "0.001770921927974741"
        ],
        [
         "lf_regex_negative_f",
         "17",
         "[0]",
         "0.0639279514394566",
         "0.06390464983514114",
         "0.015262550826624413"
        ],
        [
         "lf_regex_negative_g",
         "18",
         "[0]",
         "0.029662942293576914",
         "0.023755985599608533",
         "0.008912863650662349"
        ],
        [
         "lf_regex_negative_h",
         "19",
         "[0]",
         "0.0890121284850462",
         "0.08094977339189803",
         "0.02338315993056122"
        ],
        [
         "lf_regex_negative_i",
         "20",
         "[0]",
         "0.05558597709452296",
         "0.05428108725285736",
         "0.016567440668290013"
        ],
        [
         "lf_regex_negative_j",
         "21",
         "[0]",
         "0.01706842516107234",
         "0.011627500553413102",
         "0.004718574873880067"
        ],
        [
         "lf_regex_negative_k",
         "22",
         "[0]",
         "0.0050447973342964665",
         "0.004427304819936853",
         "0.0012233342265614987"
        ],
        [
         "lf_regex_negative_l",
         "23",
         "[0]",
         "0.034684438023557924",
         "0.030886276520138412",
         "0.018967505912782096"
        ],
        [
         "lf_regex_negative_m",
         "24",
         "[0]",
         "0.0647784599969708",
         "0.038074821451456936",
         "0.015274201628782142"
        ],
        [
         "lf_regex_negative_n",
         "25",
         "[0]",
         "0.022940429448567536",
         "0.015227598420151228",
         "0.006116671132807494"
        ],
        [
         "lf_regex_negative_o",
         "26",
         "[0]",
         "0.013724644941804243",
         "0.008062355093148163",
         "0.0036350502732113107"
        ],
        [
         "lf_regex_negative_p",
         "27",
         "[0]",
         "0.03298342090852955",
         "0.024385128916125876",
         "0.0076895294241008496"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 28
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lf_regex_positive_a</th>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.155061</td>\n",
       "      <td>0.015332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_regex_positive_b</th>\n",
       "      <td>1</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.150097</td>\n",
       "      <td>0.122380</td>\n",
       "      <td>0.011208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_regex_positive_c</th>\n",
       "      <td>2</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.242115</td>\n",
       "      <td>0.196957</td>\n",
       "      <td>0.013014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_regex_positive_d</th>\n",
       "      <td>3</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.052778</td>\n",
       "      <td>0.043481</td>\n",
       "      <td>0.003053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_regex_positive_e</th>\n",
       "      <td>4</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.312754</td>\n",
       "      <td>0.312754</td>\n",
       "      <td>0.033729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_regex_positive_f</th>\n",
       "      <td>5</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.475807</td>\n",
       "      <td>0.422248</td>\n",
       "      <td>0.050355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_regex_positive_g</th>\n",
       "      <td>6</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.220317</td>\n",
       "      <td>0.202503</td>\n",
       "      <td>0.014785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_regex_positive_h</th>\n",
       "      <td>7</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.082278</td>\n",
       "      <td>0.065955</td>\n",
       "      <td>0.013795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_regex_positive_i</th>\n",
       "      <td>8</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.004136</td>\n",
       "      <td>0.003367</td>\n",
       "      <td>0.001468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_regex_positive_j</th>\n",
       "      <td>9</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.025678</td>\n",
       "      <td>0.021519</td>\n",
       "      <td>0.018583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_regex_positive_k</th>\n",
       "      <td>10</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.028812</td>\n",
       "      <td>0.024292</td>\n",
       "      <td>0.004404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_regex_positive_l</th>\n",
       "      <td>11</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.019270</td>\n",
       "      <td>0.015309</td>\n",
       "      <td>0.001060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_regex_negative_a</th>\n",
       "      <td>12</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.026389</td>\n",
       "      <td>0.026144</td>\n",
       "      <td>0.008214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_regex_negative_b</th>\n",
       "      <td>13</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.014389</td>\n",
       "      <td>0.011523</td>\n",
       "      <td>0.006163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_regex_negative_c</th>\n",
       "      <td>14</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.048118</td>\n",
       "      <td>0.037469</td>\n",
       "      <td>0.026028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_regex_negative_d</th>\n",
       "      <td>15</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.029546</td>\n",
       "      <td>0.023814</td>\n",
       "      <td>0.006723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_regex_negative_e</th>\n",
       "      <td>16</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.005522</td>\n",
       "      <td>0.005522</td>\n",
       "      <td>0.001771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_regex_negative_f</th>\n",
       "      <td>17</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.063928</td>\n",
       "      <td>0.063905</td>\n",
       "      <td>0.015263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_regex_negative_g</th>\n",
       "      <td>18</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.029663</td>\n",
       "      <td>0.023756</td>\n",
       "      <td>0.008913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_regex_negative_h</th>\n",
       "      <td>19</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.089012</td>\n",
       "      <td>0.080950</td>\n",
       "      <td>0.023383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_regex_negative_i</th>\n",
       "      <td>20</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.055586</td>\n",
       "      <td>0.054281</td>\n",
       "      <td>0.016567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_regex_negative_j</th>\n",
       "      <td>21</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.017068</td>\n",
       "      <td>0.011628</td>\n",
       "      <td>0.004719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_regex_negative_k</th>\n",
       "      <td>22</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.005045</td>\n",
       "      <td>0.004427</td>\n",
       "      <td>0.001223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_regex_negative_l</th>\n",
       "      <td>23</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.034684</td>\n",
       "      <td>0.030886</td>\n",
       "      <td>0.018968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_regex_negative_m</th>\n",
       "      <td>24</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.064778</td>\n",
       "      <td>0.038075</td>\n",
       "      <td>0.015274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_regex_negative_n</th>\n",
       "      <td>25</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.022940</td>\n",
       "      <td>0.015228</td>\n",
       "      <td>0.006117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_regex_negative_o</th>\n",
       "      <td>26</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.013725</td>\n",
       "      <td>0.008062</td>\n",
       "      <td>0.003635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_regex_negative_p</th>\n",
       "      <td>27</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.032983</td>\n",
       "      <td>0.024385</td>\n",
       "      <td>0.007690</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      j Polarity  Coverage  Overlaps  Conflicts\n",
       "lf_regex_positive_a   0      [1]  0.160000  0.155061   0.015332\n",
       "lf_regex_positive_b   1      [1]  0.150097  0.122380   0.011208\n",
       "lf_regex_positive_c   2      [1]  0.242115  0.196957   0.013014\n",
       "lf_regex_positive_d   3      [1]  0.052778  0.043481   0.003053\n",
       "lf_regex_positive_e   4      [1]  0.312754  0.312754   0.033729\n",
       "lf_regex_positive_f   5      [1]  0.475807  0.422248   0.050355\n",
       "lf_regex_positive_g   6      [1]  0.220317  0.202503   0.014785\n",
       "lf_regex_positive_h   7      [1]  0.082278  0.065955   0.013795\n",
       "lf_regex_positive_i   8      [1]  0.004136  0.003367   0.001468\n",
       "lf_regex_positive_j   9      [1]  0.025678  0.021519   0.018583\n",
       "lf_regex_positive_k  10      [1]  0.028812  0.024292   0.004404\n",
       "lf_regex_positive_l  11      [1]  0.019270  0.015309   0.001060\n",
       "lf_regex_negative_a  12      [0]  0.026389  0.026144   0.008214\n",
       "lf_regex_negative_b  13      [0]  0.014389  0.011523   0.006163\n",
       "lf_regex_negative_c  14      [0]  0.048118  0.037469   0.026028\n",
       "lf_regex_negative_d  15      [0]  0.029546  0.023814   0.006723\n",
       "lf_regex_negative_e  16      [0]  0.005522  0.005522   0.001771\n",
       "lf_regex_negative_f  17      [0]  0.063928  0.063905   0.015263\n",
       "lf_regex_negative_g  18      [0]  0.029663  0.023756   0.008913\n",
       "lf_regex_negative_h  19      [0]  0.089012  0.080950   0.023383\n",
       "lf_regex_negative_i  20      [0]  0.055586  0.054281   0.016567\n",
       "lf_regex_negative_j  21      [0]  0.017068  0.011628   0.004719\n",
       "lf_regex_negative_k  22      [0]  0.005045  0.004427   0.001223\n",
       "lf_regex_negative_l  23      [0]  0.034684  0.030886   0.018968\n",
       "lf_regex_negative_m  24      [0]  0.064778  0.038075   0.015274\n",
       "lf_regex_negative_n  25      [0]  0.022940  0.015228   0.006117\n",
       "lf_regex_negative_o  26      [0]  0.013725  0.008062   0.003635\n",
       "lf_regex_negative_p  27      [0]  0.032983  0.024385   0.007690"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LFAnalysis(L=L_train, lfs=lfs).lf_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "j",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Polarity",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Coverage",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Overlaps",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Conflicts",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Correct",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Incorrect",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Emp. Acc.",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "931b5813-f28b-4b54-8225-fac241e36132",
       "rows": [
        [
         "lf_regex_positive_a",
         "0",
         "[1]",
         "0.13612950699043413",
         "0.13281824871228845",
         "0.013245033112582781",
         "349",
         "21",
         "0.9432432432432433"
        ],
        [
         "lf_regex_positive_b",
         "1",
         "[1]",
         "0.13171449595290655",
         "0.10706401766004416",
         "0.010669610007358351",
         "335",
         "23",
         "0.9357541899441341"
        ],
        [
         "lf_regex_positive_c",
         "2",
         "[1]",
         "0.2016188373804268",
         "0.1637233259749816",
         "0.009565857247976454",
         "538",
         "10",
         "0.9817518248175183"
        ],
        [
         "lf_regex_positive_d",
         "3",
         "[1]",
         "0.051508462104488596",
         "0.04194260485651214",
         "0.003679175864606328",
         "135",
         "5",
         "0.9642857142857143"
        ],
        [
         "lf_regex_positive_e",
         "4",
         "[1]",
         "0.2582781456953642",
         "0.2582781456953642",
         "0.029065489330389993",
         "648",
         "54",
         "0.9230769230769231"
        ],
        [
         "lf_regex_positive_f",
         "5",
         "[1]",
         "0.39514348785871967",
         "0.35467255334805003",
         "0.0437821927888153",
         "1000",
         "74",
         "0.931098696461825"
        ],
        [
         "lf_regex_positive_g",
         "6",
         "[1]",
         "0.18579838116261957",
         "0.16850625459896984",
         "0.012141280353200883",
         "497",
         "8",
         "0.9841584158415841"
        ],
        [
         "lf_regex_positive_h",
         "7",
         "[1]",
         "0.054451802796173655",
         "0.044518027961736574",
         "0.009565857247976454",
         "118",
         "30",
         "0.7972972972972974"
        ],
        [
         "lf_regex_positive_i",
         "8",
         "[1]",
         "0.0011037527593818985",
         "0.0011037527593818985",
         "0.0003679175864606328",
         "1",
         "2",
         "0.33333333333333337"
        ],
        [
         "lf_regex_positive_j",
         "9",
         "[1]",
         "0.017660044150110375",
         "0.014716703458425313",
         "0.013245033112582781",
         "8",
         "40",
         "0.16666666666666669"
        ],
        [
         "lf_regex_positive_k",
         "10",
         "[1]",
         "0.02097130242825607",
         "0.018763796909492272",
         "0.004782928623988227",
         "45",
         "12",
         "0.7894736842105263"
        ],
        [
         "lf_regex_positive_l",
         "11",
         "[1]",
         "0.013980868285504048",
         "0.011037527593818985",
         "0.0011037527593818985",
         "38",
         "0",
         "1.0"
        ],
        [
         "lf_regex_negative_a",
         "12",
         "[0]",
         "0.02612214863870493",
         "0.025754231052244298",
         "0.006990434142752024",
         "62",
         "9",
         "0.8732394366197183"
        ],
        [
         "lf_regex_negative_b",
         "13",
         "[0]",
         "0.011037527593818985",
         "0.009565857247976454",
         "0.006254598969830758",
         "21",
         "9",
         "0.7"
        ],
        [
         "lf_regex_negative_c",
         "14",
         "[0]",
         "0.036055923473142015",
         "0.027225901398086828",
         "0.01839587932303164",
         "48",
         "50",
         "0.4897959183673469"
        ],
        [
         "lf_regex_negative_d",
         "15",
         "[0]",
         "0.02759381898454746",
         "0.021707137601177335",
         "0.008094186902133923",
         "75",
         "0",
         "1.0"
        ],
        [
         "lf_regex_negative_e",
         "16",
         "[0]",
         "0.004047093451066961",
         "0.004047093451066961",
         "0.0014716703458425313",
         "8",
         "3",
         "0.7272727272727273"
        ],
        [
         "lf_regex_negative_f",
         "17",
         "[0]",
         "0.061074319352465045",
         "0.061074319352465045",
         "0.013245033112582781",
         "158",
         "8",
         "0.9518072289156627"
        ],
        [
         "lf_regex_negative_g",
         "18",
         "[0]",
         "0.02869757174392936",
         "0.021339220014716703",
         "0.006622516556291391",
         "69",
         "9",
         "0.8846153846153846"
        ],
        [
         "lf_regex_negative_h",
         "19",
         "[0]",
         "0.08314937454010302",
         "0.07579102281089035",
         "0.020603384841795438",
         "212",
         "14",
         "0.9380530973451328"
        ],
        [
         "lf_regex_negative_i",
         "20",
         "[0]",
         "0.051508462104488596",
         "0.0504047093451067",
         "0.012877115526122149",
         "126",
         "14",
         "0.9"
        ],
        [
         "lf_regex_negative_j",
         "21",
         "[0]",
         "0.013612950699043414",
         "0.00919793966151582",
         "0.004415011037527594",
         "33",
         "4",
         "0.8918918918918919"
        ],
        [
         "lf_regex_negative_k",
         "22",
         "[0]",
         "0.0051508462104488595",
         "0.004782928623988227",
         "0.0007358351729212656",
         "14",
         "0",
         "1.0"
        ],
        [
         "lf_regex_negative_l",
         "23",
         "[0]",
         "0.027961736571008096",
         "0.024650478292862398",
         "0.012141280353200883",
         "57",
         "19",
         "0.75"
        ],
        [
         "lf_regex_negative_m",
         "24",
         "[0]",
         "0.05371596762325239",
         "0.029065489330389993",
         "0.011405445180279618",
         "141",
         "5",
         "0.9657534246575342"
        ],
        [
         "lf_regex_negative_n",
         "25",
         "[0]",
         "0.017292126563649743",
         "0.011405445180279618",
         "0.0051508462104488595",
         "45",
         "2",
         "0.9574468085106382"
        ],
        [
         "lf_regex_negative_o",
         "26",
         "[0]",
         "0.011037527593818985",
         "0.008094186902133923",
         "0.004047093451066961",
         "25",
         "5",
         "0.8333333333333333"
        ],
        [
         "lf_regex_negative_p",
         "27",
         "[0]",
         "0.027961736571008096",
         "0.02207505518763797",
         "0.006622516556291391",
         "71",
         "5",
         "0.9342105263157895"
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 28
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "      <th>Correct</th>\n",
       "      <th>Incorrect</th>\n",
       "      <th>Emp. Acc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lf_regex_positive_a</th>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.136130</td>\n",
       "      <td>0.132818</td>\n",
       "      <td>0.013245</td>\n",
       "      <td>349</td>\n",
       "      <td>21</td>\n",
       "      <td>0.943243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_regex_positive_b</th>\n",
       "      <td>1</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.131714</td>\n",
       "      <td>0.107064</td>\n",
       "      <td>0.010670</td>\n",
       "      <td>335</td>\n",
       "      <td>23</td>\n",
       "      <td>0.935754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_regex_positive_c</th>\n",
       "      <td>2</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.201619</td>\n",
       "      <td>0.163723</td>\n",
       "      <td>0.009566</td>\n",
       "      <td>538</td>\n",
       "      <td>10</td>\n",
       "      <td>0.981752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_regex_positive_d</th>\n",
       "      <td>3</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.051508</td>\n",
       "      <td>0.041943</td>\n",
       "      <td>0.003679</td>\n",
       "      <td>135</td>\n",
       "      <td>5</td>\n",
       "      <td>0.964286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_regex_positive_e</th>\n",
       "      <td>4</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.258278</td>\n",
       "      <td>0.258278</td>\n",
       "      <td>0.029065</td>\n",
       "      <td>648</td>\n",
       "      <td>54</td>\n",
       "      <td>0.923077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_regex_positive_f</th>\n",
       "      <td>5</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.395143</td>\n",
       "      <td>0.354673</td>\n",
       "      <td>0.043782</td>\n",
       "      <td>1000</td>\n",
       "      <td>74</td>\n",
       "      <td>0.931099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_regex_positive_g</th>\n",
       "      <td>6</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.185798</td>\n",
       "      <td>0.168506</td>\n",
       "      <td>0.012141</td>\n",
       "      <td>497</td>\n",
       "      <td>8</td>\n",
       "      <td>0.984158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_regex_positive_h</th>\n",
       "      <td>7</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.054452</td>\n",
       "      <td>0.044518</td>\n",
       "      <td>0.009566</td>\n",
       "      <td>118</td>\n",
       "      <td>30</td>\n",
       "      <td>0.797297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_regex_positive_i</th>\n",
       "      <td>8</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.001104</td>\n",
       "      <td>0.001104</td>\n",
       "      <td>0.000368</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_regex_positive_j</th>\n",
       "      <td>9</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.017660</td>\n",
       "      <td>0.014717</td>\n",
       "      <td>0.013245</td>\n",
       "      <td>8</td>\n",
       "      <td>40</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_regex_positive_k</th>\n",
       "      <td>10</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.020971</td>\n",
       "      <td>0.018764</td>\n",
       "      <td>0.004783</td>\n",
       "      <td>45</td>\n",
       "      <td>12</td>\n",
       "      <td>0.789474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_regex_positive_l</th>\n",
       "      <td>11</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.013981</td>\n",
       "      <td>0.011038</td>\n",
       "      <td>0.001104</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_regex_negative_a</th>\n",
       "      <td>12</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.026122</td>\n",
       "      <td>0.025754</td>\n",
       "      <td>0.006990</td>\n",
       "      <td>62</td>\n",
       "      <td>9</td>\n",
       "      <td>0.873239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_regex_negative_b</th>\n",
       "      <td>13</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.011038</td>\n",
       "      <td>0.009566</td>\n",
       "      <td>0.006255</td>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_regex_negative_c</th>\n",
       "      <td>14</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.036056</td>\n",
       "      <td>0.027226</td>\n",
       "      <td>0.018396</td>\n",
       "      <td>48</td>\n",
       "      <td>50</td>\n",
       "      <td>0.489796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_regex_negative_d</th>\n",
       "      <td>15</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.027594</td>\n",
       "      <td>0.021707</td>\n",
       "      <td>0.008094</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_regex_negative_e</th>\n",
       "      <td>16</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.004047</td>\n",
       "      <td>0.004047</td>\n",
       "      <td>0.001472</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_regex_negative_f</th>\n",
       "      <td>17</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.061074</td>\n",
       "      <td>0.061074</td>\n",
       "      <td>0.013245</td>\n",
       "      <td>158</td>\n",
       "      <td>8</td>\n",
       "      <td>0.951807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_regex_negative_g</th>\n",
       "      <td>18</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.028698</td>\n",
       "      <td>0.021339</td>\n",
       "      <td>0.006623</td>\n",
       "      <td>69</td>\n",
       "      <td>9</td>\n",
       "      <td>0.884615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_regex_negative_h</th>\n",
       "      <td>19</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.083149</td>\n",
       "      <td>0.075791</td>\n",
       "      <td>0.020603</td>\n",
       "      <td>212</td>\n",
       "      <td>14</td>\n",
       "      <td>0.938053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_regex_negative_i</th>\n",
       "      <td>20</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.051508</td>\n",
       "      <td>0.050405</td>\n",
       "      <td>0.012877</td>\n",
       "      <td>126</td>\n",
       "      <td>14</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_regex_negative_j</th>\n",
       "      <td>21</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.013613</td>\n",
       "      <td>0.009198</td>\n",
       "      <td>0.004415</td>\n",
       "      <td>33</td>\n",
       "      <td>4</td>\n",
       "      <td>0.891892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_regex_negative_k</th>\n",
       "      <td>22</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.005151</td>\n",
       "      <td>0.004783</td>\n",
       "      <td>0.000736</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_regex_negative_l</th>\n",
       "      <td>23</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.027962</td>\n",
       "      <td>0.024650</td>\n",
       "      <td>0.012141</td>\n",
       "      <td>57</td>\n",
       "      <td>19</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_regex_negative_m</th>\n",
       "      <td>24</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.053716</td>\n",
       "      <td>0.029065</td>\n",
       "      <td>0.011405</td>\n",
       "      <td>141</td>\n",
       "      <td>5</td>\n",
       "      <td>0.965753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_regex_negative_n</th>\n",
       "      <td>25</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.017292</td>\n",
       "      <td>0.011405</td>\n",
       "      <td>0.005151</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>0.957447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_regex_negative_o</th>\n",
       "      <td>26</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.011038</td>\n",
       "      <td>0.008094</td>\n",
       "      <td>0.004047</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_regex_negative_p</th>\n",
       "      <td>27</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.027962</td>\n",
       "      <td>0.022075</td>\n",
       "      <td>0.006623</td>\n",
       "      <td>71</td>\n",
       "      <td>5</td>\n",
       "      <td>0.934211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      j Polarity  Coverage  Overlaps  Conflicts  Correct  \\\n",
       "lf_regex_positive_a   0      [1]  0.136130  0.132818   0.013245      349   \n",
       "lf_regex_positive_b   1      [1]  0.131714  0.107064   0.010670      335   \n",
       "lf_regex_positive_c   2      [1]  0.201619  0.163723   0.009566      538   \n",
       "lf_regex_positive_d   3      [1]  0.051508  0.041943   0.003679      135   \n",
       "lf_regex_positive_e   4      [1]  0.258278  0.258278   0.029065      648   \n",
       "lf_regex_positive_f   5      [1]  0.395143  0.354673   0.043782     1000   \n",
       "lf_regex_positive_g   6      [1]  0.185798  0.168506   0.012141      497   \n",
       "lf_regex_positive_h   7      [1]  0.054452  0.044518   0.009566      118   \n",
       "lf_regex_positive_i   8      [1]  0.001104  0.001104   0.000368        1   \n",
       "lf_regex_positive_j   9      [1]  0.017660  0.014717   0.013245        8   \n",
       "lf_regex_positive_k  10      [1]  0.020971  0.018764   0.004783       45   \n",
       "lf_regex_positive_l  11      [1]  0.013981  0.011038   0.001104       38   \n",
       "lf_regex_negative_a  12      [0]  0.026122  0.025754   0.006990       62   \n",
       "lf_regex_negative_b  13      [0]  0.011038  0.009566   0.006255       21   \n",
       "lf_regex_negative_c  14      [0]  0.036056  0.027226   0.018396       48   \n",
       "lf_regex_negative_d  15      [0]  0.027594  0.021707   0.008094       75   \n",
       "lf_regex_negative_e  16      [0]  0.004047  0.004047   0.001472        8   \n",
       "lf_regex_negative_f  17      [0]  0.061074  0.061074   0.013245      158   \n",
       "lf_regex_negative_g  18      [0]  0.028698  0.021339   0.006623       69   \n",
       "lf_regex_negative_h  19      [0]  0.083149  0.075791   0.020603      212   \n",
       "lf_regex_negative_i  20      [0]  0.051508  0.050405   0.012877      126   \n",
       "lf_regex_negative_j  21      [0]  0.013613  0.009198   0.004415       33   \n",
       "lf_regex_negative_k  22      [0]  0.005151  0.004783   0.000736       14   \n",
       "lf_regex_negative_l  23      [0]  0.027962  0.024650   0.012141       57   \n",
       "lf_regex_negative_m  24      [0]  0.053716  0.029065   0.011405      141   \n",
       "lf_regex_negative_n  25      [0]  0.017292  0.011405   0.005151       45   \n",
       "lf_regex_negative_o  26      [0]  0.011038  0.008094   0.004047       25   \n",
       "lf_regex_negative_p  27      [0]  0.027962  0.022075   0.006623       71   \n",
       "\n",
       "                     Incorrect  Emp. Acc.  \n",
       "lf_regex_positive_a         21   0.943243  \n",
       "lf_regex_positive_b         23   0.935754  \n",
       "lf_regex_positive_c         10   0.981752  \n",
       "lf_regex_positive_d          5   0.964286  \n",
       "lf_regex_positive_e         54   0.923077  \n",
       "lf_regex_positive_f         74   0.931099  \n",
       "lf_regex_positive_g          8   0.984158  \n",
       "lf_regex_positive_h         30   0.797297  \n",
       "lf_regex_positive_i          2   0.333333  \n",
       "lf_regex_positive_j         40   0.166667  \n",
       "lf_regex_positive_k         12   0.789474  \n",
       "lf_regex_positive_l          0   1.000000  \n",
       "lf_regex_negative_a          9   0.873239  \n",
       "lf_regex_negative_b          9   0.700000  \n",
       "lf_regex_negative_c         50   0.489796  \n",
       "lf_regex_negative_d          0   1.000000  \n",
       "lf_regex_negative_e          3   0.727273  \n",
       "lf_regex_negative_f          8   0.951807  \n",
       "lf_regex_negative_g          9   0.884615  \n",
       "lf_regex_negative_h         14   0.938053  \n",
       "lf_regex_negative_i         14   0.900000  \n",
       "lf_regex_negative_j          4   0.891892  \n",
       "lf_regex_negative_k          0   1.000000  \n",
       "lf_regex_negative_l         19   0.750000  \n",
       "lf_regex_negative_m          5   0.965753  \n",
       "lf_regex_negative_n          2   0.957447  \n",
       "lf_regex_negative_o          5   0.833333  \n",
       "lf_regex_negative_p          5   0.934211  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LFAnalysis(L=L_valid, lfs=lfs).lf_summary(Y=df_valid.label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LFAnalysis(L=L_train, lfs=lfs).label_coverage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8421633554083885"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LFAnalysis(L=L_valid, lfs=lfs).label_coverage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.30206034, 0.69793966])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_balance = (\n",
    "    pd.Series(df_valid.label).value_counts(normalize=True).sort_index().values\n",
    ")\n",
    "class_balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.24668243, 0.75331757])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A trick to approximate class balance without using a validation set is to use the MajorityLabelVoter model on the LFs\n",
    "\n",
    "majority_model = MajorityLabelVoter(cardinality=2)\n",
    "preds_train = majority_model.predict(\n",
    "    L=L_train, tie_break_policy=\"random\"\n",
    ")  # Random tie-breaking\n",
    "\n",
    "# Calculate class balance\n",
    "approximated_class_balance = np.unique(preds_train, return_counts=True)[1] / len(\n",
    "    preds_train\n",
    ")\n",
    "approximated_class_balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "import helpers.classification\n",
    "\n",
    "\n",
    "def train_and_evaluate_model(\n",
    "    X_train: Any,\n",
    "    y_train: Any,\n",
    "    X_test: Any,\n",
    "    y_test: Any,\n",
    "    label_model_name: str,\n",
    "    verbose: bool = True,\n",
    "    type_label: str = \"LM + EM\",\n",
    ") -> dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Train a SGDClassifier model and evaluate its performance on the test set.\n",
    "\n",
    "    Args:\n",
    "        X_train (Any): Training data features.\n",
    "        y_train (Any): Training data labels.\n",
    "        X_test (Any): Test data features.\n",
    "        y_test (Any): Test data labels.\n",
    "        label_model_name (str): Name of the label model.\n",
    "        verbose (bool, optional): Whether to print detailed metrics. Defaults to True.\n",
    "        type_label (str, optional): Type of label model. Defaults to 'LM + EM'.\n",
    "\n",
    "    Returns:\n",
    "        dict[str, Any]: A dictionary containing the label model name and Matthews correlation coefficient.\n",
    "\n",
    "    Example:\n",
    "        result = train_and_evaluate_model(X_train, y_train, X_test, y_test, 'SGDClassifier')\n",
    "    \"\"\"\n",
    "    # Initialize the SGDClassifier classifier with specified parameters\n",
    "    model = SGDClassifier(\n",
    "        loss=\"log_loss\",\n",
    "        max_iter=10000,\n",
    "        n_jobs=-1,\n",
    "        random_state=271828,\n",
    "        class_weight=\"balanced\",\n",
    "    )\n",
    "\n",
    "    # Train the model on the training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict the labels for the test data\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    if verbose:\n",
    "        # Print the label model name and classification metrics if verbose is True\n",
    "        print(f\"\\n\\nLabel Model name: {label_model_name}\")\n",
    "        helpers.classification.print_classification_metrics(y_test, y_test_pred)\n",
    "\n",
    "    # Return the label model name and Matthews correlation coefficient\n",
    "    return {\n",
    "        \"Label Model\": label_model_name + \" + End Model\",\n",
    "        \"Matthews Correlation\": matthews_corrcoef(y_test, y_test_pred),\n",
    "        \"Type\": type_label,\n",
    "    }\n",
    "\n",
    "\n",
    "def evaluate_noisy_labels(\n",
    "    true_labels: Any, predicted_labels: Any, label_model_name: str, verbose: bool = True\n",
    ") -> dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Evaluate the performance of noisy labels against the true labels.\n",
    "\n",
    "    Args:\n",
    "        true_labels (Any): The true labels.\n",
    "        predicted_labels (Any): The predicted labels.\n",
    "        label_model_name (str): Name of the label model.\n",
    "        verbose (bool, optional): Whether to print detailed metrics. Defaults to True.\n",
    "\n",
    "    Returns:\n",
    "        dict[str, Any]: A dictionary containing the label model name and Matthews correlation coefficient.\n",
    "\n",
    "    Example:\n",
    "        result = evaluate_noisy_labels(y_true, y_pred)\n",
    "    \"\"\"\n",
    "    if verbose:\n",
    "        # Print the label model name and classification metrics if verbose is True\n",
    "        print(f\"\\n\\nLabel Model name: {label_model_name}\")\n",
    "        helpers.classification.print_classification_metrics(\n",
    "            true_labels, predicted_labels\n",
    "        )\n",
    "\n",
    "    # Return the label model name and Matthews correlation coefficient\n",
    "    return {\n",
    "        \"Label Model\": label_model_name,\n",
    "        \"Matthews Correlation\": matthews_corrcoef(true_labels, predicted_labels),\n",
    "        \"Type\": \"LM alone\",\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Snorkel Label Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = []\n",
    "\n",
    "# Let's see again the performance of the MajorityLabelVoter and Snorkel MeTaL LabelModel. We'll keep the End Model the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Computing O...\n",
      "INFO:root:Estimating \\mu...\n",
      "  0%|          | 0/1000 [00:00<?, ?epoch/s]INFO:root:[0 epochs]: TRAIN:[loss=0.207]\n",
      "  9%|▉         | 93/1000 [00:00<00:04, 188.13epoch/s]INFO:root:[100 epochs]: TRAIN:[loss=0.044]\n",
      " 19%|█▉        | 188/1000 [00:01<00:04, 172.95epoch/s]INFO:root:[200 epochs]: TRAIN:[loss=0.040]\n",
      " 29%|██▉       | 294/1000 [00:01<00:04, 163.10epoch/s]INFO:root:[300 epochs]: TRAIN:[loss=0.039]\n",
      " 40%|███▉      | 398/1000 [00:02<00:03, 151.50epoch/s]INFO:root:[400 epochs]: TRAIN:[loss=0.039]\n",
      " 50%|████▉     | 496/1000 [00:02<00:03, 150.70epoch/s]INFO:root:[500 epochs]: TRAIN:[loss=0.039]\n",
      " 58%|█████▊    | 579/1000 [00:03<00:01, 288.27epoch/s]INFO:root:[600 epochs]: TRAIN:[loss=0.039]\n",
      " 65%|██████▍   | 649/1000 [00:03<00:00, 402.51epoch/s]INFO:root:[700 epochs]: TRAIN:[loss=0.039]\n",
      " 76%|███████▌  | 759/1000 [00:03<00:00, 459.85epoch/s]INFO:root:[800 epochs]: TRAIN:[loss=0.039]\n",
      " 84%|████████▎ | 835/1000 [00:03<00:00, 545.31epoch/s]INFO:root:[900 epochs]: TRAIN:[loss=0.039]\n",
      "100%|██████████| 1000/1000 [00:03<00:00, 251.62epoch/s]\n",
      "INFO:root:Finished Training\n"
     ]
    }
   ],
   "source": [
    "# Initialize the LabelModel from the Snorkel library\n",
    "# cardinality: number of unique classes in the validation set\n",
    "metal_model = LabelModel(cardinality=len(np.unique(y_valid)), verbose=True)\n",
    "\n",
    "# Fit the LabelModel using the training label matrix (L_train)\n",
    "# n_epochs: number of training epochs\n",
    "# log_freq: frequency of logging during training\n",
    "# seed: random seed for reproducibility\n",
    "# class_balance: prior class distribution\n",
    "metal_model.fit(\n",
    "    L_train, n_epochs=1000, log_freq=100, seed=271828, class_balance=class_balance\n",
    ")\n",
    "\n",
    "# Predict the labels for the training, validation, and test sets using the trained LabelModel\n",
    "# This step uses the learned parameters to infer the most likely labels\n",
    "y_train_metal = metal_model.predict(L_train)\n",
    "y_valid_metal = metal_model.predict(L_valid)\n",
    "y_test_metal = metal_model.predict(L_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Label Model name: Snorkel MeTaL\n",
      "Metric                                   Score\n",
      "=============================================\n",
      "Accuracy Score:                        0.95274\n",
      "Balanced Accuracy Score:               0.94776\n",
      "F1 Score (weighted):                   0.95292\n",
      "Cohen Kappa Score:                     0.88876\n",
      "Matthews Correlation Coefficient:      0.88893\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.92      7050\n",
      "           1       0.97      0.96      0.97     16290\n",
      "\n",
      "    accuracy                           0.95     23340\n",
      "   macro avg       0.94      0.95      0.94     23340\n",
      "weighted avg       0.95      0.95      0.95     23340\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "Class 0 has 457 false negatives and 646 false positives.\n",
      "Class 1 has 646 false negatives and 457 false positives.\n",
      "The total number of errors is 1103 out of 23340 samples (error rate: 0.0473).\n",
      "Predicted      0       1     All\n",
      "True                            \n",
      "0          6,593     457   7,050\n",
      "1            646  15,644  16,290\n",
      "All        7,239  16,101  23,340\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate a model using the training features (X_train) and the labels predicted by the LabelModel (y_train_metal)\n",
    "# The function 'train_and_evaluate_model' trains a machine learning model and evaluates its performance on the test set\n",
    "results_metal_em = train_and_evaluate_model(\n",
    "    X_train, y_train_metal, X_test, y_test, \"Snorkel MeTaL\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Label Model name: Snorkel MeTaL\n",
      "Metric                                   Score\n",
      "=============================================\n",
      "Accuracy Score:                        0.87121\n",
      "Balanced Accuracy Score:               0.80314\n",
      "F1 Score (weighted):                   0.86340\n",
      "Cohen Kappa Score:                     0.66497\n",
      "Matthews Correlation Coefficient:      0.68579\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.63      0.75      7050\n",
      "           1       0.86      0.98      0.91     16290\n",
      "\n",
      "    accuracy                           0.87     23340\n",
      "   macro avg       0.89      0.80      0.83     23340\n",
      "weighted avg       0.88      0.87      0.86     23340\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "Class 0 has 2600 false negatives and 406 false positives.\n",
      "Class 1 has 406 false negatives and 2600 false positives.\n",
      "The total number of errors is 3006 out of 23340 samples (error rate: 0.1288).\n",
      "Predicted      0       1     All\n",
      "True                            \n",
      "0          4,450   2,600   7,050\n",
      "1            406  15,884  16,290\n",
      "All        4,856  18,484  23,340\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the noisy labels predicted by the LabelModel (y_test_metal) against the true test labels (y_test)\n",
    "# The function 'evaluate_noisy_labels' compares the predicted labels to the true labels and returns evaluation metrics\n",
    "results_metal_lm = evaluate_noisy_labels(y_test, y_test_metal, \"Snorkel MeTaL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the MajorityLabelVoter model\n",
    "# cardinality: number of unique classes in the validation set\n",
    "majority_model = MajorityLabelVoter(cardinality=len(np.unique(y_valid)))\n",
    "\n",
    "# Predict the labels for the training, validation, and test sets using the MajorityLabelVoter model\n",
    "# tie_break_policy=\"random\": randomly break ties when multiple labels have the same majority vote\n",
    "y_train_majority = majority_model.predict(L_train, tie_break_policy=\"random\")\n",
    "y_valid_majority = majority_model.predict(L_valid, tie_break_policy=\"random\")\n",
    "y_test_majority = majority_model.predict(L_test, tie_break_policy=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Label Model name: Majority Label Voter\n",
      "Metric                                   Score\n",
      "=============================================\n",
      "Accuracy Score:                        0.94833\n",
      "Balanced Accuracy Score:               0.92895\n",
      "F1 Score (weighted):                   0.94779\n",
      "Cohen Kappa Score:                     0.87501\n",
      "Matthews Correlation Coefficient:      0.87612\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.88      0.91      7050\n",
      "           1       0.95      0.98      0.96     16290\n",
      "\n",
      "    accuracy                           0.95     23340\n",
      "   macro avg       0.95      0.93      0.94     23340\n",
      "weighted avg       0.95      0.95      0.95     23340\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "Class 0 has 846 false negatives and 360 false positives.\n",
      "Class 1 has 360 false negatives and 846 false positives.\n",
      "The total number of errors is 1206 out of 23340 samples (error rate: 0.0517).\n",
      "Predicted      0       1     All\n",
      "True                            \n",
      "0          6,204     846   7,050\n",
      "1            360  15,930  16,290\n",
      "All        6,564  16,776  23,340\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate a model using the training features (X_train) and the labels predicted by the MajorityLabelVoter (y_train_majority)\n",
    "# The function 'train_and_evaluate_model' trains a machine learning model and evaluates its performance on the test set\n",
    "results_majority_em = train_and_evaluate_model(\n",
    "    X_train, y_train_majority, X_test, y_test, \"Majority Label Voter\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Label Model name: Majority Label Voter\n",
      "Metric                                   Score\n",
      "=============================================\n",
      "Accuracy Score:                        0.86272\n",
      "Balanced Accuracy Score:               0.83198\n",
      "F1 Score (weighted):                   0.86198\n",
      "Cohen Kappa Score:                     0.67098\n",
      "Matthews Correlation Coefficient:      0.67122\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.75      0.77      7050\n",
      "           1       0.90      0.91      0.90     16290\n",
      "\n",
      "    accuracy                           0.86     23340\n",
      "   macro avg       0.84      0.83      0.84     23340\n",
      "weighted avg       0.86      0.86      0.86     23340\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "Class 0 has 1732 false negatives and 1472 false positives.\n",
      "Class 1 has 1472 false negatives and 1732 false positives.\n",
      "The total number of errors is 3204 out of 23340 samples (error rate: 0.1373).\n",
      "Predicted      0       1     All\n",
      "True                            \n",
      "0          5,318   1,732   7,050\n",
      "1          1,472  14,818  16,290\n",
      "All        6,790  16,550  23,340\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the noisy labels predicted by the MajorityLabelVoter (y_test_majority) against the true test labels (y_test)\n",
    "# The function 'evaluate_noisy_labels' compares the predicted labels to the true labels and returns evaluation metrics\n",
    "results_majority_lm = evaluate_noisy_labels(\n",
    "    y_test, y_test_majority, \"Majority Label Voter\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append the evaluation results of the LabelModel's noisy labels to the all_results list\n",
    "# results_metal_lm contains the evaluation metrics for the noisy labels predicted by the LabelModel\n",
    "all_results.append(results_metal_lm)\n",
    "\n",
    "# Append the evaluation results of the MajorityLabelVoter's noisy labels to the all_results list\n",
    "# results_majority_lm contains the evaluation metrics for the noisy labels predicted by the MajorityLabelVoter\n",
    "all_results.append(results_majority_lm)\n",
    "\n",
    "# Append the evaluation results of the model trained with the LabelModel's labels to the all_results list\n",
    "all_results.append(results_metal_em)\n",
    "\n",
    "# Append the evaluation results of the model trained with the MajorityLabelVoter's labels to the all_results list\n",
    "all_results.append(results_majority_em)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Label Model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Matthews Correlation",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Type",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "d5aff03b-4a1e-4ee2-b227-cd93e7a5e09f",
       "rows": [
        [
         "2",
         "Snorkel MeTaL + End Model",
         "0.8889251584442059",
         "LM + EM"
        ],
        [
         "3",
         "Majority Label Voter + End Model",
         "0.8761199167917382",
         "LM + EM"
        ],
        [
         "0",
         "Snorkel MeTaL",
         "0.6857925272523081",
         "LM alone"
        ],
        [
         "1",
         "Majority Label Voter",
         "0.6712213834075154",
         "LM alone"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 4
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label Model</th>\n",
       "      <th>Matthews Correlation</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Snorkel MeTaL + End Model</td>\n",
       "      <td>0.888925</td>\n",
       "      <td>LM + EM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Majority Label Voter + End Model</td>\n",
       "      <td>0.876120</td>\n",
       "      <td>LM + EM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Snorkel MeTaL</td>\n",
       "      <td>0.685793</td>\n",
       "      <td>LM alone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Majority Label Voter</td>\n",
       "      <td>0.671221</td>\n",
       "      <td>LM alone</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Label Model  Matthews Correlation      Type\n",
       "2         Snorkel MeTaL + End Model              0.888925   LM + EM\n",
       "3  Majority Label Voter + End Model              0.876120   LM + EM\n",
       "0                     Snorkel MeTaL              0.685793  LM alone\n",
       "1              Majority Label Voter              0.671221  LM alone"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_baseline = pd.DataFrame(all_results)\n",
    "df_baseline.sort_values(by=\"Matthews Correlation\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Label Model name: Full Supervision on Dev Set\n",
      "Metric                                   Score\n",
      "=============================================\n",
      "Accuracy Score:                        0.96071\n",
      "Balanced Accuracy Score:               0.94884\n",
      "F1 Score (weighted):                   0.96053\n",
      "Cohen Kappa Score:                     0.90596\n",
      "Matthews Correlation Coefficient:      0.90621\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.93      7050\n",
      "           1       0.97      0.98      0.97     16290\n",
      "\n",
      "    accuracy                           0.96     23340\n",
      "   macro avg       0.96      0.95      0.95     23340\n",
      "weighted avg       0.96      0.96      0.96     23340\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "Class 0 has 572 false negatives and 345 false positives.\n",
      "Class 1 has 345 false negatives and 572 false positives.\n",
      "The total number of errors is 917 out of 23340 samples (error rate: 0.0393).\n",
      "Predicted      0       1     All\n",
      "True                            \n",
      "0          6,478     572   7,050\n",
      "1            345  15,945  16,290\n",
      "All        6,823  16,517  23,340\n"
     ]
    }
   ],
   "source": [
    "# Let's compare with the performance of a full supervision model trained on the development set (Let's assume we have 1000 labeled samples).\n",
    "\n",
    "# Train and evaluate a fully supervised model using the first 1000 labeled samples from the development set\n",
    "results_full_supervision = train_and_evaluate_model(\n",
    "    X_valid[:1000],\n",
    "    y_valid[:1000],\n",
    "    X_test,\n",
    "    y_test,\n",
    "    \"Full Supervision on Dev Set\",\n",
    "    type_label=\"Full supervision\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Label Model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Matthews Correlation",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Type",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "c5b8447d-7682-4394-99d6-a876e9dba6a3",
       "rows": [
        [
         "4",
         "Full Supervision on Dev Set + End Model",
         "0.9062052593266651",
         "Full supervision"
        ],
        [
         "2",
         "Snorkel MeTaL + End Model",
         "0.8889251584442059",
         "LM + EM"
        ],
        [
         "3",
         "Majority Label Voter + End Model",
         "0.8761199167917382",
         "LM + EM"
        ],
        [
         "0",
         "Snorkel MeTaL",
         "0.6857925272523081",
         "LM alone"
        ],
        [
         "1",
         "Majority Label Voter",
         "0.6712213834075154",
         "LM alone"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label Model</th>\n",
       "      <th>Matthews Correlation</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Full Supervision on Dev Set + End Model</td>\n",
       "      <td>0.906205</td>\n",
       "      <td>Full supervision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Snorkel MeTaL + End Model</td>\n",
       "      <td>0.888925</td>\n",
       "      <td>LM + EM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Majority Label Voter + End Model</td>\n",
       "      <td>0.876120</td>\n",
       "      <td>LM + EM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Snorkel MeTaL</td>\n",
       "      <td>0.685793</td>\n",
       "      <td>LM alone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Majority Label Voter</td>\n",
       "      <td>0.671221</td>\n",
       "      <td>LM alone</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Label Model  Matthews Correlation  \\\n",
       "4  Full Supervision on Dev Set + End Model              0.906205   \n",
       "2                Snorkel MeTaL + End Model              0.888925   \n",
       "3         Majority Label Voter + End Model              0.876120   \n",
       "0                            Snorkel MeTaL              0.685793   \n",
       "1                     Majority Label Voter              0.671221   \n",
       "\n",
       "               Type  \n",
       "4  Full supervision  \n",
       "2           LM + EM  \n",
       "3           LM + EM  \n",
       "0          LM alone  \n",
       "1          LM alone  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Append the results of the fully supervised model to the all_results list\n",
    "# This list contains the evaluation metrics for different models and labeling strategies\n",
    "all_results.append(results_full_supervision)\n",
    "\n",
    "# Create a DataFrame from the all_results list for easier analysis and comparison\n",
    "df_baseline = pd.DataFrame(all_results)\n",
    "\n",
    "# Sort the DataFrame by the 'Matthews Correlation' column in descending order\n",
    "# This helps in identifying the best performing model based on the Matthews Correlation metric\n",
    "df_baseline.sort_values(by=\"Matthews Correlation\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other Label Models\n",
    "\n",
    "Programmatic Weak Supervision (PWS) uses *labeling functions* (LFs) to generate noisy labels from simple rules or heuristics. Combining these outputs—especially when the signals may conflict—is a critical challenge in obtaining high-quality labels.\n",
    "\n",
    "In earlier notebooks, we used the Metal Label Model from Snorkel to aggregate LF outputs. In this section, we review alternative label models that support label aggregation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## The Hyper Label Model (HyperLM) for Programmatic Weak Supervision\n",
    "\n",
    "HyperLM addresses label aggregation challenges by learning a dataset-agnostic model that can be applied directly to new datasets without additional training or parameter tuning. Unlike traditional label models that require retraining for each new dataset, HyperLM approximates an optimal solution through deep learning.\n",
    "\n",
    "### Key Components of HyperLM\n",
    "\n",
    "1. **Label Matrix ($X$)**\n",
    "\n",
    "   - **Definition:** The label matrix $X$ is an $n \\times m$ matrix containing outputs from $m$ LFs applied to $n$ data points.\n",
    "   - **Element Meaning:** Each entry $X_{i,j}$ represents the label given by the $j$-th LF for the $i$-th data point, using the following encoding:\n",
    "     - **$+1$:** Positive label\n",
    "     - **$-1$:** Negative label\n",
    "     - **$0$:** Abstention (the LF does not provide a label)\n",
    "\n",
    "2. **Ground Truth Labels ($y$)**\n",
    "\n",
    "   - **Goal:** Infer the true label vector $y \\in \\{+1, -1\\}^n$.\n",
    "   - **Challenge:** In weak supervision, the true label vector $y$ is typically not observed.\n",
    "\n",
    "3. **Better-Than-Random Assumption**\n",
    "\n",
    "   - **Concept:** Most LFs for each class perform better than random guessing. Mathematically, let $g(X, y, j, c)$ be an indicator that equals 1 if the $j$-th LF is better-than-random for class $c$, and 0 otherwise. The assumption is expressed as:\n",
    "\n",
    "     $$\n",
    "     \\frac{1}{m} \\sum_{j=0}^{m-1} g(X, y, j, +1) > \\frac{1}{2} \\quad \\text{and} \\quad \\frac{1}{m} \\sum_{j=0}^{m-1} g(X, y, j, -1) > \\frac{1}{2}\n",
    "     $$\n",
    "\n",
    "4. **Valid Label Vectors**\n",
    "\n",
    "   - A label vector $y$ is deemed *valid* if it satisfies the better-than-random assumption. All valid candidate vectors form the set $U_y(X)$.\n",
    "\n",
    "5. **Optimal Analytical Solution**\n",
    "\n",
    "   - In theory, the optimal estimation of $y$ from $X$ is given by the average of all valid candidate vectors:\n",
    "\n",
    "     $$\n",
    "     h^*(X) = \\frac{1}{|U_y(X)|} \\sum_{y \\in U_y(X)} y\n",
    "     $$\n",
    "\n",
    "   - This averaging minimizes the average error across all possible outcomes.\n",
    "\n",
    "6. **Approximating the Optimal Solution**\n",
    "\n",
    "   - Direct computation is intractable for large datasets. HyperLM uses a Graph Neural Network (GNN) to approximate the analytical solution, effectively handling large-scale problems.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### HyperLM Architecture\n",
    "\n",
    "HyperLM uses a GNN-based architecture to address several real-world requirements:\n",
    "\n",
    "1. **Handling Arbitrary Input Sizes**\n",
    "\n",
    "   - **Feature:** The model accepts varying numbers of data points and LFs.\n",
    "   - **Method:** The label matrix $X$ is represented as graph, enabling the GNN to work with inputs of arbitrary size.\n",
    "\n",
    "2. **LF Permutation Invariance**\n",
    "\n",
    "   - **Requirement:** The output should remain unchanged if the order of LFs is shuffled.\n",
    "   - **Formalization:** For any permutation matrix $P_m \\in \\mathbb{R}^{m \\times m}$, the model must satisfy:\n",
    "\n",
    "     $$\n",
    "     h(XP_m) = h(X)\n",
    "     $$\n",
    "\n",
    "3. **Data Point Permutation Equivariance**\n",
    "\n",
    "   - **Requirement:** Shuffling data points should produce a corresponding permutation in output labels.\n",
    "   - **Formalization:** For any permutation matrix $P_n \\in \\mathbb{R}^{n \\times n}$:\n",
    "\n",
    "     $$\n",
    "     h(P_n X) = P_n h(X)\n",
    "     $$\n",
    "\n",
    "   - The GNN's architecture inherently maintains this property.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Dataset-Agnostic Learning\n",
    "\n",
    "A central benefit of HyperLM is its ability to work with new datasets without retraining. The process includes:\n",
    "\n",
    "1. **Synthetic Data Generation**\n",
    "\n",
    "   - **Procedure:** Train HyperLM with a large dataset of synthetically generated label matrices paired with approximated optimal label vectors.\n",
    "   - This synthetic generation uniformly samples valid label vectors, ensuring the model learns a general aggregation strategy.\n",
    "\n",
    "2. **GNN-based Processing**\n",
    "\n",
    "   - **Graph Representation:** Data points and LFs are nodes in the graph. Edges connect data points with respective LF outputs.\n",
    "   - **Message Passing:** Through message exchanges between nodes, the GNN learns the relationships required for effective label aggregation.\n",
    "\n",
    "3. **Single Forward Pass Inference**\n",
    "\n",
    "   - **Efficiency:** Once trained, the model produces label predictions in a single forward pass, requiring no dataset-specific parameter adjustment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Advantages of HyperLM\n",
    "\n",
    "- **Improved Accuracy:** Provides high label accuracy across varied datasets.\n",
    "- **Computational Efficiency:** Faster processing compared to methods needing dataset-specific training.\n",
    "- **Interactive LF Development:** Allows quick evaluation of the effects of new or changed LFs.\n",
    "- **Scalability:** Suitable for large datasets and complex labeling tasks, relevant in industrial applications.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Training Approaches for HyperLM\n",
    "\n",
    "HyperLM supports both unsupervised and semi-supervised training modes.\n",
    "\n",
    "### Unsupervised HyperLM\n",
    "\n",
    "In the unsupervised setting, HyperLM relies entirely on synthetic data:\n",
    "\n",
    "1. **Data Generation**\n",
    "\n",
    "   - **Sampling:** Generate a label matrix $X$ by randomly choosing $n$ and $m$ from defined ranges.\n",
    "   - **Validity Check:** Pair $X$ with a label vector $y$ that meets the better-than-random assumption.\n",
    "  \n",
    "2. **Training Objective**\n",
    "\n",
    "   - **Loss Function:** Minimize the cross-entropy loss over the synthetic dataset $D$:\n",
    "\n",
    "     $$\n",
    "     \\mathcal{L}(h; D) = \\frac{1}{|D|} \\sum_{i=1}^{|D|} \\sum_{j=1}^{n} \\ell_{\\text{CE}}(h(X_i)[j], y_i[j])\n",
    "     $$\n",
    "\n",
    "     where $\\ell_{\\text{CE}}(\\cdot)\\ is the cross-entropy loss.\n",
    "\n",
    "3. **Model Architecture**\n",
    "\n",
    "   - Use a multi-layer GNN to aggregate message passing.\n",
    "   - Pool embeddings from the final layer and process them with a multilayer perceptron (MLP) to generate outputs.\n",
    "\n",
    "4. **Inference**\n",
    "\n",
    "   - For any new dataset, a single forward pass yields the predicted labels.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Semi-supervised HyperLM\n",
    "\n",
    "Fine-tuning HyperLM with a small set of ground truth labels is handled as follows:\n",
    "\n",
    "1. **Pretraining**\n",
    "\n",
    "   - **Initialization:** Start with weights from the unsupervised HyperLM trained on synthetic data.\n",
    "\n",
    "2. **Fine-Tuning Objective**\n",
    "\n",
    "   - **Loss Function:** Minimize the cross-entropy loss over the ground truth labeled set $D_{\\text{gt}}$:\n",
    "\n",
    "     $$\n",
    "     \\mathcal{L}_{\\text{fine-tune}}(h; D_{\\text{gt}}) = \\sum_{i \\in I} \\ell_{\\text{CE}}(h(X)[i], y[i])\n",
    "     $$\n",
    "\n",
    "   - Here, $I$ denotes the indices of data points with labels.\n",
    "\n",
    "3. **Learning Rate Adjustment**\n",
    "\n",
    "   - Use a smaller learning rate to reduce overfitting during fine-tuning. The number of fine-tuning epochs can be adjusted based on the size of the labeled set.\n",
    "\n",
    "4. **Inference**\n",
    "\n",
    "   - After fine-tuning, obtain predicted labels with a single forward pass across the new dataset.\n",
    "\n",
    "> **Note:** The choice of training mode (unsupervised vs. semi-supervised) depends on the availability of ground truth labels. In practical applications, unsupervised training may be combined with limited ground truth data for quicker adaptation to specific tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((85831,), (23340,), (85831, 768), (23340, 768))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from hyperlm import HyperLabelModel\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "with torch.serialization.safe_globals(\n",
    "    [np.core.multiarray.scalar, np.dtype, np.dtypes.Float64DType]\n",
    "):  # This is to avoid the error from torch >=2.6\n",
    "\n",
    "    # Initialize the HyperLabelModel for unsupervised learning\n",
    "    # device='cpu' specifies that the model should run on the CPU\n",
    "    hyper_lm_unsupervised_model = HyperLabelModel(device=\"cpu\")\n",
    "\n",
    "# Infer the labels for the training set using the unsupervised HyperLabelModel\n",
    "# L_train is the label matrix for the training set\n",
    "y_train_hyper_lm_unsupervised = hyper_lm_unsupervised_model.infer(L_train)\n",
    "\n",
    "# Infer the labels for the test set using the unsupervised HyperLabelModel\n",
    "# L_test is the label matrix for the test set\n",
    "y_test_hyper_lm_unsupervised = hyper_lm_unsupervised_model.infer(L_test)\n",
    "\n",
    "# Display the shapes of the inferred labels and the feature matrices\n",
    "# This helps in verifying that the dimensions of the inferred labels match the feature matrices\n",
    "y_train_hyper_lm_unsupervised.shape, y_test_hyper_lm_unsupervised.shape, X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Label Model name: HyperLabelModel Unsupervised\n",
      "Metric                                   Score\n",
      "=============================================\n",
      "Accuracy Score:                        0.93089\n",
      "Balanced Accuracy Score:               0.93492\n",
      "F1 Score (weighted):                   0.93192\n",
      "Cohen Kappa Score:                     0.84145\n",
      "Matthews Correlation Coefficient:      0.84432\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89      7050\n",
      "           1       0.97      0.92      0.95     16290\n",
      "\n",
      "    accuracy                           0.93     23340\n",
      "   macro avg       0.91      0.93      0.92     23340\n",
      "weighted avg       0.94      0.93      0.93     23340\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "Class 0 has 387 false negatives and 1226 false positives.\n",
      "Class 1 has 1226 false negatives and 387 false positives.\n",
      "The total number of errors is 1613 out of 23340 samples (error rate: 0.0691).\n",
      "Predicted      0       1     All\n",
      "True                            \n",
      "0          6,663     387   7,050\n",
      "1          1,226  15,064  16,290\n",
      "All        7,889  15,451  23,340\n",
      "\n",
      "\n",
      "Label Model name: HyperLabelModel Unsupervised\n",
      "Metric                                   Score\n",
      "=============================================\n",
      "Accuracy Score:                        0.87888\n",
      "Balanced Accuracy Score:               0.82091\n",
      "F1 Score (weighted):                   0.87333\n",
      "Cohen Kappa Score:                     0.69080\n",
      "Matthews Correlation Coefficient:      0.70402\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.67      0.77      7050\n",
      "           1       0.87      0.97      0.92     16290\n",
      "\n",
      "    accuracy                           0.88     23340\n",
      "   macro avg       0.89      0.82      0.84     23340\n",
      "weighted avg       0.88      0.88      0.87     23340\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "Class 0 has 2295 false negatives and 532 false positives.\n",
      "Class 1 has 532 false negatives and 2295 false positives.\n",
      "The total number of errors is 2827 out of 23340 samples (error rate: 0.1211).\n",
      "Predicted      0       1     All\n",
      "True                            \n",
      "0          4,755   2,295   7,050\n",
      "1            532  15,758  16,290\n",
      "All        5,287  18,053  23,340\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate a model using the training features (X_train) and the labels inferred by the unsupervised HyperLabelModel (y_train_hyper_lm_unsupervised)\n",
    "# The function 'train_and_evaluate_model' trains a machine learning model and evaluates its performance on the test set\n",
    "results_hyper_lm_unsupervised_em = train_and_evaluate_model(\n",
    "    X_train,\n",
    "    y_train_hyper_lm_unsupervised,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    \"HyperLabelModel Unsupervised\",\n",
    ")\n",
    "\n",
    "# Evaluate the noisy labels inferred by the unsupervised HyperLabelModel (y_test_hyper_lm_unsupervised) against the true test labels (y_test)\n",
    "# The function 'evaluate_noisy_labels' compares the inferred labels to the true labels and returns evaluation metrics\n",
    "results_hyper_lm_unsupervised_lm = evaluate_noisy_labels(\n",
    "    y_test, y_test_hyper_lm_unsupervised, \"HyperLabelModel Unsupervised\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the HyperLabelModel for semi-supervised learning\n",
    "with torch.serialization.safe_globals(\n",
    "    [np.core.multiarray.scalar, np.dtype, np.dtypes.Float64DType]\n",
    "):  # This is to avoid the error from torch >=2.6\n",
    "    hyper_lm_semi_supervised_model = HyperLabelModel(device=\"cpu\")\n",
    "\n",
    "# Concatenate the training and validation label matrices\n",
    "# L_train: label matrix for the training set\n",
    "# L here will be train + valid (remember this is an Semi-Supervised Learning approach). Let's assume we have 1000 labeled samples.\n",
    "# L_valid[:1000]: first 1000 samples from the validation set (assumed to be labeled)\n",
    "L_concat = np.concatenate([L_train, L_valid[:1000]])\n",
    "\n",
    "# Create index arrays for the training and validation sets within the concatenated label matrix\n",
    "# idx_train: indices for the training set\n",
    "# idx_valid: indices for the validation set within the concatenated matrix\n",
    "idx_train = np.arange(L_train.shape[0])\n",
    "idx_valid = np.arange(L_train.shape[0], L_concat.shape[0])\n",
    "\n",
    "# Infer the labels for the training set using the semi-supervised HyperLabelModel\n",
    "# L_concat: concatenated label matrix\n",
    "# y_indices=idx_valid: indices of the labeled validation samples\n",
    "# y_vals=y_valid[:1000]: true labels for the first 1000 validation samples\n",
    "with torch.serialization.safe_globals(\n",
    "    [np.core.multiarray.scalar, np.dtype, np.dtypes.Float64DType]\n",
    "):  # This is to avoid the error from torch >=2.6\n",
    "    y_train_hyper_lm_semi_supervised = hyper_lm_semi_supervised_model.infer(\n",
    "        L_concat, y_indices=idx_valid, y_vals=y_valid[:1000]\n",
    "    )\n",
    "\n",
    "# Extract the inferred labels for the training set from the concatenated results\n",
    "y_train_hyper_lm_semi_supervised = y_train_hyper_lm_semi_supervised[idx_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the test and validation label matrices\n",
    "# L_test: label matrix for the test set\n",
    "# L_valid[:1000]: first 1000 samples from the validation set (assumed to be labeled)\n",
    "L_concat_2 = np.concatenate([L_test, L_valid[:1000]])\n",
    "\n",
    "# Create index arrays for the test and validation sets within the concatenated label matrix\n",
    "# idx_test: indices for the test set\n",
    "# idx_valid: indices for the validation set within the concatenated matrix\n",
    "idx_test = np.arange(L_test.shape[0])\n",
    "idx_valid = np.arange(L_test.shape[0], L_concat_2.shape[0])\n",
    "\n",
    "# Infer the labels for the test set using the semi-supervised HyperLabelModel\n",
    "# L_concat_2: concatenated label matrix\n",
    "# y_indices=idx_valid: indices of the labeled validation samples\n",
    "# y_vals=y_valid[:1000]: true labels for the first 1000 validation samples\n",
    "with torch.serialization.safe_globals(\n",
    "    [np.core.multiarray.scalar, np.dtype, np.dtypes.Float64DType]\n",
    "):  # This is to avoid the error from torch >=2.6\n",
    "    y_test_hyper_lm_semi_supervised = hyper_lm_semi_supervised_model.infer(\n",
    "        L_concat_2, y_indices=idx_valid, y_vals=y_valid[:1000]\n",
    "    )\n",
    "\n",
    "# Extract the inferred labels for the test set from the concatenated results\n",
    "y_test_hyper_lm_semi_supervised = y_test_hyper_lm_semi_supervised[idx_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Label Model name: HyperLabelModel Semi-Supervised\n",
      "Metric                                   Score\n",
      "=============================================\n",
      "Accuracy Score:                        0.93016\n",
      "Balanced Accuracy Score:               0.91586\n",
      "F1 Score (weighted):                   0.93007\n",
      "Cohen Kappa Score:                     0.83393\n",
      "Matthews Correlation Coefficient:      0.83394\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.88      0.88      7050\n",
      "           1       0.95      0.95      0.95     16290\n",
      "\n",
      "    accuracy                           0.93     23340\n",
      "   macro avg       0.92      0.92      0.92     23340\n",
      "weighted avg       0.93      0.93      0.93     23340\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "Class 0 has 848 false negatives and 782 false positives.\n",
      "Class 1 has 782 false negatives and 848 false positives.\n",
      "The total number of errors is 1630 out of 23340 samples (error rate: 0.0698).\n",
      "Predicted      0       1     All\n",
      "True                            \n",
      "0          6,202     848   7,050\n",
      "1            782  15,508  16,290\n",
      "All        6,984  16,356  23,340\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate a model using the training features (X_train) and the labels inferred by the semi-supervised HyperLabelModel (y_train_hyper_lm_semi_supervised)\n",
    "# The function 'train_and_evaluate_model' trains a machine learning model and evaluates its performance on the test set\n",
    "results_hyper_lm_semi_supervised_em = train_and_evaluate_model(\n",
    "    X_train,\n",
    "    y_train_hyper_lm_semi_supervised,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    \"HyperLabelModel Semi-Supervised\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Label Model name: HyperLabelModel Semi-Supervised\n",
      "Metric                                   Score\n",
      "=============================================\n",
      "Accuracy Score:                        0.84773\n",
      "Balanced Accuracy Score:               0.86915\n",
      "F1 Score (weighted):                   0.85284\n",
      "Cohen Kappa Score:                     0.67152\n",
      "Matthews Correlation Coefficient:      0.68977\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.92      0.79      7050\n",
      "           1       0.96      0.82      0.88     16290\n",
      "\n",
      "    accuracy                           0.85     23340\n",
      "   macro avg       0.82      0.87      0.83     23340\n",
      "weighted avg       0.88      0.85      0.85     23340\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "Class 0 has 541 false negatives and 3013 false positives.\n",
      "Class 1 has 3013 false negatives and 541 false positives.\n",
      "The total number of errors is 3554 out of 23340 samples (error rate: 0.1523).\n",
      "Predicted      0       1     All\n",
      "True                            \n",
      "0          6,509     541   7,050\n",
      "1          3,013  13,277  16,290\n",
      "All        9,522  13,818  23,340\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the noisy labels inferred by the semi-supervised HyperLabelModel (y_test_hyper_lm_semi_supervised) against the true test labels (y_test)\n",
    "# The function 'evaluate_noisy_labels' compares the inferred labels to the true labels and returns evaluation metrics\n",
    "results_hyper_lm_semi_supervised_lm = evaluate_noisy_labels(\n",
    "    y_test, y_test_hyper_lm_semi_supervised, \"HyperLabelModel Semi-Supervised\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Label Model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Matthews Correlation",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Type",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "e52ff574-48a1-4b1b-8f05-30c54302da2e",
       "rows": [
        [
         "4",
         "Full Supervision on Dev Set + End Model",
         "0.9062052593266651",
         "Full supervision"
        ],
        [
         "2",
         "Snorkel MeTaL + End Model",
         "0.8889251584442059",
         "LM + EM"
        ],
        [
         "3",
         "Majority Label Voter + End Model",
         "0.8761199167917382",
         "LM + EM"
        ],
        [
         "5",
         "HyperLabelModel Unsupervised + End Model",
         "0.8443216796321857",
         "LM + EM"
        ],
        [
         "7",
         "HyperLabelModel Semi-Supervised + End Model",
         "0.8339443855395706",
         "LM + EM"
        ],
        [
         "6",
         "HyperLabelModel Unsupervised",
         "0.7040155349376804",
         "LM alone"
        ],
        [
         "8",
         "HyperLabelModel Semi-Supervised",
         "0.6897673717851329",
         "LM alone"
        ],
        [
         "0",
         "Snorkel MeTaL",
         "0.6857925272523081",
         "LM alone"
        ],
        [
         "1",
         "Majority Label Voter",
         "0.6712213834075154",
         "LM alone"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 9
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label Model</th>\n",
       "      <th>Matthews Correlation</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Full Supervision on Dev Set + End Model</td>\n",
       "      <td>0.906205</td>\n",
       "      <td>Full supervision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Snorkel MeTaL + End Model</td>\n",
       "      <td>0.888925</td>\n",
       "      <td>LM + EM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Majority Label Voter + End Model</td>\n",
       "      <td>0.876120</td>\n",
       "      <td>LM + EM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HyperLabelModel Unsupervised + End Model</td>\n",
       "      <td>0.844322</td>\n",
       "      <td>LM + EM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HyperLabelModel Semi-Supervised + End Model</td>\n",
       "      <td>0.833944</td>\n",
       "      <td>LM + EM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HyperLabelModel Unsupervised</td>\n",
       "      <td>0.704016</td>\n",
       "      <td>LM alone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HyperLabelModel Semi-Supervised</td>\n",
       "      <td>0.689767</td>\n",
       "      <td>LM alone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Snorkel MeTaL</td>\n",
       "      <td>0.685793</td>\n",
       "      <td>LM alone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Majority Label Voter</td>\n",
       "      <td>0.671221</td>\n",
       "      <td>LM alone</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Label Model  Matthews Correlation  \\\n",
       "4      Full Supervision on Dev Set + End Model              0.906205   \n",
       "2                    Snorkel MeTaL + End Model              0.888925   \n",
       "3             Majority Label Voter + End Model              0.876120   \n",
       "5     HyperLabelModel Unsupervised + End Model              0.844322   \n",
       "7  HyperLabelModel Semi-Supervised + End Model              0.833944   \n",
       "6                 HyperLabelModel Unsupervised              0.704016   \n",
       "8              HyperLabelModel Semi-Supervised              0.689767   \n",
       "0                                Snorkel MeTaL              0.685793   \n",
       "1                         Majority Label Voter              0.671221   \n",
       "\n",
       "               Type  \n",
       "4  Full supervision  \n",
       "2           LM + EM  \n",
       "3           LM + EM  \n",
       "5           LM + EM  \n",
       "7           LM + EM  \n",
       "6          LM alone  \n",
       "8          LM alone  \n",
       "0          LM alone  \n",
       "1          LM alone  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results.append(results_hyper_lm_unsupervised_em)\n",
    "all_results.append(results_hyper_lm_unsupervised_lm)\n",
    "all_results.append(results_hyper_lm_semi_supervised_em)\n",
    "all_results.append(results_hyper_lm_semi_supervised_lm)\n",
    "\n",
    "df_baseline = pd.DataFrame(all_results)\n",
    "\n",
    "df_baseline.sort_values(by=\"Matthews Correlation\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Dawid & Skene Model for Reliable Label Aggregation\n",
    "\n",
    "The Dawid & Skene (DS) model, introduced in 1979 ([source](https://www.jstor.org/stable/234680)), is a probabilistic framework for inferring the likely true labels for items when the observed labels come from multiple annotators with unknown reliability. This model is useful in situations where annotations are noisy, such as in crowdsourced settings or when using labeling functions in weak supervision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Motivation: Addressing Annotator Variability\n",
    "\n",
    "When collecting annotations, especially through crowdsourcing, the quality of the labels can vary significantly between annotators. Consider an image classification task with two classes, \"cat\" and \"dog.\" Some annotators may have difficulty distinguishing between similar breeds or might misinterpret an image, while others deliver high-quality annotations consistently. The DS model handles these discrepancies by simultaneously estimating the true labels and the reliability (error rates) of individual annotators. This approach extends naturally to weak supervision, where labeling functions (LFs) act as annotators that provide possibly noisy labels.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Components\n",
    "\n",
    "The DS model formulates the problem in a probabilistic manner with the following elements:\n",
    "\n",
    "1. **True Labels ($Z$)**\n",
    "   - Each item $i$ has an unobserved true label $Z_i$.\n",
    "   - For a dataset with $N$ items and $K$ classes, $Z_i \\in \\{1, 2, \\dots, K\\}$.\n",
    "\n",
    "2. **Observed Labels ($X$)**\n",
    "   - The observed labels come from $M$ annotators. These are represented as matrix $X$ with entries $X_{ij}$, where $X_{ij}$ is the label given by annotator $j$ for item $i$.\n",
    "\n",
    "3. **Annotator Error Rates ($\\pi^{(j)}$)**\n",
    "   - Each annotator $j$ is characterized by a confusion matrix $\\pi^{(j)}$.\n",
    "   - The entry $\\pi^{(j)}_{kl}$ represents the probability that annotator $j$ assigns label $l$ when the true label is $k$. These matrices capture the reliability and error patterns of each annotator.\n",
    "\n",
    "4. **Class Priors ($\\pi_k$)**\n",
    "   - These are the prior probabilities of each class $k$ in the dataset.\n",
    "   - They summarize our initial belief about the distribution of the true labels before observing any data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Assumptions\n",
    "\n",
    "The DS model is based on a few key assumptions:\n",
    "\n",
    "- **Conditional Independence:**  \n",
    " Given the true label $Z_i$, the labels provided by different annotators are independent. This is expressed as:\n",
    "\n",
    "  $$\n",
    "  P(X_{i1}, X_{i2}, \\dots, X_{iM} \\mid Z_i) = \\prod_{j=1}^M P(X_{ij} \\mid Z_i)\n",
    "  $$\n",
    "\n",
    "- **Stationary Annotator Behavior:**  \n",
    " An annotator's error rates, as described by their confusion matrix, are assumed to remain constant across all items. Although this assumption simplifies the model, it may not always hold if annotator performance varies with item characteristics.\n",
    "\n",
    "- **Fixed Set of Classes:**  \n",
    " The set of possible labels is assumed to be known and remains constant throughout the process.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Estimation with the Expectation-Maximization (EM) Algorithm\n",
    "\n",
    "The DS model employs the EM algorithm to estimate both the true labels and the parameters (confusion matrices and class priors). The process involves the following steps:\n",
    "\n",
    "#### 1. Initialization\n",
    "- **Parameter Setup:**  \n",
    " Initiate with estimates for the confusion matrices $\\pi^{(j)}$ and the class priors $\\pi_k$. Often, these are set uniformly or based on the distribution of observed labels.\n",
    "\n",
    "#### 2. E-Step (Expectation)\n",
    "- **Posterior Calculation:**  \n",
    " For each item $i$ and each class $k$, calculate the posterior probability that the true label is $k$ given the observed labels:\n",
    "\n",
    "  $$\n",
    "  P(Z_i = k \\mid X_i, \\{\\pi^{(j)}\\}) = \\frac{\\pi_k \\prod_{j=1}^M \\pi^{(j)}_{k, X_{ij}}}{\\sum_{k'=1}^{K} \\pi_{k'} \\prod_{j=1}^M \\pi^{(j)}_{k', X_{ij}}}\n",
    "  $$\n",
    "\n",
    "  This probability weighs the evidence from all annotators based on their estimated reliability.\n",
    "\n",
    "#### 3. M-Step (Maximization)\n",
    "- **Update Confusion Matrices:**  \n",
    " Adjust the entries of each annotator's confusion matrix according to:\n",
    "\n",
    "  $$\n",
    "  \\pi^{(j)}_{kl} = \\frac{\\sum_{i=1}^N P(Z_i = k \\mid X_i, \\{\\pi^{(j)}\\}) \\cdot \\mathbb{I}(X_{ij} = l)}{\\sum_{i=1}^N P(Z_i = k \\mid X_i, \\{\\pi^{(j)}\\})}\n",
    "  $$\n",
    "\n",
    "  Here, $\\mathbb{I}(X_{ij} = l)$ is an indicator function that equals1 if $X_{ij} = l$ and0 otherwise.\n",
    "\n",
    "- **Update Class Priors:**\n",
    "\n",
    "  $$\n",
    "  \\pi_k = \\frac{1}{N} \\sum_{i=1}^N P(Z_i = k \\mid X_i, \\{\\pi^{(j)}\\})\n",
    "  $$\n",
    "\n",
    "#### 4. Iteration\n",
    "- **Convergence:**  \n",
    " Repeat the E-Step and M-Step iteratively until the parameters stabilize (i.e., changes in the parameters fall below a predefined threshold).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Instinctive Understanding\n",
    "\n",
    "> **Note:** The DS model weighs annotator contributions based on their estimated reliability. Annotators with high consensus with inferred true labels have higher influence. In practice, this means that if several annotators frequently agree (and are later estimated as reliable), their votes contribute more strongly to the final label decision. Pay attention because here we are not using human annotators, but labeling functions. If labeling functions are correlated, they will have a higher influence on the final label decision, even if they are noisy.\n",
    "\n",
    "- **Estimating Reliability:**  \n",
    " The confusion matrices serve as measure of each annotator’s accuracy. Annotators whose mistakes rarely deviate from the true labels are considered more reliable.\n",
    "  \n",
    "- **Aggregating Noisy Labels:**  \n",
    " Rather than treating all annotators equally, the DS model uses the reliability estimates to combine their responses, producing more accurate true label estimates.\n",
    "\n",
    "### Practical Considerations\n",
    "\n",
    "- **Multiple Annotations per Item:**  \n",
    " The model benefits when each item is labeled by multiple annotators, as more data helps in reliably estimating both the true label and the annotators' error characteristics.\n",
    "\n",
    "- **Identifiability Issues:**  \n",
    " When there are no ground truth labels, several parameter configurations might explain the observed data similarly. Including a small set of known true labels can reduce ambiguity in the estimates.\n",
    "\n",
    "- **Sensitivity to Initialization:**  \n",
    " The EM algorithm may converge to a local minimum depending on the initial parameter values. Running the algorithm multiple times with different initializations or using informed initialization strategies can improve the robustness of the outcomes.\n",
    "\n",
    "- **Applications Beyond Crowdsourcing:**  \n",
    " The DS model also adapts to weak supervision scenarios, where labeling functions, viewed as annotators, produce labels for training models. In such cases, understanding and modeling the error rates of these functions becomes critical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jacob/.cache/pypoetry/virtualenvs/imd3011-datacentric-ai-ZY2qswVr-py3.12/lib/python3.12/site-packages/flyingsquid/label_model.py:324: SyntaxWarning: invalid escape sequence '\\l'\n",
      "  '''Compute the marginal probabilities of each clique and separator set in the junction tree.\n",
      "/home/jacob/.cache/pypoetry/virtualenvs/imd3011-datacentric-ai-ZY2qswVr-py3.12/lib/python3.12/site-packages/flyingsquid/label_model.py:713: SyntaxWarning: invalid escape sequence '\\l'\n",
      "  '''Predict the probabilities of the Y's given the outputs of the LF's.\n",
      "/home/jacob/.cache/pypoetry/virtualenvs/imd3011-datacentric-ai-ZY2qswVr-py3.12/lib/python3.12/site-packages/flyingsquid/label_model.py:863: SyntaxWarning: invalid escape sequence '\\l'\n",
      "  '''Predict the value of the Y's that best fits the outputs of the LF's.\n",
      "/home/jacob/.cache/pypoetry/virtualenvs/imd3011-datacentric-ai-ZY2qswVr-py3.12/lib/python3.12/site-packages/flyingsquid/label_model.py:890: SyntaxWarning: invalid escape sequence '\\l'\n",
      "  '''Predict the probabilities of the Y's given the outputs of the LF's, marginalizing out all the\n",
      "/home/jacob/.cache/pypoetry/virtualenvs/imd3011-datacentric-ai-ZY2qswVr-py3.12/lib/python3.12/site-packages/pgmpy/factors/base.py:80: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  \"\"\"\n",
      "/home/jacob/.cache/pypoetry/virtualenvs/imd3011-datacentric-ai-ZY2qswVr-py3.12/lib/python3.12/site-packages/pgmpy/extern/tabulate.py:151: SyntaxWarning: invalid escape sequence '\\h'\n",
      "  return \"\\\\begin{tabular}{\" + tabular_columns_fmt + \"}\\n\\hline\"\n",
      "/home/jacob/.cache/pypoetry/virtualenvs/imd3011-datacentric-ai-ZY2qswVr-py3.12/lib/python3.12/site-packages/pgmpy/extern/tabulate.py:256: SyntaxWarning: invalid escape sequence '\\['\n",
      "  _invisible_codes = re.compile(\"\\x1b\\[\\d*m\")  # ANSI color codes\n",
      "/home/jacob/.cache/pypoetry/virtualenvs/imd3011-datacentric-ai-ZY2qswVr-py3.12/lib/python3.12/site-packages/pgmpy/extern/tabulate.py:257: SyntaxWarning: invalid escape sequence '\\['\n",
      "  _invisible_codes_bytes = re.compile(b\"\\x1b\\[\\d*m\")  # ANSI color codes\n",
      "/home/jacob/.cache/pypoetry/virtualenvs/imd3011-datacentric-ai-ZY2qswVr-py3.12/lib/python3.12/site-packages/pgmpy/models/MarkovNetwork.py:611: SyntaxWarning: invalid escape sequence '\\p'\n",
      "  \"\"\"\n",
      "/home/jacob/.cache/pypoetry/virtualenvs/imd3011-datacentric-ai-ZY2qswVr-py3.12/lib/python3.12/site-packages/pgmpy/models/MarkovNetwork.py:725: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  \"\"\"\n",
      "/home/jacob/.cache/pypoetry/virtualenvs/imd3011-datacentric-ai-ZY2qswVr-py3.12/lib/python3.12/site-packages/pgmpy/models/FactorGraph.py:404: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  \"\"\"\n",
      "/home/jacob/.cache/pypoetry/virtualenvs/imd3011-datacentric-ai-ZY2qswVr-py3.12/lib/python3.12/site-packages/pgmpy/models/SEM.py:624: SyntaxWarning: invalid escape sequence '\\g'\n",
      "  \"\"\"\n",
      "/home/jacob/.cache/pypoetry/virtualenvs/imd3011-datacentric-ai-ZY2qswVr-py3.12/lib/python3.12/site-packages/numba/np/ufunc/parallel.py:371: NumbaWarning: The TBB threading layer requires TBB version 2021 update 6 or later i.e., TBB_INTERFACE_VERSION >= 12060. Found TBB_INTERFACE_VERSION = 12050. The TBB threading layer is disabled.\n",
      "  warnings.warn(problem)\n",
      "  0%|          | 26/10000 [00:02<19:01,  8.74it/s] \n"
     ]
    }
   ],
   "source": [
    "from helpers.labelmodels import DawidSkene\n",
    "\n",
    "# Initialize the Dawid-Skene model\n",
    "# cardinality: number of unique classes in the validation set\n",
    "ds_model = DawidSkene(cardinality=len(np.unique(y_valid)))\n",
    "\n",
    "# Fit the Dawid-Skene model using the training label matrix (L_train)\n",
    "# This step estimates the true labels based on the noisy labels provided by multiple annotators\n",
    "ds_model.fit(L_train)\n",
    "\n",
    "# Predict the labels for the training set using the fitted Dawid-Skene model\n",
    "# This step uses the learned parameters to infer the most likely labels for the training data\n",
    "y_train_ds = ds_model.predict(L_train)\n",
    "\n",
    "# Predict the labels for the test set using the fitted Dawid-Skene model\n",
    "# This step uses the learned parameters to infer the most likely labels for the test data\n",
    "y_test_ds = ds_model.predict(L_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Label Model name: Dawid-Skene\n",
      "Metric                                   Score\n",
      "=============================================\n",
      "Accuracy Score:                        0.95094\n",
      "Balanced Accuracy Score:               0.94941\n",
      "F1 Score (weighted):                   0.95129\n",
      "Cohen Kappa Score:                     0.88539\n",
      "Matthews Correlation Coefficient:      0.88602\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92      7050\n",
      "           1       0.98      0.95      0.96     16290\n",
      "\n",
      "    accuracy                           0.95     23340\n",
      "   macro avg       0.94      0.95      0.94     23340\n",
      "weighted avg       0.95      0.95      0.95     23340\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "Class 0 has 384 false negatives and 761 false positives.\n",
      "Class 1 has 761 false negatives and 384 false positives.\n",
      "The total number of errors is 1145 out of 23340 samples (error rate: 0.0491).\n",
      "Predicted      0       1     All\n",
      "True                            \n",
      "0          6,666     384   7,050\n",
      "1            761  15,529  16,290\n",
      "All        7,427  15,913  23,340\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate a model using the training features (X_train) and the labels inferred by the Dawid-Skene model (y_train_ds)\n",
    "# The function 'train_and_evaluate_model' trains a machine learning model and evaluates its performance on the test set\n",
    "results_ds_em = train_and_evaluate_model(\n",
    "    X_train, y_train_ds, X_test, y_test, \"Dawid-Skene\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Label Model name: Dawid-Skene\n",
      "Metric                                   Score\n",
      "=============================================\n",
      "Accuracy Score:                        0.88685\n",
      "Balanced Accuracy Score:               0.82927\n",
      "F1 Score (weighted):                   0.88147\n",
      "Cohen Kappa Score:                     0.71047\n",
      "Matthews Correlation Coefficient:      0.72500\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.68      0.78      7050\n",
      "           1       0.88      0.97      0.92     16290\n",
      "\n",
      "    accuracy                           0.89     23340\n",
      "   macro avg       0.90      0.83      0.85     23340\n",
      "weighted avg       0.89      0.89      0.88     23340\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "Class 0 has 2229 false negatives and 412 false positives.\n",
      "Class 1 has 412 false negatives and 2229 false positives.\n",
      "The total number of errors is 2641 out of 23340 samples (error rate: 0.1132).\n",
      "Predicted      0       1     All\n",
      "True                            \n",
      "0          4,821   2,229   7,050\n",
      "1            412  15,878  16,290\n",
      "All        5,233  18,107  23,340\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the noisy labels inferred by the Dawid-Skene model (y_test_ds) against the true test labels (y_test)\n",
    "# The function 'evaluate_noisy_labels' compares the inferred labels to the true labels and returns evaluation metrics\n",
    "results_ds_lm = evaluate_noisy_labels(y_test, y_test_ds, \"Dawid-Skene\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Label Model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Matthews Correlation",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Type",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "b8980bb8-df8c-4b20-a9ba-242c382aad28",
       "rows": [
        [
         "4",
         "Full Supervision on Dev Set + End Model",
         "0.9062052593266651",
         "Full supervision"
        ],
        [
         "2",
         "Snorkel MeTaL + End Model",
         "0.8889251584442059",
         "LM + EM"
        ],
        [
         "9",
         "Dawid-Skene + End Model",
         "0.8860193750293153",
         "LM + EM"
        ],
        [
         "3",
         "Majority Label Voter + End Model",
         "0.8761199167917382",
         "LM + EM"
        ],
        [
         "5",
         "HyperLabelModel Unsupervised + End Model",
         "0.8443216796321857",
         "LM + EM"
        ],
        [
         "7",
         "HyperLabelModel Semi-Supervised + End Model",
         "0.8339443855395706",
         "LM + EM"
        ],
        [
         "10",
         "Dawid-Skene",
         "0.7249990758311258",
         "LM alone"
        ],
        [
         "6",
         "HyperLabelModel Unsupervised",
         "0.7040155349376804",
         "LM alone"
        ],
        [
         "8",
         "HyperLabelModel Semi-Supervised",
         "0.6897673717851329",
         "LM alone"
        ],
        [
         "0",
         "Snorkel MeTaL",
         "0.6857925272523081",
         "LM alone"
        ],
        [
         "1",
         "Majority Label Voter",
         "0.6712213834075154",
         "LM alone"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 11
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label Model</th>\n",
       "      <th>Matthews Correlation</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Full Supervision on Dev Set + End Model</td>\n",
       "      <td>0.906205</td>\n",
       "      <td>Full supervision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Snorkel MeTaL + End Model</td>\n",
       "      <td>0.888925</td>\n",
       "      <td>LM + EM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dawid-Skene + End Model</td>\n",
       "      <td>0.886019</td>\n",
       "      <td>LM + EM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Majority Label Voter + End Model</td>\n",
       "      <td>0.876120</td>\n",
       "      <td>LM + EM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HyperLabelModel Unsupervised + End Model</td>\n",
       "      <td>0.844322</td>\n",
       "      <td>LM + EM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HyperLabelModel Semi-Supervised + End Model</td>\n",
       "      <td>0.833944</td>\n",
       "      <td>LM + EM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Dawid-Skene</td>\n",
       "      <td>0.724999</td>\n",
       "      <td>LM alone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HyperLabelModel Unsupervised</td>\n",
       "      <td>0.704016</td>\n",
       "      <td>LM alone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HyperLabelModel Semi-Supervised</td>\n",
       "      <td>0.689767</td>\n",
       "      <td>LM alone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Snorkel MeTaL</td>\n",
       "      <td>0.685793</td>\n",
       "      <td>LM alone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Majority Label Voter</td>\n",
       "      <td>0.671221</td>\n",
       "      <td>LM alone</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Label Model  Matthews Correlation  \\\n",
       "4       Full Supervision on Dev Set + End Model              0.906205   \n",
       "2                     Snorkel MeTaL + End Model              0.888925   \n",
       "9                       Dawid-Skene + End Model              0.886019   \n",
       "3              Majority Label Voter + End Model              0.876120   \n",
       "5      HyperLabelModel Unsupervised + End Model              0.844322   \n",
       "7   HyperLabelModel Semi-Supervised + End Model              0.833944   \n",
       "10                                  Dawid-Skene              0.724999   \n",
       "6                  HyperLabelModel Unsupervised              0.704016   \n",
       "8               HyperLabelModel Semi-Supervised              0.689767   \n",
       "0                                 Snorkel MeTaL              0.685793   \n",
       "1                          Majority Label Voter              0.671221   \n",
       "\n",
       "                Type  \n",
       "4   Full supervision  \n",
       "2            LM + EM  \n",
       "9            LM + EM  \n",
       "3            LM + EM  \n",
       "5            LM + EM  \n",
       "7            LM + EM  \n",
       "10          LM alone  \n",
       "6           LM alone  \n",
       "8           LM alone  \n",
       "0           LM alone  \n",
       "1           LM alone  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results.append(results_ds_em)\n",
    "all_results.append(results_ds_lm)\n",
    "df_baseline = pd.DataFrame(all_results)\n",
    "df_baseline.sort_values(by=\"Matthews Correlation\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Snorkel Generative Model\n",
    "\n",
    "The **Snorkel generative model** is the predecessor to the **Snorkel MeTaL** label model, designed to address the problem of combining noisy and potentially conflicting labels generated by weak supervision sources. It was originally introduced in the [Snorkel paper](https://arxiv.org/abs/1711.10160) by Ratner et al. (2017). Although the MeTaL model has since superseded the generative model in the Snorkel framework, understanding the generative model is important for grasping the fundamental principles of weak supervision and label aggregation.\n",
    "\n",
    "### Objectives of the Generative Model\n",
    "\n",
    "1. **Estimate LF Accuracy**:  \n",
    " Each LF has a different reliability level. The model learns a weight $w_j$ for each LF, representing its accuracy without direct access to the true labels.\n",
    "\n",
    "2. **Model LF Correlations**:  \n",
    " Some LFs may rely on similar cues or patterns and can be correlated. The model adjusts for this to prevent overcounting evidence from highly correlated LFs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operational Overview\n",
    "\n",
    "The model treats the true label $y_i$ for each data point $x_i$ as latent variable. Each labeling function $\\lambda_j(x_i)$ either assigns label or abstains from labeling. These LF outputs are interpreted as noisy votes about the true label.\n",
    "\n",
    "#### 1. Labeling Functions as Noisy Voters\n",
    "\n",
    "- **LF Output**:  \n",
    " For each data point $x_i$, each labeling function $\\lambda_j(x_i)$ outputs a label or $\\emptyset$ (abstention).  \n",
    "- **Noisy Evidence**:  \n",
    " Conflicting labels among LFs are combined to produce a probabilistic estimate of the true label $y_i$.\n",
    "\n",
    "#### 2. Modeling LF Accuracy\n",
    "\n",
    "- **Weight Assignment**:  \n",
    " Each LF $lambda_j $ receives a weight $ w_j $ that reflects its estimated accuracy.  \n",
    "- **Accuracy Factor**:  \n",
    " An accuracy factor, denoted as $\\phi^{\\text{Acc}}_{i,j}$, quantifies the probability that LF $ j $ correctly assigns the latent true label $ y_i $.\n",
    "\n",
    "#### 3. Modeling LF Correlations\n",
    "\n",
    "- **Correlation Factors**:  \n",
    " To adjust for dependencies among LFs, the model incorporates correlation factors $\\phi^{\\text{Corr}}_{i,j,k}$ that capture pairwise relationships between labeling function outputs.\n",
    "  \n",
    "- **Avoiding Overcounting**:  \n",
    " These factors help ensure that correlated signals from similar LFs do not result in an overconfident prediction.\n",
    "\n",
    "#### 4. Factor Graph Representation\n",
    "\n",
    "The generative model is expressed via a factor graph, linking the latent true labels and LF outputs. For each data point $x_i$, the joint probability distribution over true labels $y_i$ and LF outputs $\\lambda_j(x_i)$ can be written as:\n",
    "\n",
    "$$\n",
    "P(\\mathbf{Y}, \\mathbf{\\Lambda} \\mid \\mathbf{w}) = \\frac{1}{Z} \\exp\\left(\\sum_{i=1}^{m} \\mathbf{w}^T \\phi_i(\\mathbf{\\Lambda}, y_i)\\right)\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "- $\\mathbf{Y} = (y_1, y_2, \\ldots, y_m)$ is the vector of latent true labels.\n",
    "- $\\mathbf{\\Lambda}$ is the matrix of LF outputs.\n",
    "- $\\mathbf{w}$ contains the model parameters (LF accuracies and correlations).\n",
    "- $Z$ is the normalizing constant.\n",
    "- $\\phi_i(\\mathbf{\\Lambda}, y_i)$ are feature functions encapsulating accuracy and correlation effects.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Learning the Model\n",
    "\n",
    "The goal is to estimate the parameters $\\mathbf{w}$ by maximizing the marginal likelihood of the observed LF outputs. The training involves the following steps:\n",
    "\n",
    "#### 1. Initialization\n",
    "\n",
    "- **Starting Point**:  \n",
    " An initial guess is made for the latent true labels $\\mathbf{Y}$.\n",
    "\n",
    "#### 2. Gibbs Sampling\n",
    "\n",
    "- **Purpose**:  \n",
    " Gibbs sampling, a form of Markov Chain Monte Carlo (MCMC), estimates the joint distribution of the latent labels.\n",
    "  \n",
    "- **Conditional Sampling**:  \n",
    " For each data point $x_i$, sample the true label from the conditional distribution:\n",
    "\n",
    "  $$\n",
    "  P(y_i \\mid \\mathbf{\\Lambda}, \\mathbf{Y}_{-i}, \\mathbf{w}) \\propto \\exp\\left(\\mathbf{w}^T \\phi_i(\\mathbf{\\Lambda}, y_i)\\right)\n",
    "  $$\n",
    "  \n",
    " Here, $\\mathbf{Y}_{-i}$ denotes the set of latent labels excluding $y_i$.\n",
    "\n",
    "#### 3. Parameter Update\n",
    "\n",
    "- **Optimization Step**:  \n",
    " Use stochastic gradient descent to update the parameter vector $\\mathbf{w}$ based on the current samples of the latent true labels.\n",
    "\n",
    "#### 4. Convergence\n",
    "\n",
    "- **Iterative Process**:  \n",
    " Repeat the sampling and parameter update steps until the latent label distribution stabilizes, indicating convergence.\n",
    "  \n",
    "- **Probabilistic Labels**:  \n",
    " Once converged, the model produces probabilistic label estimates:\n",
    "\n",
    "  $$\n",
    "  \\hat{y}_i = P(y_i \\mid \\mathbf{\\Lambda}, \\mathbf{w})\n",
    "  $$\n",
    "\n",
    "  where\n",
    "  - $\\hat{y}_i$ is the estimated probability distribution over the true label $y_i$.\n",
    "  - $\\mathbf{\\Lambda}$ is the matrix of LF outputs.\n",
    "  - $\\mathbf{w}$ contains the learned parameters.\n",
    "  \n",
    "\n",
    "These estimates serve as training labels for a downstream discriminative model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### The Role of the Generative Model in the Snorkel Pipeline\n",
    "\n",
    "The generative model acts as a **bridge** between noisy LF outputs and the final discriminative model:\n",
    "1. **Labeling Functions**: Users create LFs based on domain knowledge, heuristics, or external resources.\n",
    "2. **Generative Model**: It estimates LF accuracies and correlations, combining their votes into probabilistic labels.\n",
    "3. **Discriminative Model**: The probabilistic labels train a high-performing discriminative model, improving predictive performance on new data.\n",
    "\n",
    "By learning LF accuracies and correlations, the Snorkel generative model produces probabilistic labels that significantly reduce the need for costly manual labeling, enabling rapid deployment of machine learning models in real-world scenarios where labeled datasets are scarce.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import helpers.labelmodels\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "# Initialize the GenerativeModel from the helpers.labelmodels module\n",
    "# cardinality: number of unique classes in the validation set\n",
    "generative_model = helpers.labelmodels.GenerativeModel(\n",
    "    cardinality=len(np.unique(y_valid))\n",
    ")\n",
    "\n",
    "# Fit the GenerativeModel using the training label matrix (L_train)\n",
    "# class_balance: prior class distribution\n",
    "# threads: number of threads to use for parallel processing\n",
    "# This step estimates the true labels based on the noisy labels provided by multiple labeling functions (LFs)\n",
    "generative_model.fit(L_train, class_balance=class_balance, threads=cpu_count())\n",
    "\n",
    "# Note: The fitting process can take a significant amount of time depending on the size of the LF set and the machine's core count\n",
    "# For a our LF set, it takes around 2 minutes on a 48-core machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the labels for the training set using the fitted GenerativeModel\n",
    "# This step uses the learned parameters to infer the most likely labels for the training data\n",
    "y_train_generative = generative_model.predict(L_train)\n",
    "\n",
    "# Predict the labels for the test set using the fitted GenerativeModel\n",
    "# This step uses the learned parameters to infer the most likely labels for the test data\n",
    "y_test_generative = generative_model.predict(L_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Label Model name: Generative Model\n",
      "Metric                                   Score\n",
      "=============================================\n",
      "Accuracy Score:                        0.95244\n",
      "Balanced Accuracy Score:               0.95088\n",
      "F1 Score (weighted):                   0.95277\n",
      "Cohen Kappa Score:                     0.88883\n",
      "Matthews Correlation Coefficient:      0.88941\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92      7050\n",
      "           1       0.98      0.95      0.97     16290\n",
      "\n",
      "    accuracy                           0.95     23340\n",
      "   macro avg       0.94      0.95      0.94     23340\n",
      "weighted avg       0.95      0.95      0.95     23340\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "Class 0 has 374 false negatives and 736 false positives.\n",
      "Class 1 has 736 false negatives and 374 false positives.\n",
      "The total number of errors is 1110 out of 23340 samples (error rate: 0.0476).\n",
      "Predicted      0       1     All\n",
      "True                            \n",
      "0          6,676     374   7,050\n",
      "1            736  15,554  16,290\n",
      "All        7,412  15,928  23,340\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate a model using the training features (X_train) and the labels inferred by the GenerativeModel (y_train_generative)\n",
    "# The function 'train_and_evaluate_model' trains a machine learning model and evaluates its performance on the test set\n",
    "results_generative_em = train_and_evaluate_model(\n",
    "    X_train, y_train_generative, X_test, y_test, \"Generative Model\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Label Model name: Generative Model\n",
      "Metric                                   Score\n",
      "=============================================\n",
      "Accuracy Score:                        0.84229\n",
      "Balanced Accuracy Score:               0.83609\n",
      "F1 Score (weighted):                   0.84535\n",
      "Cohen Kappa Score:                     0.64248\n",
      "Matthews Correlation Coefficient:      0.64652\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.82      0.76      7050\n",
      "           1       0.92      0.85      0.88     16290\n",
      "\n",
      "    accuracy                           0.84     23340\n",
      "   macro avg       0.81      0.84      0.82     23340\n",
      "weighted avg       0.85      0.84      0.85     23340\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "Class 0 has 1266 false negatives and 2415 false positives.\n",
      "Class 1 has 2415 false negatives and 1266 false positives.\n",
      "The total number of errors is 3681 out of 23340 samples (error rate: 0.1577).\n",
      "Predicted      0       1     All\n",
      "True                            \n",
      "0          5,784   1,266   7,050\n",
      "1          2,415  13,875  16,290\n",
      "All        8,199  15,141  23,340\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the noisy labels inferred by the GenerativeModel (y_test_generative) against the true test labels (y_test)\n",
    "# The function 'evaluate_noisy_labels' compares the inferred labels to the true labels and returns evaluation metrics\n",
    "results_generative_lm = evaluate_noisy_labels(\n",
    "    y_test, y_test_generative, \"Generative Model\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Label Model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Matthews Correlation",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Type",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "2ae5172c-579a-4a24-89de-87a3f954b3ce",
       "rows": [
        [
         "4",
         "Full Supervision on Dev Set + End Model",
         "0.9062052593266651",
         "Full supervision"
        ],
        [
         "11",
         "Generative Model + End Model",
         "0.889410391987121",
         "LM + EM"
        ],
        [
         "2",
         "Snorkel MeTaL + End Model",
         "0.8889251584442059",
         "LM + EM"
        ],
        [
         "9",
         "Dawid-Skene + End Model",
         "0.8860193750293153",
         "LM + EM"
        ],
        [
         "3",
         "Majority Label Voter + End Model",
         "0.8761199167917382",
         "LM + EM"
        ],
        [
         "5",
         "HyperLabelModel Unsupervised + End Model",
         "0.8443216796321857",
         "LM + EM"
        ],
        [
         "7",
         "HyperLabelModel Semi-Supervised + End Model",
         "0.8339443855395706",
         "LM + EM"
        ],
        [
         "10",
         "Dawid-Skene",
         "0.7249990758311258",
         "LM alone"
        ],
        [
         "6",
         "HyperLabelModel Unsupervised",
         "0.7040155349376804",
         "LM alone"
        ],
        [
         "8",
         "HyperLabelModel Semi-Supervised",
         "0.6897673717851329",
         "LM alone"
        ],
        [
         "0",
         "Snorkel MeTaL",
         "0.6857925272523081",
         "LM alone"
        ],
        [
         "1",
         "Majority Label Voter",
         "0.6712213834075154",
         "LM alone"
        ],
        [
         "12",
         "Generative Model",
         "0.6465167480320975",
         "LM alone"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 13
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label Model</th>\n",
       "      <th>Matthews Correlation</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Full Supervision on Dev Set + End Model</td>\n",
       "      <td>0.906205</td>\n",
       "      <td>Full supervision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Generative Model + End Model</td>\n",
       "      <td>0.889410</td>\n",
       "      <td>LM + EM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Snorkel MeTaL + End Model</td>\n",
       "      <td>0.888925</td>\n",
       "      <td>LM + EM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dawid-Skene + End Model</td>\n",
       "      <td>0.886019</td>\n",
       "      <td>LM + EM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Majority Label Voter + End Model</td>\n",
       "      <td>0.876120</td>\n",
       "      <td>LM + EM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HyperLabelModel Unsupervised + End Model</td>\n",
       "      <td>0.844322</td>\n",
       "      <td>LM + EM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HyperLabelModel Semi-Supervised + End Model</td>\n",
       "      <td>0.833944</td>\n",
       "      <td>LM + EM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Dawid-Skene</td>\n",
       "      <td>0.724999</td>\n",
       "      <td>LM alone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HyperLabelModel Unsupervised</td>\n",
       "      <td>0.704016</td>\n",
       "      <td>LM alone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HyperLabelModel Semi-Supervised</td>\n",
       "      <td>0.689767</td>\n",
       "      <td>LM alone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Snorkel MeTaL</td>\n",
       "      <td>0.685793</td>\n",
       "      <td>LM alone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Majority Label Voter</td>\n",
       "      <td>0.671221</td>\n",
       "      <td>LM alone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Generative Model</td>\n",
       "      <td>0.646517</td>\n",
       "      <td>LM alone</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Label Model  Matthews Correlation  \\\n",
       "4       Full Supervision on Dev Set + End Model              0.906205   \n",
       "11                 Generative Model + End Model              0.889410   \n",
       "2                     Snorkel MeTaL + End Model              0.888925   \n",
       "9                       Dawid-Skene + End Model              0.886019   \n",
       "3              Majority Label Voter + End Model              0.876120   \n",
       "5      HyperLabelModel Unsupervised + End Model              0.844322   \n",
       "7   HyperLabelModel Semi-Supervised + End Model              0.833944   \n",
       "10                                  Dawid-Skene              0.724999   \n",
       "6                  HyperLabelModel Unsupervised              0.704016   \n",
       "8               HyperLabelModel Semi-Supervised              0.689767   \n",
       "0                                 Snorkel MeTaL              0.685793   \n",
       "1                          Majority Label Voter              0.671221   \n",
       "12                             Generative Model              0.646517   \n",
       "\n",
       "                Type  \n",
       "4   Full supervision  \n",
       "11           LM + EM  \n",
       "2            LM + EM  \n",
       "9            LM + EM  \n",
       "3            LM + EM  \n",
       "5            LM + EM  \n",
       "7            LM + EM  \n",
       "10          LM alone  \n",
       "6           LM alone  \n",
       "8           LM alone  \n",
       "0           LM alone  \n",
       "1           LM alone  \n",
       "12          LM alone  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results.append(results_generative_em)\n",
    "all_results.append(results_generative_lm)\n",
    "df_baseline = pd.DataFrame(all_results)\n",
    "df_baseline.sort_values(by=\"Matthews Correlation\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FlyingSquid Model\n",
    "\n",
    "The **FlyingSquid** model is a framework specifically designed to tackle the computational demands of weak supervision. Traditional approaches often rely on **latent variable models** and iterative algorithms like **stochastic gradient descent (SGD)** to estimate the accuracies of labeling functions (LFs). However, these methods can be computationally intensive, especially with a large number of LFs or data points.\n",
    "\n",
    "FlyingSquid distinguishes itself by using **closed-form solutions** to estimate model parameters. This approach dramatically reduces computation time, offering a significant speed advantage over iterative optimization methods.\n",
    "\n",
    "### Key Components\n",
    "\n",
    "1. **Weak Supervision Setup**\n",
    "\n",
    "   - **Data and Labels**: Let $X = \\{X_1, X_2, \\dots, X_n\\}$ be the set of unlabeled data points, and $Y = \\{Y_1, Y_2, \\dots, Y_n\\}$ be the set of unobserved true labels. For binary classification, each $Y_i \\in \\{-1, +1\\}$.\n",
    "   - **Weak Supervision Sources**: We have $m$ weak supervision sources (labeling functions), denoted as $S_1, S_2, \\dots, S_m$. Each source $S_j$ provides a noisy label $\\lambda_j \\in \\{-1, 0, 1\\}$ for each data point, where $0$ signifies abstention.\n",
    "\n",
    "2. **Label Model**\n",
    "\n",
    "   - **Latent Variable Approach**: FlyingSquid employs a **latent variable model** to infer both the accuracies of and the dependencies between the weak supervision sources.\n",
    "   - **Binary Ising Model**: Specifically, it uses a **binary Ising model** to aggregate weak signals into probabilistic labels. The Ising model captures the relationships between the LFs and the unobserved true labels, allowing for efficient probabilistic aggregation.\n",
    "\n",
    "3. **Triplet Decomposition**\n",
    "\n",
    "   - **Key Innovation**: The central idea in FlyingSquid is the **triplet method**. It simplifies parameter estimation by breaking down the problem into smaller, solvable subproblems involving triplets of label sources.\n",
    "   - **Pairwise Agreements**: For any three label sources $ \\lambda_i, \\lambda_j, \\lambda_k $, the method estimates their accuracies by analyzing their pairwise agreements.\n",
    "   - **Conditional Independence**:  Assuming conditional independence between sources $\\lambda_i$ and $\\lambda_j$ given the true label $Y$, the following relationship holds:\n",
    "\n",
    "     $$\n",
    "     E[\\lambda_i Y] \\cdot E[\\lambda_j Y] = E[\\lambda_i \\lambda_j]\n",
    "     $$\n",
    "\n",
    "     Here, $E[\\lambda_i Y]$ is intended to capture the “accuracy” of the $i$th labeling function (LF) under the assumption that the LF returns values in $\\{-1, 0, +1\\}$ and the true label $Y \\in \\{-1, +1\\}$.\n",
    "     \n",
    "     Under the conditional independence assumption (given $Y$), if we denote $a_i = E[\\lambda_i Y]$ as the accuracy of LF $i$ and $a_j = E[\\lambda_j Y]$, the product $a_i\\,a_j$ naturally appears as the expected pairwise agreement $E[\\lambda_i \\lambda_j]$.\n",
    "\n",
    "     This equation relates the expected product of $\\lambda_i$ and $Y$ with the expected product of $\\lambda_j$ and $Y$ to the directly observable expected product of $\\lambda_i$ and $\\lambda_j$. By forming triplets and employing this relationship, FlyingSquid sets up a system of equations to estimate the accuracy parameters.\n",
    "\n",
    "4. **Closed-Form Solution**\n",
    "\n",
    "   - **Direct Calculation**:  FlyingSquid derives **closed-form solutions** for estimating parameters, in contrast to iterative optimization used in many latent variable models.\n",
    "   - **Linear Systems**: This is accomplished by solving linear systems based on the observed agreement rates between pairs of weak supervision sources.\n",
    "   - **Accuracy Estimation Formula**: The accuracy $a_i$ of a source $\\lambda_i$ can be computed directly using the agreement rates with two other sources $\\lambda_j$ and $\\lambda_k$:\n",
    "\n",
    "     $$\n",
    "     a_i = \\sqrt{\\frac{E[\\lambda_i \\lambda_j] \\cdot E[\\lambda_i \\lambda_k]}{E[\\lambda_j \\lambda_k]}}\n",
    "     $$\n",
    "\n",
    "     If the accuracies of the labeling functions in a triplet are defined as above, then from $E[\\lambda_i \\lambda_j] = a_i a_j$ and likewise for other pairs, solving for $a_i$ yields this closed-form expression.\n",
    "     This formula requires that $E[\\lambda_j \\lambda_k]$ is non-zero, which is usually assumed when the LFs are sufficiently informative and not completely uncorrelated.\n",
    "\n",
    "   - **Efficiency**: This method is computationally efficient because it scales linearly with the number of sources. It avoids the computational overhead of iterative procedures, making it suitable for large-scale weak supervision tasks.\n",
    "\n",
    "5. **Binary Ising Model**\n",
    "\n",
    "   - **Dependency Modeling**: FlyingSquid models the relationships between label sources and true labels using a **binary Ising model**.\n",
    "   - **Graph Representation**: The Ising model is visualized as a graph $G$ where each node represents a weak supervision source. Edges between nodes can represent dependencies. Each source $\\lambda_i$ is implicitly connected to the true label $Y$.\n",
    "   - **Joint Distribution**: The Ising model defines the joint probability distribution over the true labels $Y$ and the observed labels $\\lambda$:\n",
    "\n",
    "     $$\n",
    "     P(Y, \\lambda) = \\frac{1}{Z} \\exp \\left( \\sum_{i} \\theta_i Y \\lambda_i + \\sum_{i,j} \\theta_{ij} \\lambda_i \\lambda_j \\right)\n",
    "     $$\n",
    "\n",
    "     Here, $\\theta_i$ reflects the accuracy of source $\\lambda_i$, and $\\theta_{ij}$ captures the correlation between sources $\\lambda_i$ and $\\lambda_j$. The triplet method allows for efficient estimation of these $\\theta$ parameters, making the Ising model parameters tractable.\n",
    "\n",
    "### Generalization Bound\n",
    "\n",
    "FlyingSquid provides theoretical guarantees on the **generalization error** of models trained using its generated labels. These bounds consider both sampling error and potential model inaccuracies (misspecification).\n",
    "\n",
    "- **Error Bound**: The generalization error $E$ of a model trained with FlyingSquid labels is bounded by:\n",
    "\n",
    "  $$\n",
    "  E \\leq \\gamma(n) + \\frac{8 \\|Y\\|}{\\lambda_{\\min}} \\|\\hat{\\mu} - \\mu\\|_2^2 + \\delta(D, P_\\mu)\n",
    "  $$\n",
    "\n",
    "  Where:\n",
    "\n",
    "  - $\\gamma(n)$ decreases as the number of samples $n$ increases, representing the reduction in sampling error with more data.\n",
    "  - $\\lambda_{\\min}$ is the smallest eigenvalue of the covariance matrix of observed variables, influencing the stability of the estimation.\n",
    "  - $\\|\\hat{\\mu} - \\mu\\|_2$ measures the error in parameter estimation, i.e., how accurately the model parameters are estimated.\n",
    "  - $\\delta(D, P_\\mu)$ is the Kullback-Leibler (KL) divergence, quantifying the difference between the true data distribution $D$ and the Ising model distribution $P_\\mu$. This term accounts for model misspecification – if the Ising model does not perfectly represent the data, this term captures the resulting error.\n",
    "\n",
    "- **Consequences**: This bound suggests that even if the Ising model is an approximation, the performance of a downstream model trained with FlyingSquid labels remains close to the performance achievable with true labels, especially when the sample size is sufficiently large.\n",
    "\n",
    "> **Analogy**: Imagine you are trying to judge the fairness of three coin-flipping sources (analogous to LFs) without knowing the true probability of heads for each. You can observe pairs of coin flips from each pair of sources. By comparing how often each pair agrees (both heads or both tails), you can infer the reliability (accuracy) of each source without knowing the true outcome of any flip. FlyingSquid’s triplet method is similar—it uses observed agreements between triplets of LFs to estimate their individual accuracies in a computationally efficient way.\n",
    "\n",
    ">\n",
    "> That said, these expressions depend on the modeling assumptions (e.g., conditional independence, non-zero pairwise expectations) and may vary slightly with different formulations or under alternate assumptions. The key takeaway is that FlyingSquid provides a computationally efficient method for estimating LF accuracies and dependencies, enabling adaptable weak supervision applications.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pgmpy:MarkovModel has been renamed to MarkovNetwork. Please use MarkovNetwork class, MarkovModel will be removed in future.\n",
      "WARNING:pgmpy:MarkovModel has been renamed to MarkovNetwork. Please use MarkovNetwork class, MarkovModel will be removed in future.\n",
      "WARNING:pgmpy:MarkovModel has been renamed to MarkovNetwork. Please use MarkovNetwork class, MarkovModel will be removed in future.\n",
      "WARNING:pgmpy:MarkovModel has been renamed to MarkovNetwork. Please use MarkovNetwork class, MarkovModel will be removed in future.\n",
      "WARNING:pgmpy:MarkovModel has been renamed to MarkovNetwork. Please use MarkovNetwork class, MarkovModel will be removed in future.\n",
      "WARNING:pgmpy:MarkovModel has been renamed to MarkovNetwork. Please use MarkovNetwork class, MarkovModel will be removed in future.\n",
      "WARNING:pgmpy:MarkovModel has been renamed to MarkovNetwork. Please use MarkovNetwork class, MarkovModel will be removed in future.\n",
      "WARNING:pgmpy:MarkovModel has been renamed to MarkovNetwork. Please use MarkovNetwork class, MarkovModel will be removed in future.\n",
      "WARNING:pgmpy:MarkovModel has been renamed to MarkovNetwork. Please use MarkovNetwork class, MarkovModel will be removed in future.\n",
      "WARNING:pgmpy:MarkovModel has been renamed to MarkovNetwork. Please use MarkovNetwork class, MarkovModel will be removed in future.\n",
      "WARNING:pgmpy:MarkovModel has been renamed to MarkovNetwork. Please use MarkovNetwork class, MarkovModel will be removed in future.\n",
      "WARNING:pgmpy:MarkovModel has been renamed to MarkovNetwork. Please use MarkovNetwork class, MarkovModel will be removed in future.\n",
      "WARNING:pgmpy:MarkovModel has been renamed to MarkovNetwork. Please use MarkovNetwork class, MarkovModel will be removed in future.\n",
      "WARNING:pgmpy:MarkovModel has been renamed to MarkovNetwork. Please use MarkovNetwork class, MarkovModel will be removed in future.\n",
      "WARNING:pgmpy:MarkovModel has been renamed to MarkovNetwork. Please use MarkovNetwork class, MarkovModel will be removed in future.\n",
      "WARNING:pgmpy:MarkovModel has been renamed to MarkovNetwork. Please use MarkovNetwork class, MarkovModel will be removed in future.\n",
      "WARNING:pgmpy:MarkovModel has been renamed to MarkovNetwork. Please use MarkovNetwork class, MarkovModel will be removed in future.\n",
      "WARNING:pgmpy:MarkovModel has been renamed to MarkovNetwork. Please use MarkovNetwork class, MarkovModel will be removed in future.\n",
      "WARNING:pgmpy:MarkovModel has been renamed to MarkovNetwork. Please use MarkovNetwork class, MarkovModel will be removed in future.\n",
      "WARNING:pgmpy:MarkovModel has been renamed to MarkovNetwork. Please use MarkovNetwork class, MarkovModel will be removed in future.\n",
      "WARNING:pgmpy:MarkovModel has been renamed to MarkovNetwork. Please use MarkovNetwork class, MarkovModel will be removed in future.\n",
      "WARNING:pgmpy:MarkovModel has been renamed to MarkovNetwork. Please use MarkovNetwork class, MarkovModel will be removed in future.\n",
      "WARNING:pgmpy:MarkovModel has been renamed to MarkovNetwork. Please use MarkovNetwork class, MarkovModel will be removed in future.\n",
      "WARNING:pgmpy:MarkovModel has been renamed to MarkovNetwork. Please use MarkovNetwork class, MarkovModel will be removed in future.\n",
      "WARNING:pgmpy:MarkovModel has been renamed to MarkovNetwork. Please use MarkovNetwork class, MarkovModel will be removed in future.\n",
      "WARNING:pgmpy:MarkovModel has been renamed to MarkovNetwork. Please use MarkovNetwork class, MarkovModel will be removed in future.\n",
      "WARNING:pgmpy:MarkovModel has been renamed to MarkovNetwork. Please use MarkovNetwork class, MarkovModel will be removed in future.\n",
      "WARNING:pgmpy:MarkovModel has been renamed to MarkovNetwork. Please use MarkovNetwork class, MarkovModel will be removed in future.\n",
      "WARNING:pgmpy:MarkovModel has been renamed to MarkovNetwork. Please use MarkovNetwork class, MarkovModel will be removed in future.\n",
      "Marginals written down\n",
      "R vector written down\n",
      "Expectations to estimate written down\n",
      "Triplets constructed\n",
      "Y marginals computed\n",
      "Y equals one computed\n",
      "lambda marginals, moments, conditions computed\n",
      "Unobserved probabilities computed\n",
      "R values computed\n"
     ]
    }
   ],
   "source": [
    "# Initialize the FlyingSquid model from the helpers.labelmodels module\n",
    "# cardinality: number of unique classes in the validation set\n",
    "fs_model = helpers.labelmodels.FlyingSquid(cardinality=len(np.unique(y_valid)))\n",
    "\n",
    "# Fit the FlyingSquid model using the training label matrix (L_train)\n",
    "# class_balance: prior class distribution\n",
    "# verbose=True: enables detailed logging during the fitting process\n",
    "# This step estimates the true labels based on the noisy labels provided by multiple labeling functions (LFs)\n",
    "fs_model.fit(L_train, class_balance=class_balance, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the labels for the training set using the fitted FlyingSquid model\n",
    "# This step uses the learned parameters to infer the most likely labels for the training data\n",
    "y_train_fs = fs_model.predict(L_train)\n",
    "\n",
    "# Predict the labels for the test set using the fitted FlyingSquid model\n",
    "# This step uses the learned parameters to infer the most likely labels for the test data\n",
    "y_test_fs = fs_model.predict(L_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Label Model name: FlyingSquid\n",
      "Metric                                   Score\n",
      "=============================================\n",
      "Accuracy Score:                        0.88338\n",
      "Balanced Accuracy Score:               0.82678\n",
      "F1 Score (weighted):                   0.87814\n",
      "Cohen Kappa Score:                     0.70264\n",
      "Matthews Correlation Coefficient:      0.71562\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.68      0.78      7050\n",
      "           1       0.88      0.97      0.92     16290\n",
      "\n",
      "    accuracy                           0.88     23340\n",
      "   macro avg       0.89      0.83      0.85     23340\n",
      "weighted avg       0.89      0.88      0.88     23340\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "Class 0 has 2229 false negatives and 493 false positives.\n",
      "Class 1 has 493 false negatives and 2229 false positives.\n",
      "The total number of errors is 2722 out of 23340 samples (error rate: 0.1166).\n",
      "Predicted      0       1     All\n",
      "True                            \n",
      "0          4,821   2,229   7,050\n",
      "1            493  15,797  16,290\n",
      "All        5,314  18,026  23,340\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate a model using the training features (X_train) and the labels inferred by the FlyingSquid model (y_train_fs)\n",
    "# The function 'train_and_evaluate_model' trains a machine learning model and evaluates its performance on the test set\n",
    "results_fs_em = train_and_evaluate_model(\n",
    "    X_train, y_train_fs, X_test, y_test, \"FlyingSquid\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Label Model name: FlyingSquid\n",
      "Metric                                   Score\n",
      "=============================================\n",
      "Accuracy Score:                        0.83483\n",
      "Balanced Accuracy Score:               0.74357\n",
      "F1 Score (weighted):                   0.81940\n",
      "Cohen Kappa Score:                     0.55428\n",
      "Matthews Correlation Coefficient:      0.59127\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.51      0.65      7050\n",
      "           1       0.82      0.97      0.89     16290\n",
      "\n",
      "    accuracy                           0.83     23340\n",
      "   macro avg       0.86      0.74      0.77     23340\n",
      "weighted avg       0.84      0.83      0.82     23340\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "Class 0 has 3433 false negatives and 422 false positives.\n",
      "Class 1 has 422 false negatives and 3433 false positives.\n",
      "The total number of errors is 3855 out of 23340 samples (error rate: 0.1652).\n",
      "Predicted      0       1     All\n",
      "True                            \n",
      "0          3,617   3,433   7,050\n",
      "1            422  15,868  16,290\n",
      "All        4,039  19,301  23,340\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the noisy labels inferred by the FlyingSquid model (y_test_fs) against the true test labels (y_test)\n",
    "# The function 'evaluate_noisy_labels' compares the inferred labels to the true labels and returns evaluation metrics\n",
    "results_fs_lm = evaluate_noisy_labels(y_test, y_test_fs, \"FlyingSquid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Label Model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Matthews Correlation",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Type",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "3c4a3e48-905a-4ac9-8c28-2213a3cf72cb",
       "rows": [
        [
         "4",
         "Full Supervision on Dev Set + End Model",
         "0.9062052593266651",
         "Full supervision"
        ],
        [
         "11",
         "Generative Model + End Model",
         "0.889410391987121",
         "LM + EM"
        ],
        [
         "2",
         "Snorkel MeTaL + End Model",
         "0.8889251584442059",
         "LM + EM"
        ],
        [
         "9",
         "Dawid-Skene + End Model",
         "0.8860193750293153",
         "LM + EM"
        ],
        [
         "3",
         "Majority Label Voter + End Model",
         "0.8761199167917382",
         "LM + EM"
        ],
        [
         "5",
         "HyperLabelModel Unsupervised + End Model",
         "0.8443216796321857",
         "LM + EM"
        ],
        [
         "7",
         "HyperLabelModel Semi-Supervised + End Model",
         "0.8339443855395706",
         "LM + EM"
        ],
        [
         "10",
         "Dawid-Skene",
         "0.7249990758311258",
         "LM alone"
        ],
        [
         "13",
         "FlyingSquid + End Model",
         "0.7156224802187824",
         "LM + EM"
        ],
        [
         "6",
         "HyperLabelModel Unsupervised",
         "0.7040155349376804",
         "LM alone"
        ],
        [
         "8",
         "HyperLabelModel Semi-Supervised",
         "0.6897673717851329",
         "LM alone"
        ],
        [
         "0",
         "Snorkel MeTaL",
         "0.6857925272523081",
         "LM alone"
        ],
        [
         "1",
         "Majority Label Voter",
         "0.6712213834075154",
         "LM alone"
        ],
        [
         "12",
         "Generative Model",
         "0.6465167480320975",
         "LM alone"
        ],
        [
         "14",
         "FlyingSquid",
         "0.5912699244529404",
         "LM alone"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 15
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label Model</th>\n",
       "      <th>Matthews Correlation</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Full Supervision on Dev Set + End Model</td>\n",
       "      <td>0.906205</td>\n",
       "      <td>Full supervision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Generative Model + End Model</td>\n",
       "      <td>0.889410</td>\n",
       "      <td>LM + EM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Snorkel MeTaL + End Model</td>\n",
       "      <td>0.888925</td>\n",
       "      <td>LM + EM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dawid-Skene + End Model</td>\n",
       "      <td>0.886019</td>\n",
       "      <td>LM + EM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Majority Label Voter + End Model</td>\n",
       "      <td>0.876120</td>\n",
       "      <td>LM + EM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HyperLabelModel Unsupervised + End Model</td>\n",
       "      <td>0.844322</td>\n",
       "      <td>LM + EM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HyperLabelModel Semi-Supervised + End Model</td>\n",
       "      <td>0.833944</td>\n",
       "      <td>LM + EM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Dawid-Skene</td>\n",
       "      <td>0.724999</td>\n",
       "      <td>LM alone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>FlyingSquid + End Model</td>\n",
       "      <td>0.715622</td>\n",
       "      <td>LM + EM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HyperLabelModel Unsupervised</td>\n",
       "      <td>0.704016</td>\n",
       "      <td>LM alone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HyperLabelModel Semi-Supervised</td>\n",
       "      <td>0.689767</td>\n",
       "      <td>LM alone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Snorkel MeTaL</td>\n",
       "      <td>0.685793</td>\n",
       "      <td>LM alone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Majority Label Voter</td>\n",
       "      <td>0.671221</td>\n",
       "      <td>LM alone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Generative Model</td>\n",
       "      <td>0.646517</td>\n",
       "      <td>LM alone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>FlyingSquid</td>\n",
       "      <td>0.591270</td>\n",
       "      <td>LM alone</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Label Model  Matthews Correlation  \\\n",
       "4       Full Supervision on Dev Set + End Model              0.906205   \n",
       "11                 Generative Model + End Model              0.889410   \n",
       "2                     Snorkel MeTaL + End Model              0.888925   \n",
       "9                       Dawid-Skene + End Model              0.886019   \n",
       "3              Majority Label Voter + End Model              0.876120   \n",
       "5      HyperLabelModel Unsupervised + End Model              0.844322   \n",
       "7   HyperLabelModel Semi-Supervised + End Model              0.833944   \n",
       "10                                  Dawid-Skene              0.724999   \n",
       "13                      FlyingSquid + End Model              0.715622   \n",
       "6                  HyperLabelModel Unsupervised              0.704016   \n",
       "8               HyperLabelModel Semi-Supervised              0.689767   \n",
       "0                                 Snorkel MeTaL              0.685793   \n",
       "1                          Majority Label Voter              0.671221   \n",
       "12                             Generative Model              0.646517   \n",
       "14                                  FlyingSquid              0.591270   \n",
       "\n",
       "                Type  \n",
       "4   Full supervision  \n",
       "11           LM + EM  \n",
       "2            LM + EM  \n",
       "9            LM + EM  \n",
       "3            LM + EM  \n",
       "5            LM + EM  \n",
       "7            LM + EM  \n",
       "10          LM alone  \n",
       "13           LM + EM  \n",
       "6           LM alone  \n",
       "8           LM alone  \n",
       "0           LM alone  \n",
       "1           LM alone  \n",
       "12          LM alone  \n",
       "14          LM alone  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results.append(results_fs_em)\n",
    "all_results.append(results_fs_lm)\n",
    "\n",
    "df_baseline = pd.DataFrame(all_results)\n",
    "df_baseline.sort_values(by=\"Matthews Correlation\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crowdlab Model for Weak Supervision Using Label Functions\n",
    "\n",
    "The Crowdlab method was originally developed for aggregating annotations from multiple human annotators, but we use it to aggregate outputs from weak supervision sources It kinda merges majority voting with confident learning, aiming to derive high-quality consensus labels and to evaluate the quality of the LFs themselves. Crowdlab achieves this by integrating predictions from LFs with a classifier trained on weakly labeled data, thereby using the complementary strengths and mitigating the weaknesses of both approaches.\n",
    "\n",
    "### Method Overview\n",
    "\n",
    "The Crowdlab method is designed for a dataset $D = \\{X_i\\}_{i=1}^{n}$, where each instance $X_i$ belongs to one of $K$ possible classes. The true label $Y_i$ for each instance is unknown. We have access to $m$ label functions, $LF_j$, each providing a weak label $Y_{ij} \\in \\{1, \\dots, K\\}$, or abstaining if $LF_j$ is not applicable to $X_i$. Crowdlab is structured to achieve three primary goals:\n",
    "\n",
    "1. **Consensus Label Inference**: To combine predictions from LFs and a trained classifier to estimate the most probable true label for each instance.\n",
    "2. **Confidence Estimation**: To quantify the reliability of these consensus labels, based on the level of agreement between LFs and the classifier.\n",
    "3. **Label Function Quality Rating**: To evaluate the performance of each LF, assessing its accuracy and consistency with the derived consensus labels.\n",
    "\n",
    "Through these integrated functionalities, Crowdlab manages the innate noise and potential conflicts present in weak supervision signals.\n",
    "\n",
    "### Consensus Label Estimation\n",
    "\n",
    "Crowdlab uses a **weighted ensemble** approach to calculate consensus labels. This method combines the probabilistic outputs of the LFs and a classifier that has been trained using the weakly labeled data. To prevent overfitting of the classifier on the weakly supervised training data, Crowdlab uses **cross-validation**. This ensures that the classifier's predictions used in the ensemble are based on data it has not been directly trained on. The combined probability prediction for each instance $X_i$ belonging to class $k$ is given by:\n",
    "\n",
    "$$\n",
    "\\hat{p}(Y_i = k \\mid X_i, \\{Y_{ij}\\}_{j=1}^{m}) = \\frac{w_M \\hat{p}(Y_i = k \\mid X_i) + \\sum_{j \\in J_i} w_j p_j(Y_i = k \\mid X_i)}{w_M + \\sum_{j \\in J_i} w_j}\n",
    "$$\n",
    "\n",
    "Let's break down each component of this formula:\n",
    "\n",
    "- $\\hat{p}(Y_i = k \\mid X_i)$: This represents the probability that instance $X_i$ belongs to class $k$, as predicted by the classifier. This classifier is typically trained on data weakly labeled by the LFs, and cross-validation is used to get out-of-sample predictions to avoid overestimation of performance in the ensemble.\n",
    "- $p_j(Y_i = k \\mid X_i)$: This is the probabilistic estimate from label function $LF_j$ for instance $X_i$ belonging to class $k$. If $LF_j$ directly outputs a class label, this can be represented as a probability distribution concentrated on that class (e.g., 1 for the predicted class, 0 for others). For LFs that provide scores or confidence levels, these can be converted into probability estimates over classes.\n",
    "- $w_M$: This is the weight assigned to the classifier, reflecting its estimated overall accuracy and contribution to the consensus. A higher $w_M$ indicates greater reliance on the classifier's predictions in the ensemble.\n",
    "- $w_j$: This is the weight assigned to label function $LF_j$. It represents the quality and reliability of $LF_j$. Higher weights are given to LFs that are deemed more accurate and consistent.\n",
    "- $J_i$: This is the set of indices of label functions that provided a non-abstaining label for instance $X_i$.  Only LFs that actually provide a label for $X_i$ contribute to the weighted sum for that instance.\n",
    "\n",
    "The weights $w_M$ and $w_j$ are determined based on the agreement observed between the classifier's predictions and the labels provided by the LFs. These weights are adjusted dynamically: if the classifier shows higher reliability across the dataset, $w_M$ will be larger, placing more emphasis on its predictions. Conversely, if certain LFs are found to be more consistent and accurate, their corresponding $w_j$ values will increase, giving them more influence in the consensus label.\n",
    "\n",
    "This adaptive weighting mechanism allows Crowdlab to balance the contributions of both the data-driven classifier and the knowledge-driven LFs, leading to more sturdy consensus labels than relying on either source alone.\n",
    "\n",
    "### Scoring Label Function Quality\n",
    "\n",
    "A significant feature of Crowdlab is its capability to assess the quality of individual LFs. This is particularly valuable in weak supervision because LFs inherently vary in accuracy and applicability. Crowdlab assigns a **quality score** $a_j$ to each label function $LF_j$, which serves as an indicator of its reliability and usefulness.\n",
    "\n",
    "The quality score $a_j$ is computed based on two key factors:\n",
    "\n",
    "1. **Agreement with Consensus Labels**: This measures the extent to which the labels generated by $LF_j$ align with the final consensus labels derived by Crowdlab. Higher agreement suggests that the LF is effectively capturing the fundamental patterns in the data. The agreement score for $LF_j$ is calculated as:\n",
    "\n",
    "   $$\n",
    "   \\text{Agreement}_j = \\frac{1}{|I_j|} \\sum_{i \\in I_j} \\mathbb{1}(Y_{ij} = \\hat{Y_i})\n",
    "   $$\n",
    "\n",
    "   - $I_j$: The set of indices of instances for which label function $LF_j$ provided a label.\n",
    "   - $\\hat{Y_i}$: The consensus label for instance $X_i$, as estimated by Crowdlab.\n",
    "   - $\\mathbb{1}(Y_{ij} = \\hat{Y_i})$: An indicator function that equals 1 if the label $Y_{ij}$ from $LF_j$ for instance $X_i$ matches the consensus label $\\hat{Y_i}$, and 0 otherwise.\n",
    "   - $|I_j|$: The total number of instances labeled by $LF_j$.\n",
    "   - $\\text{Agreement}_j$: The fraction of times $LF_j$'s label agrees with the consensus label, averaged over all instances it labeled.\n",
    "\n",
    "2. **Prediction Confidence Alignment**: This factor assesses how well the predictions of $LF_j$ correlate with the confidence of the classifier's predictions. LFs that tend to produce labels in alignment with what the classifier predicts with high confidence are considered more reliable.  A higher confidence alignment suggests that the LF and the classifier are reinforcing each other, potentially pointing to more trustworthy labels.  *(Note: The original text mentions \"prediction confidence\" but does not give a formula. A possible approach to quantify this \"Confidence\" could involve measuring how often LF labels align with classes for which the classifier outputs high probabilities, but the provided text does not specify the exact calculation for  $\\text{Confidence}_j$. It's often context-dependent.)* For simplicity and based on the provided context focusing on agreement, we can proceed by primarily focusing on the \"Agreement\" metric as directly described for scoring LF quality.\n",
    "\n",
    "The final quality score $a_j$ for label function $LF_j$ is a weighted average of these two components:\n",
    "\n",
    "$$\n",
    "a_j = \\alpha \\times \\text{Agreement}_j + (1 - \\alpha) \\times \\text{Confidence}_j\n",
    "$$\n",
    "\n",
    "- $\\alpha$: A hyperparameter that controls the relative importance of agreement versus confidence. It allows for tuning the quality score to emphasize either the direct match with consensus labels or the alignment with classifier confidence, depending on the specific application and characteristics of the LFs and classifier.\n",
    "\n",
    "This quality score $a_j$ allows for ranking LFs and identifying those that are most reliable and beneficial for the weak supervision task. It can guide efforts in refining LFs, discarding less effective ones, or focusing on improving the most promising labeling strategies.\n",
    "\n",
    "### Advantages of Crowdlab in Weak Supervision\n",
    "\n",
    "Applying Crowdlab to weak supervision offers several significant advantages:\n",
    "\n",
    "- **Integrated Use of Multiple Information Sources**: Crowdlab excels at synergistically combining programmatic LFs with machine learning models. By dynamically weighting each source, it optimally integrates their information. This is especially beneficial in noisy weak supervision environments, leading to more reliable and accurate consensus labels.\n",
    "\n",
    "- **Effective Handling of Label Function Diversity**:  Recognizing that LFs can vary significantly in noise levels and applicability across different data subsets, Crowdlab's capacity to assign individual weights to each LF is crucial. This tailored approach effectively manages diverse and noisy labeling strategies, enhancing the overall label aggregation process.\n",
    "\n",
    "- **Classifier Agnostic Design**: Crowdlab's design is independent of the specific classifier model used. This classifier-agnostic nature means it can be integrated with any machine learning classifier. This flexibility ensures that Crowdlab can benefit from ongoing advancements in classifier technology, continually improving the quality of generated labels as better classifiers emerge.\n",
    "\n",
    "- **Assessment of Label Function Trustworthiness**: By providing a quality score for each LF, Crowdlab offers valuable insights into the contributions of different labeling strategies. This assessment helps identify LFs that provide useful signals and those that introduce noise. Such insights are invaluable for iteratively refining weak supervision pipelines and for selecting the most reliable sources of weak labels, enhancing the overall process of weak supervision.\n",
    "\n",
    "In conclusion, Crowdlab is another nice framework for weak supervision that not only generates improved consensus labels by combining LFs and classifier predictions but also provides mechanisms to understand and evaluate the reliability of different labeling approaches. This makes Crowdlab a valuable asset in scenarios where weak supervision is a primary method for generating training data, offering a structured and adaptive approach to handling the complexities and uncertainties innate in weakly labeled datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from cleanlab.multiannotator import (\n",
    "    get_label_quality_multiannotator,\n",
    "    get_majority_vote_label,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crowdlab expects abstains to be represented as np.nan (Not a Number)\n",
    "# Create a copy of the training label matrix (L_train) and convert it to float type\n",
    "L_train_crowdlab = L_train.copy().astype(float)\n",
    "\n",
    "# Replace all instances of -1 (abstains) in the copied label matrix with np.nan\n",
    "L_train_crowdlab[L_train_crowdlab == -1] = np.nan\n",
    "\n",
    "# Before training a machine learning model, we need to obtain initial consensus labels from the data annotations.\n",
    "# These consensus labels represent a crude guess of the best label for each example.\n",
    "# The most straightforward way to obtain an initial set of consensus labels is via simple majority vote.\n",
    "# Use the get_majority_vote_label function to obtain the majority vote labels for the training set\n",
    "crowdlab_majority_vote_train = get_majority_vote_label(L_train_crowdlab)\n",
    "\n",
    "# Display the first 5 majority vote labels for the training set\n",
    "crowdlab_majority_vote_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Initialize a Logistic Regression model with specific parameters\n",
    "# random_state: ensures reproducibility\n",
    "# n_jobs=-1: uses all available processors\n",
    "# class_weight='balanced': adjusts weights inversely proportional to class frequencies\n",
    "# max_iter=1000: sets the maximum number of iterations for the solver\n",
    "model_lr_crowdlab_train = LogisticRegression(\n",
    "    random_state=271828, n_jobs=-1, class_weight=\"balanced\", max_iter=1000\n",
    ")\n",
    "\n",
    "# Perform cross-validated predictions on the training data\n",
    "# estimator: the logistic regression model\n",
    "# X: feature matrix for the training set\n",
    "# y: majority vote labels for the training set\n",
    "# cv: StratifiedKFold cross-validator with 10 splits, shuffling, and a fixed random state for reproducibility\n",
    "# method='predict_proba': returns the predicted probabilities for each class\n",
    "pred_probs_train = cross_val_predict(\n",
    "    estimator=model_lr_crowdlab_train,\n",
    "    X=X_train,\n",
    "    y=crowdlab_majority_vote_train,\n",
    "    cv=StratifiedKFold(n_splits=10, shuffle=True, random_state=271828),\n",
    "    method=\"predict_proba\",\n",
    ")\n",
    "\n",
    "# Calculate the quality of the labels provided by multiple annotators\n",
    "# L_train_crowdlab: label matrix with np.nan for abstains\n",
    "# pred_probs_train: predicted probabilities from the logistic regression model\n",
    "# verbose=False: disables verbose output\n",
    "labels_quality_train = get_label_quality_multiannotator(\n",
    "    L_train_crowdlab, pred_probs_train, verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['label_quality', 'detailed_label_quality', 'annotator_stats'])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_quality_train.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "consensus_label",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "consensus_quality_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "annotator_agreement",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "num_annotations",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "a64be1b6-0d3a-45fb-882c-dd41a495a00b",
       "rows": [
        [
         "0",
         "1",
         "0.5243525228883563",
         "0.5",
         "4"
        ],
        [
         "1",
         "0",
         "0.9866320503750684",
         "1.0",
         "3"
        ],
        [
         "2",
         "0",
         "0.9909481099981039",
         "1.0",
         "2"
        ],
        [
         "3",
         "1",
         "0.957038206434969",
         "1.0",
         "1"
        ],
        [
         "4",
         "1",
         "0.9292271663394653",
         "1.0",
         "2"
        ],
        [
         "5",
         "0",
         "0.880520071472162",
         "0.5",
         "2"
        ],
        [
         "6",
         "1",
         "0.9668430366576719",
         "1.0",
         "2"
        ],
        [
         "7",
         "0",
         "0.6651530867667242",
         "0.5",
         "2"
        ],
        [
         "8",
         "1",
         "0.6221344775972008",
         "0.6666666666666666",
         "3"
        ],
        [
         "9",
         "1",
         "0.9752970409045346",
         "1.0",
         "1"
        ],
        [
         "10",
         "1",
         "0.9617892994180745",
         "1.0",
         "2"
        ],
        [
         "11",
         "0",
         "0.9519069147635681",
         "1.0",
         "2"
        ],
        [
         "12",
         "1",
         "0.9665020574958787",
         "1.0",
         "2"
        ],
        [
         "13",
         "1",
         "0.9690561366717944",
         "1.0",
         "2"
        ],
        [
         "14",
         "0",
         "0.9952670534693656",
         "1.0",
         "1"
        ],
        [
         "15",
         "0",
         "0.9688910379060451",
         "1.0",
         "3"
        ],
        [
         "16",
         "0",
         "0.6209883545110862",
         "0.0",
         "1"
        ],
        [
         "17",
         "1",
         "0.9558451492265454",
         "1.0",
         "1"
        ],
        [
         "18",
         "0",
         "0.6613227526960018",
         "0.6",
         "5"
        ],
        [
         "19",
         "1",
         "0.5839383215288506",
         "0.5",
         "2"
        ],
        [
         "20",
         "0",
         "0.959980642040483",
         "1.0",
         "3"
        ],
        [
         "21",
         "1",
         "0.943940673027455",
         "0.6666666666666666",
         "3"
        ],
        [
         "22",
         "1",
         "0.966672020817889",
         "1.0",
         "2"
        ],
        [
         "23",
         "1",
         "0.9546845504119842",
         "1.0",
         "3"
        ],
        [
         "24",
         "1",
         "0.9576711216689653",
         "1.0",
         "3"
        ],
        [
         "25",
         "1",
         "0.9599238107285761",
         "1.0",
         "4"
        ],
        [
         "26",
         "1",
         "0.925235341109368",
         "1.0",
         "1"
        ],
        [
         "27",
         "1",
         "0.9722191661890236",
         "1.0",
         "2"
        ],
        [
         "28",
         "1",
         "0.9665590034067513",
         "1.0",
         "2"
        ],
        [
         "29",
         "0",
         "0.9796107598396557",
         "0.75",
         "4"
        ],
        [
         "30",
         "0",
         "0.9946290590408045",
         "1.0",
         "1"
        ],
        [
         "31",
         "1",
         "0.954451939742063",
         "1.0",
         "2"
        ],
        [
         "32",
         "1",
         "0.9637969238045969",
         "1.0",
         "2"
        ],
        [
         "33",
         "1",
         "0.6490340421498738",
         "1.0",
         "2"
        ],
        [
         "34",
         "0",
         "0.9806609679638882",
         "1.0",
         "4"
        ],
        [
         "35",
         "1",
         "0.9507590893515626",
         "1.0",
         "2"
        ],
        [
         "36",
         "0",
         "0.9968840143517435",
         "1.0",
         "1"
        ],
        [
         "37",
         "1",
         "0.8665477517807635",
         "1.0",
         "2"
        ],
        [
         "38",
         "1",
         "0.9167525265842252",
         "1.0",
         "1"
        ],
        [
         "39",
         "0",
         "0.9730628521460144",
         "1.0",
         "1"
        ],
        [
         "40",
         "1",
         "0.9625494995647985",
         "1.0",
         "3"
        ],
        [
         "41",
         "1",
         "0.9719137015649394",
         "1.0",
         "2"
        ],
        [
         "42",
         "0",
         "0.9658618151460115",
         "1.0",
         "2"
        ],
        [
         "43",
         "1",
         "0.9031421057297149",
         "1.0",
         "2"
        ],
        [
         "44",
         "1",
         "0.9643108116972037",
         "1.0",
         "1"
        ],
        [
         "45",
         "1",
         "0.9318816061316714",
         "1.0",
         "3"
        ],
        [
         "46",
         "1",
         "0.9606804320206559",
         "1.0",
         "3"
        ],
        [
         "47",
         "0",
         "0.9881953660282161",
         "1.0",
         "2"
        ],
        [
         "48",
         "1",
         "0.9689817642677824",
         "1.0",
         "2"
        ],
        [
         "49",
         "0",
         "0.5370667358004865",
         "0.3333333333333333",
         "3"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 85831
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>consensus_label</th>\n",
       "      <th>consensus_quality_score</th>\n",
       "      <th>annotator_agreement</th>\n",
       "      <th>num_annotations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.524353</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.986632</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.990948</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.957038</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.929227</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85826</th>\n",
       "      <td>1</td>\n",
       "      <td>0.933930</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85827</th>\n",
       "      <td>1</td>\n",
       "      <td>0.947261</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85828</th>\n",
       "      <td>1</td>\n",
       "      <td>0.976285</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85829</th>\n",
       "      <td>1</td>\n",
       "      <td>0.964287</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85830</th>\n",
       "      <td>1</td>\n",
       "      <td>0.960103</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85831 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       consensus_label  consensus_quality_score  annotator_agreement  \\\n",
       "0                    1                 0.524353                  0.5   \n",
       "1                    0                 0.986632                  1.0   \n",
       "2                    0                 0.990948                  1.0   \n",
       "3                    1                 0.957038                  1.0   \n",
       "4                    1                 0.929227                  1.0   \n",
       "...                ...                      ...                  ...   \n",
       "85826                1                 0.933930                  1.0   \n",
       "85827                1                 0.947261                  1.0   \n",
       "85828                1                 0.976285                  1.0   \n",
       "85829                1                 0.964287                  1.0   \n",
       "85830                1                 0.960103                  1.0   \n",
       "\n",
       "       num_annotations  \n",
       "0                    4  \n",
       "1                    3  \n",
       "2                    2  \n",
       "3                    1  \n",
       "4                    2  \n",
       "...                ...  \n",
       "85826                1  \n",
       "85827                1  \n",
       "85828                1  \n",
       "85829                3  \n",
       "85830                3  \n",
       "\n",
       "[85831 rows x 4 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Access the 'label_quality' column from the labels_quality_train DataFrame\n",
    "# This column contains the improved consensus labels using information from each of the annotators and the model\n",
    "# The DataFrame also includes information about the number of annotations, annotator agreement, and consensus quality score for each example\n",
    "improved_consensus_labels = labels_quality_train[\"label_quality\"]\n",
    "\n",
    "# Display the improved consensus labels\n",
    "improved_consensus_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "quality_annotator_0",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "quality_annotator_1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "quality_annotator_2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "quality_annotator_3",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "quality_annotator_4",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "quality_annotator_5",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "quality_annotator_6",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "quality_annotator_7",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "quality_annotator_8",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "quality_annotator_9",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "quality_annotator_10",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "quality_annotator_11",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "quality_annotator_12",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "quality_annotator_13",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "quality_annotator_14",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "quality_annotator_15",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "quality_annotator_16",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "quality_annotator_17",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "quality_annotator_18",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "quality_annotator_19",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "quality_annotator_20",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "quality_annotator_21",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "quality_annotator_22",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "quality_annotator_23",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "quality_annotator_24",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "quality_annotator_25",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "quality_annotator_26",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "quality_annotator_27",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "6cdb2a50-e336-4bee-bacc-92f75b729f77",
       "rows": [
        [
         "0",
         null,
         null,
         null,
         null,
         "0.5243525228883563",
         "0.5243525228883563",
         null,
         null,
         null,
         null,
         null,
         null,
         "0.4756474771116437",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0.4756474771116437",
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "1",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0.9866320503750684",
         "0.9866320503750684",
         null,
         null,
         "0.9866320503750684",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "2",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0.9909481099981039",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0.9909481099981039",
         null,
         null,
         null
        ],
        [
         "3",
         null,
         null,
         null,
         null,
         null,
         null,
         "0.957038206434969",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "4",
         null,
         null,
         null,
         null,
         "0.9292271663394653",
         "0.9292271663394653",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "5",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0.11947992852783793",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0.880520071472162",
         null,
         null,
         null
        ],
        [
         "6",
         null,
         null,
         null,
         null,
         "0.9668430366576719",
         "0.9668430366576719",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "7",
         null,
         null,
         null,
         null,
         null,
         "0.33484691323327587",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0.6651530867667242",
         null
        ],
        [
         "8",
         null,
         null,
         null,
         null,
         "0.6221344775972008",
         "0.6221344775972008",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0.37786552240279925"
        ],
        [
         "9",
         null,
         null,
         "0.9752970409045346",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "10",
         null,
         null,
         null,
         null,
         "0.9617892994180745",
         "0.9617892994180745",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "11",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0.9519069147635681",
         "0.9519069147635681",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "12",
         null,
         "0.9665020574958787",
         "0.9665020574958787",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "13",
         null,
         null,
         null,
         null,
         "0.9690561366717944",
         "0.9690561366717944",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "14",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0.9952670534693656",
         null,
         null,
         null
        ],
        [
         "15",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0.9688910379060451",
         null,
         null,
         null,
         "0.9688910379060451",
         null,
         null,
         "0.9688910379060451"
        ],
        [
         "16",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0.3790116454889139",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "17",
         null,
         null,
         "0.9558451492265454",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "18",
         null,
         "0.33867724730399795",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0.33867724730399795",
         null,
         null,
         null,
         "0.6613227526960018",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0.6613227526960018",
         null,
         "0.6613227526960018"
        ],
        [
         "19",
         null,
         null,
         null,
         null,
         null,
         "0.5839383215288506",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0.41606167847114955",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "20",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0.959980642040483",
         null,
         "0.959980642040483",
         "0.959980642040483",
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "21",
         null,
         null,
         null,
         null,
         "0.943940673027455",
         "0.943940673027455",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0.056059326972545065",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "22",
         null,
         null,
         "0.966672020817889",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0.966672020817889",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "23",
         "0.9546845504119842",
         null,
         null,
         "0.9546845504119842",
         null,
         null,
         "0.9546845504119842",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "24",
         "0.9576711216689653",
         null,
         null,
         "0.9576711216689653",
         null,
         null,
         "0.9576711216689653",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "25",
         "0.9599238107285761",
         "0.9599238107285761",
         null,
         null,
         null,
         null,
         "0.9599238107285761",
         "0.9599238107285761",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "26",
         null,
         null,
         null,
         null,
         null,
         null,
         "0.925235341109368",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "27",
         null,
         null,
         null,
         null,
         null,
         null,
         "0.9722191661890236",
         "0.9722191661890236",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "28",
         "0.9665590034067513",
         null,
         null,
         null,
         null,
         null,
         "0.9665590034067513",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "29",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0.02038924016034419",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0.9796107598396557",
         "0.9796107598396557",
         null,
         "0.9796107598396557",
         null,
         null,
         null
        ],
        [
         "30",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0.9946290590408045",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "31",
         null,
         null,
         "0.954451939742063",
         null,
         null,
         "0.954451939742063",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "32",
         null,
         null,
         "0.9637969238045969",
         null,
         null,
         null,
         "0.9637969238045969",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "33",
         null,
         null,
         null,
         null,
         "0.6490340421498738",
         "0.6490340421498738",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "34",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0.9806609679638882",
         "0.9806609679638882",
         "0.9806609679638882",
         null,
         null,
         null,
         "0.9806609679638882",
         null,
         null,
         null,
         null
        ],
        [
         "35",
         null,
         null,
         null,
         null,
         "0.9507590893515626",
         "0.9507590893515626",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "36",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0.9968840143517435",
         null,
         null,
         null
        ],
        [
         "37",
         null,
         null,
         null,
         null,
         "0.8665477517807635",
         "0.8665477517807635",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "38",
         null,
         "0.9167525265842252",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "39",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0.9730628521460144",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "40",
         null,
         null,
         "0.9625494995647985",
         null,
         "0.9625494995647985",
         "0.9625494995647985",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "41",
         null,
         null,
         "0.9719137015649394",
         null,
         null,
         null,
         null,
         "0.9719137015649394",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "42",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0.9658618151460115",
         null,
         "0.9658618151460115",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "43",
         null,
         null,
         null,
         null,
         "0.9031421057297149",
         "0.9031421057297149",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "44",
         null,
         "0.9643108116972037",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "45",
         null,
         null,
         null,
         null,
         "0.9318816061316714",
         "0.9318816061316714",
         null,
         null,
         null,
         null,
         null,
         "0.9318816061316714",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "46",
         null,
         "0.9606804320206559",
         null,
         null,
         "0.9606804320206559",
         "0.9606804320206559",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "47",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0.9881953660282161",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0.9881953660282161",
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "48",
         null,
         null,
         null,
         null,
         "0.9689817642677824",
         "0.9689817642677824",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "49",
         null,
         null,
         null,
         null,
         "0.4629332641995137",
         "0.4629332641995137",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0.5370667358004865",
         null,
         null,
         null
        ]
       ],
       "shape": {
        "columns": 28,
        "rows": 85831
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quality_annotator_0</th>\n",
       "      <th>quality_annotator_1</th>\n",
       "      <th>quality_annotator_2</th>\n",
       "      <th>quality_annotator_3</th>\n",
       "      <th>quality_annotator_4</th>\n",
       "      <th>quality_annotator_5</th>\n",
       "      <th>quality_annotator_6</th>\n",
       "      <th>quality_annotator_7</th>\n",
       "      <th>quality_annotator_8</th>\n",
       "      <th>quality_annotator_9</th>\n",
       "      <th>quality_annotator_10</th>\n",
       "      <th>quality_annotator_11</th>\n",
       "      <th>quality_annotator_12</th>\n",
       "      <th>quality_annotator_13</th>\n",
       "      <th>quality_annotator_14</th>\n",
       "      <th>quality_annotator_15</th>\n",
       "      <th>quality_annotator_16</th>\n",
       "      <th>quality_annotator_17</th>\n",
       "      <th>quality_annotator_18</th>\n",
       "      <th>quality_annotator_19</th>\n",
       "      <th>quality_annotator_20</th>\n",
       "      <th>quality_annotator_21</th>\n",
       "      <th>quality_annotator_22</th>\n",
       "      <th>quality_annotator_23</th>\n",
       "      <th>quality_annotator_24</th>\n",
       "      <th>quality_annotator_25</th>\n",
       "      <th>quality_annotator_26</th>\n",
       "      <th>quality_annotator_27</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.524353</td>\n",
       "      <td>0.524353</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.475647</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.475647</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.986632</td>\n",
       "      <td>0.986632</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.986632</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.990948</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.990948</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.957038</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.929227</td>\n",
       "      <td>0.929227</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85826</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.933930</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85827</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.947261</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85828</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.976285</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85829</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.964287</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.964287</td>\n",
       "      <td>0.964287</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85830</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.960103</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.960103</td>\n",
       "      <td>0.960103</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85831 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       quality_annotator_0  quality_annotator_1  quality_annotator_2  \\\n",
       "0                      NaN                  NaN                  NaN   \n",
       "1                      NaN                  NaN                  NaN   \n",
       "2                      NaN                  NaN                  NaN   \n",
       "3                      NaN                  NaN                  NaN   \n",
       "4                      NaN                  NaN                  NaN   \n",
       "...                    ...                  ...                  ...   \n",
       "85826                  NaN                  NaN                  NaN   \n",
       "85827                  NaN                  NaN                  NaN   \n",
       "85828                  NaN             0.976285                  NaN   \n",
       "85829                  NaN                  NaN                  NaN   \n",
       "85830                  NaN                  NaN             0.960103   \n",
       "\n",
       "       quality_annotator_3  quality_annotator_4  quality_annotator_5  \\\n",
       "0                      NaN             0.524353             0.524353   \n",
       "1                      NaN                  NaN                  NaN   \n",
       "2                      NaN                  NaN                  NaN   \n",
       "3                      NaN                  NaN                  NaN   \n",
       "4                      NaN             0.929227             0.929227   \n",
       "...                    ...                  ...                  ...   \n",
       "85826                  NaN                  NaN                  NaN   \n",
       "85827                  NaN                  NaN                  NaN   \n",
       "85828                  NaN                  NaN                  NaN   \n",
       "85829             0.964287                  NaN                  NaN   \n",
       "85830                  NaN             0.960103             0.960103   \n",
       "\n",
       "       quality_annotator_6  quality_annotator_7  quality_annotator_8  \\\n",
       "0                      NaN                  NaN                  NaN   \n",
       "1                      NaN                  NaN                  NaN   \n",
       "2                      NaN                  NaN                  NaN   \n",
       "3                 0.957038                  NaN                  NaN   \n",
       "4                      NaN                  NaN                  NaN   \n",
       "...                    ...                  ...                  ...   \n",
       "85826                  NaN             0.933930                  NaN   \n",
       "85827             0.947261                  NaN                  NaN   \n",
       "85828                  NaN                  NaN                  NaN   \n",
       "85829             0.964287             0.964287                  NaN   \n",
       "85830                  NaN                  NaN                  NaN   \n",
       "\n",
       "       quality_annotator_9  quality_annotator_10  quality_annotator_11  \\\n",
       "0                      NaN                   NaN                   NaN   \n",
       "1                      NaN                   NaN                   NaN   \n",
       "2                      NaN                   NaN                   NaN   \n",
       "3                      NaN                   NaN                   NaN   \n",
       "4                      NaN                   NaN                   NaN   \n",
       "...                    ...                   ...                   ...   \n",
       "85826                  NaN                   NaN                   NaN   \n",
       "85827                  NaN                   NaN                   NaN   \n",
       "85828                  NaN                   NaN                   NaN   \n",
       "85829                  NaN                   NaN                   NaN   \n",
       "85830                  NaN                   NaN                   NaN   \n",
       "\n",
       "       quality_annotator_12  quality_annotator_13  quality_annotator_14  \\\n",
       "0                  0.475647                   NaN                   NaN   \n",
       "1                       NaN                   NaN              0.986632   \n",
       "2                       NaN                   NaN              0.990948   \n",
       "3                       NaN                   NaN                   NaN   \n",
       "4                       NaN                   NaN                   NaN   \n",
       "...                     ...                   ...                   ...   \n",
       "85826                   NaN                   NaN                   NaN   \n",
       "85827                   NaN                   NaN                   NaN   \n",
       "85828                   NaN                   NaN                   NaN   \n",
       "85829                   NaN                   NaN                   NaN   \n",
       "85830                   NaN                   NaN                   NaN   \n",
       "\n",
       "       quality_annotator_15  quality_annotator_16  quality_annotator_17  \\\n",
       "0                       NaN                   NaN                   NaN   \n",
       "1                  0.986632                   NaN                   NaN   \n",
       "2                       NaN                   NaN                   NaN   \n",
       "3                       NaN                   NaN                   NaN   \n",
       "4                       NaN                   NaN                   NaN   \n",
       "...                     ...                   ...                   ...   \n",
       "85826                   NaN                   NaN                   NaN   \n",
       "85827                   NaN                   NaN                   NaN   \n",
       "85828                   NaN                   NaN                   NaN   \n",
       "85829                   NaN                   NaN                   NaN   \n",
       "85830                   NaN                   NaN                   NaN   \n",
       "\n",
       "       quality_annotator_18  quality_annotator_19  quality_annotator_20  \\\n",
       "0                       NaN                   NaN              0.475647   \n",
       "1                  0.986632                   NaN                   NaN   \n",
       "2                       NaN                   NaN                   NaN   \n",
       "3                       NaN                   NaN                   NaN   \n",
       "4                       NaN                   NaN                   NaN   \n",
       "...                     ...                   ...                   ...   \n",
       "85826                   NaN                   NaN                   NaN   \n",
       "85827                   NaN                   NaN                   NaN   \n",
       "85828                   NaN                   NaN                   NaN   \n",
       "85829                   NaN                   NaN                   NaN   \n",
       "85830                   NaN                   NaN                   NaN   \n",
       "\n",
       "       quality_annotator_21  quality_annotator_22  quality_annotator_23  \\\n",
       "0                       NaN                   NaN                   NaN   \n",
       "1                       NaN                   NaN                   NaN   \n",
       "2                       NaN                   NaN                   NaN   \n",
       "3                       NaN                   NaN                   NaN   \n",
       "4                       NaN                   NaN                   NaN   \n",
       "...                     ...                   ...                   ...   \n",
       "85826                   NaN                   NaN                   NaN   \n",
       "85827                   NaN                   NaN                   NaN   \n",
       "85828                   NaN                   NaN                   NaN   \n",
       "85829                   NaN                   NaN                   NaN   \n",
       "85830                   NaN                   NaN                   NaN   \n",
       "\n",
       "       quality_annotator_24  quality_annotator_25  quality_annotator_26  \\\n",
       "0                       NaN                   NaN                   NaN   \n",
       "1                       NaN                   NaN                   NaN   \n",
       "2                  0.990948                   NaN                   NaN   \n",
       "3                       NaN                   NaN                   NaN   \n",
       "4                       NaN                   NaN                   NaN   \n",
       "...                     ...                   ...                   ...   \n",
       "85826                   NaN                   NaN                   NaN   \n",
       "85827                   NaN                   NaN                   NaN   \n",
       "85828                   NaN                   NaN                   NaN   \n",
       "85829                   NaN                   NaN                   NaN   \n",
       "85830                   NaN                   NaN                   NaN   \n",
       "\n",
       "       quality_annotator_27  \n",
       "0                       NaN  \n",
       "1                       NaN  \n",
       "2                       NaN  \n",
       "3                       NaN  \n",
       "4                       NaN  \n",
       "...                     ...  \n",
       "85826                   NaN  \n",
       "85827                   NaN  \n",
       "85828                   NaN  \n",
       "85829                   NaN  \n",
       "85830                   NaN  \n",
       "\n",
       "[85831 rows x 28 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Access the 'detailed_label_quality' column from the labels_quality_train DataFrame\n",
    "# This column contains the label quality score for each label given by every annotator\n",
    "# The label quality score provides insights into the reliability of each annotator's labels\n",
    "detailed_label_quality_scores = labels_quality_train[\"detailed_label_quality\"]\n",
    "\n",
    "# Display the detailed label quality scores\n",
    "detailed_label_quality_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "annotator_quality",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "agreement_with_consensus",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "worst_class",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "num_examples_labeled",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "bf09daf6-6cd5-4f9a-9309-28c08389212e",
       "rows": [
        [
         "9",
         "0.30942982978257283",
         "0.2813067150635209",
         "1",
         "2204"
        ],
        [
         "14",
         "0.5613338226194815",
         "0.5757869249394673",
         "0",
         "4130"
        ],
        [
         "8",
         "0.5901593799777026",
         "0.5887323943661972",
         "1",
         "355"
        ],
        [
         "13",
         "0.7035984415283367",
         "0.7295546558704453",
         "0",
         "1235"
        ],
        [
         "23",
         "0.7381752418773557",
         "0.7574739670809539",
         "0",
         "2977"
        ],
        [
         "18",
         "0.8106042649171157",
         "0.8413197172034564",
         "0",
         "2546"
        ],
        [
         "12",
         "0.8248803359563575",
         "0.8503311258278146",
         "0",
         "2265"
        ],
        [
         "7",
         "0.8302562489168586",
         "0.8346077598414047",
         "1",
         "7062"
        ],
        [
         "21",
         "0.841195864377313",
         "0.8819112627986349",
         "0",
         "1465"
        ],
        [
         "26",
         "0.8502470884343618",
         "0.8947368421052632",
         "0",
         "1178"
        ],
        [
         "20",
         "0.8554073636124315",
         "0.8914273737162021",
         "0",
         "4771"
        ],
        [
         "16",
         "0.8705503257700511",
         "0.9029535864978903",
         "0",
         "474"
        ],
        [
         "19",
         "0.874792827182884",
         "0.9115183246073298",
         "0",
         "7640"
        ],
        [
         "10",
         "0.8777499376550026",
         "0.898099474322685",
         "1",
         "2473"
        ],
        [
         "25",
         "0.8817422928664911",
         "0.9283900457084815",
         "0",
         "1969"
        ],
        [
         "24",
         "0.9068286296150472",
         "0.952158273381295",
         "0",
         "5560"
        ],
        [
         "17",
         "0.9104207268182325",
         "0.9520685256059778",
         "0",
         "5487"
        ],
        [
         "27",
         "0.9133609540930675",
         "0.9565524549629106",
         "0",
         "2831"
        ],
        [
         "5",
         "0.9230946026320661",
         "0.9548715688435074",
         "1",
         "40839"
        ],
        [
         "22",
         "0.923809826446685",
         "0.9653579676674365",
         "0",
         "433"
        ],
        [
         "15",
         "0.9261989800868993",
         "0.9727917981072555",
         "0",
         "2536"
        ],
        [
         "4",
         "0.9318625101548852",
         "0.9690806139174489",
         "1",
         "26844"
        ],
        [
         "1",
         "0.9336919531283976",
         "0.9589381355274392",
         "1",
         "12883"
        ],
        [
         "0",
         "0.9382141811111344",
         "0.9675234835796985",
         "1",
         "13733"
        ],
        [
         "11",
         "0.938576073385716",
         "0.9746070133010882",
         "1",
         "1654"
        ],
        [
         "3",
         "0.9482800407776055",
         "0.9777041942604856",
         "1",
         "4530"
        ],
        [
         "2",
         "0.9559547876278912",
         "0.9868629998556374",
         "1",
         "20781"
        ],
        [
         "6",
         "0.957422800380437",
         "0.9932310946589106",
         "1",
         "18910"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 28
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotator_quality</th>\n",
       "      <th>agreement_with_consensus</th>\n",
       "      <th>worst_class</th>\n",
       "      <th>num_examples_labeled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.309430</td>\n",
       "      <td>0.281307</td>\n",
       "      <td>1</td>\n",
       "      <td>2204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.561334</td>\n",
       "      <td>0.575787</td>\n",
       "      <td>0</td>\n",
       "      <td>4130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.590159</td>\n",
       "      <td>0.588732</td>\n",
       "      <td>1</td>\n",
       "      <td>355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.703598</td>\n",
       "      <td>0.729555</td>\n",
       "      <td>0</td>\n",
       "      <td>1235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.738175</td>\n",
       "      <td>0.757474</td>\n",
       "      <td>0</td>\n",
       "      <td>2977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.810604</td>\n",
       "      <td>0.841320</td>\n",
       "      <td>0</td>\n",
       "      <td>2546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.824880</td>\n",
       "      <td>0.850331</td>\n",
       "      <td>0</td>\n",
       "      <td>2265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.830256</td>\n",
       "      <td>0.834608</td>\n",
       "      <td>1</td>\n",
       "      <td>7062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.841196</td>\n",
       "      <td>0.881911</td>\n",
       "      <td>0</td>\n",
       "      <td>1465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.850247</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0</td>\n",
       "      <td>1178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.855407</td>\n",
       "      <td>0.891427</td>\n",
       "      <td>0</td>\n",
       "      <td>4771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.870550</td>\n",
       "      <td>0.902954</td>\n",
       "      <td>0</td>\n",
       "      <td>474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.874793</td>\n",
       "      <td>0.911518</td>\n",
       "      <td>0</td>\n",
       "      <td>7640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.877750</td>\n",
       "      <td>0.898099</td>\n",
       "      <td>1</td>\n",
       "      <td>2473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.881742</td>\n",
       "      <td>0.928390</td>\n",
       "      <td>0</td>\n",
       "      <td>1969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.906829</td>\n",
       "      <td>0.952158</td>\n",
       "      <td>0</td>\n",
       "      <td>5560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.910421</td>\n",
       "      <td>0.952069</td>\n",
       "      <td>0</td>\n",
       "      <td>5487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.913361</td>\n",
       "      <td>0.956552</td>\n",
       "      <td>0</td>\n",
       "      <td>2831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.923095</td>\n",
       "      <td>0.954872</td>\n",
       "      <td>1</td>\n",
       "      <td>40839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.923810</td>\n",
       "      <td>0.965358</td>\n",
       "      <td>0</td>\n",
       "      <td>433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.926199</td>\n",
       "      <td>0.972792</td>\n",
       "      <td>0</td>\n",
       "      <td>2536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.931863</td>\n",
       "      <td>0.969081</td>\n",
       "      <td>1</td>\n",
       "      <td>26844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.933692</td>\n",
       "      <td>0.958938</td>\n",
       "      <td>1</td>\n",
       "      <td>12883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.938214</td>\n",
       "      <td>0.967523</td>\n",
       "      <td>1</td>\n",
       "      <td>13733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.938576</td>\n",
       "      <td>0.974607</td>\n",
       "      <td>1</td>\n",
       "      <td>1654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.948280</td>\n",
       "      <td>0.977704</td>\n",
       "      <td>1</td>\n",
       "      <td>4530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.955955</td>\n",
       "      <td>0.986863</td>\n",
       "      <td>1</td>\n",
       "      <td>20781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.957423</td>\n",
       "      <td>0.993231</td>\n",
       "      <td>1</td>\n",
       "      <td>18910</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    annotator_quality  agreement_with_consensus  worst_class  \\\n",
       "9            0.309430                  0.281307            1   \n",
       "14           0.561334                  0.575787            0   \n",
       "8            0.590159                  0.588732            1   \n",
       "13           0.703598                  0.729555            0   \n",
       "23           0.738175                  0.757474            0   \n",
       "18           0.810604                  0.841320            0   \n",
       "12           0.824880                  0.850331            0   \n",
       "7            0.830256                  0.834608            1   \n",
       "21           0.841196                  0.881911            0   \n",
       "26           0.850247                  0.894737            0   \n",
       "20           0.855407                  0.891427            0   \n",
       "16           0.870550                  0.902954            0   \n",
       "19           0.874793                  0.911518            0   \n",
       "10           0.877750                  0.898099            1   \n",
       "25           0.881742                  0.928390            0   \n",
       "24           0.906829                  0.952158            0   \n",
       "17           0.910421                  0.952069            0   \n",
       "27           0.913361                  0.956552            0   \n",
       "5            0.923095                  0.954872            1   \n",
       "22           0.923810                  0.965358            0   \n",
       "15           0.926199                  0.972792            0   \n",
       "4            0.931863                  0.969081            1   \n",
       "1            0.933692                  0.958938            1   \n",
       "0            0.938214                  0.967523            1   \n",
       "11           0.938576                  0.974607            1   \n",
       "3            0.948280                  0.977704            1   \n",
       "2            0.955955                  0.986863            1   \n",
       "6            0.957423                  0.993231            1   \n",
       "\n",
       "    num_examples_labeled  \n",
       "9                   2204  \n",
       "14                  4130  \n",
       "8                    355  \n",
       "13                  1235  \n",
       "23                  2977  \n",
       "18                  2546  \n",
       "12                  2265  \n",
       "7                   7062  \n",
       "21                  1465  \n",
       "26                  1178  \n",
       "20                  4771  \n",
       "16                   474  \n",
       "19                  7640  \n",
       "10                  2473  \n",
       "25                  1969  \n",
       "24                  5560  \n",
       "17                  5487  \n",
       "27                  2831  \n",
       "5                  40839  \n",
       "22                   433  \n",
       "15                  2536  \n",
       "4                  26844  \n",
       "1                  12883  \n",
       "0                  13733  \n",
       "11                  1654  \n",
       "3                   4530  \n",
       "2                  20781  \n",
       "6                  18910  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Access the 'annotator_stats' column from the labels_quality_train DataFrame\n",
    "# This column provides the annotator quality score for each annotator, alongside other information such as:\n",
    "# - The number of examples each annotator labeled\n",
    "# - Their agreement with the consensus labels\n",
    "# - The class they perform the worst at\n",
    "# The annotator_stats DataFrame is sorted by increasing annotator_quality, showing the worst annotators first\n",
    "annotator_stats = labels_quality_train[\"annotator_stats\"]\n",
    "\n",
    "# Display the annotator statistics\n",
    "annotator_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Label Model name: CrowdLab Model\n",
      "Metric                                   Score\n",
      "=============================================\n",
      "Accuracy Score:                        0.95197\n",
      "Balanced Accuracy Score:               0.94242\n",
      "F1 Score (weighted):                   0.95194\n",
      "Cohen Kappa Score:                     0.88595\n",
      "Matthews Correlation Coefficient:      0.88595\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92      7050\n",
      "           1       0.96      0.97      0.97     16290\n",
      "\n",
      "    accuracy                           0.95     23340\n",
      "   macro avg       0.94      0.94      0.94     23340\n",
      "weighted avg       0.95      0.95      0.95     23340\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "Class 0 has 576 false negatives and 545 false positives.\n",
      "Class 1 has 545 false negatives and 576 false positives.\n",
      "The total number of errors is 1121 out of 23340 samples (error rate: 0.0480).\n",
      "Predicted      0       1     All\n",
      "True                            \n",
      "0          6,474     576   7,050\n",
      "1            545  15,745  16,290\n",
      "All        7,019  16,321  23,340\n"
     ]
    }
   ],
   "source": [
    "# Extract the consensus labels from the 'label_quality' column of the labels_quality_train DataFrame\n",
    "# These labels represent the improved consensus labels using information from each of the annotators and the model\n",
    "y_train_crowdlab = labels_quality_train[\"label_quality\"][\"consensus_label\"].values\n",
    "\n",
    "# Train and evaluate a model using the training features (X_train) and the consensus labels (y_train_crowdlab)\n",
    "# The function 'train_and_evaluate_model' trains a machine learning model and evaluates its performance on the test set\n",
    "results_crowdlab_em = train_and_evaluate_model(\n",
    "    X_train, y_train_crowdlab, X_test, y_test, \"CrowdLab Model\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Label Model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Matthews Correlation",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Type",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "1b07dae2-0547-4809-8df8-ae4c1b0d3f27",
       "rows": [
        [
         "4",
         "Full Supervision on Dev Set + End Model",
         "0.9062052593266651",
         "Full supervision"
        ],
        [
         "11",
         "Generative Model + End Model",
         "0.889410391987121",
         "LM + EM"
        ],
        [
         "2",
         "Snorkel MeTaL + End Model",
         "0.8889251584442059",
         "LM + EM"
        ],
        [
         "9",
         "Dawid-Skene + End Model",
         "0.8860193750293153",
         "LM + EM"
        ],
        [
         "15",
         "CrowdLab Model + End Model",
         "0.8859510151005762",
         "LM + EM"
        ],
        [
         "3",
         "Majority Label Voter + End Model",
         "0.8761199167917382",
         "LM + EM"
        ],
        [
         "5",
         "HyperLabelModel Unsupervised + End Model",
         "0.8443216796321857",
         "LM + EM"
        ],
        [
         "7",
         "HyperLabelModel Semi-Supervised + End Model",
         "0.8339443855395706",
         "LM + EM"
        ],
        [
         "10",
         "Dawid-Skene",
         "0.7249990758311258",
         "LM alone"
        ],
        [
         "13",
         "FlyingSquid + End Model",
         "0.7156224802187824",
         "LM + EM"
        ],
        [
         "6",
         "HyperLabelModel Unsupervised",
         "0.7040155349376804",
         "LM alone"
        ],
        [
         "8",
         "HyperLabelModel Semi-Supervised",
         "0.6897673717851329",
         "LM alone"
        ],
        [
         "0",
         "Snorkel MeTaL",
         "0.6857925272523081",
         "LM alone"
        ],
        [
         "1",
         "Majority Label Voter",
         "0.6712213834075154",
         "LM alone"
        ],
        [
         "12",
         "Generative Model",
         "0.6465167480320975",
         "LM alone"
        ],
        [
         "14",
         "FlyingSquid",
         "0.5912699244529404",
         "LM alone"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 16
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label Model</th>\n",
       "      <th>Matthews Correlation</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Full Supervision on Dev Set + End Model</td>\n",
       "      <td>0.906205</td>\n",
       "      <td>Full supervision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Generative Model + End Model</td>\n",
       "      <td>0.889410</td>\n",
       "      <td>LM + EM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Snorkel MeTaL + End Model</td>\n",
       "      <td>0.888925</td>\n",
       "      <td>LM + EM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dawid-Skene + End Model</td>\n",
       "      <td>0.886019</td>\n",
       "      <td>LM + EM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>CrowdLab Model + End Model</td>\n",
       "      <td>0.885951</td>\n",
       "      <td>LM + EM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Majority Label Voter + End Model</td>\n",
       "      <td>0.876120</td>\n",
       "      <td>LM + EM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HyperLabelModel Unsupervised + End Model</td>\n",
       "      <td>0.844322</td>\n",
       "      <td>LM + EM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HyperLabelModel Semi-Supervised + End Model</td>\n",
       "      <td>0.833944</td>\n",
       "      <td>LM + EM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Dawid-Skene</td>\n",
       "      <td>0.724999</td>\n",
       "      <td>LM alone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>FlyingSquid + End Model</td>\n",
       "      <td>0.715622</td>\n",
       "      <td>LM + EM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HyperLabelModel Unsupervised</td>\n",
       "      <td>0.704016</td>\n",
       "      <td>LM alone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HyperLabelModel Semi-Supervised</td>\n",
       "      <td>0.689767</td>\n",
       "      <td>LM alone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Snorkel MeTaL</td>\n",
       "      <td>0.685793</td>\n",
       "      <td>LM alone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Majority Label Voter</td>\n",
       "      <td>0.671221</td>\n",
       "      <td>LM alone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Generative Model</td>\n",
       "      <td>0.646517</td>\n",
       "      <td>LM alone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>FlyingSquid</td>\n",
       "      <td>0.591270</td>\n",
       "      <td>LM alone</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Label Model  Matthews Correlation  \\\n",
       "4       Full Supervision on Dev Set + End Model              0.906205   \n",
       "11                 Generative Model + End Model              0.889410   \n",
       "2                     Snorkel MeTaL + End Model              0.888925   \n",
       "9                       Dawid-Skene + End Model              0.886019   \n",
       "15                   CrowdLab Model + End Model              0.885951   \n",
       "3              Majority Label Voter + End Model              0.876120   \n",
       "5      HyperLabelModel Unsupervised + End Model              0.844322   \n",
       "7   HyperLabelModel Semi-Supervised + End Model              0.833944   \n",
       "10                                  Dawid-Skene              0.724999   \n",
       "13                      FlyingSquid + End Model              0.715622   \n",
       "6                  HyperLabelModel Unsupervised              0.704016   \n",
       "8               HyperLabelModel Semi-Supervised              0.689767   \n",
       "0                                 Snorkel MeTaL              0.685793   \n",
       "1                          Majority Label Voter              0.671221   \n",
       "12                             Generative Model              0.646517   \n",
       "14                                  FlyingSquid              0.591270   \n",
       "\n",
       "                Type  \n",
       "4   Full supervision  \n",
       "11           LM + EM  \n",
       "2            LM + EM  \n",
       "9            LM + EM  \n",
       "15           LM + EM  \n",
       "3            LM + EM  \n",
       "5            LM + EM  \n",
       "7            LM + EM  \n",
       "10          LM alone  \n",
       "13           LM + EM  \n",
       "6           LM alone  \n",
       "8           LM alone  \n",
       "0           LM alone  \n",
       "1           LM alone  \n",
       "12          LM alone  \n",
       "14          LM alone  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results.append(results_crowdlab_em)\n",
    "df_baseline = pd.DataFrame(all_results)\n",
    "df_baseline.sort_values(by=\"Matthews Correlation\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using CrowdLab to Refine Labeling Function Sets by Removing Noisy LFs\n",
    "\n",
    "As observed, models like Dawid & Skene and Majority Voting perform pretty well in many label aggregation tasks. However, advanced models such as HyperLM, FlyingSquid, and Crowdlab, offer significant advantages for complex and large-scale weak supervision scenarios due to their computational efficiency, scalability, and adaptability to diverse labeling strategies. Crowdlab especially excels in combining the strengths of label functions and classifier predictions, along with its capacity to estimate LF quality and generate high-quality consensus labels. This section will detail how Crowdlab can be specifically utilized to identify and mitigate the impact of noisy LFs by employing its quality estimation capabilities.\n",
    "\n",
    "CrowdLab enables a systematic approach to refine sets of LFs by identifying and potentially removing those that are deemed noisy or less reliable. This refinement process is based on evaluating each LF's performance through quality scores, which are derived from the LF's agreement with the consensus labels and its prediction confidence.  We can, then, strategically remove less effective LFs, potentially enhancing the overall quality of the aggregated labels.\n",
    "\n",
    "We can break down the process of noisy LF removal using Crowdlab into four key steps:\n",
    "\n",
    "1.  **Quality Score Calculation for Each Labeling Function**:\n",
    "\n",
    "    -   **Process**: The first step involves computing a complete quality score, denoted as $a_j$, for each labeling function $LF_j$. This score serves as a metric for evaluating the trustworthiness and effectiveness of each LF.\n",
    "    -   **Basis of Score**: The quality score $a_j$ is typically a composite measure, incorporating at least two key aspects of an LF's performance:\n",
    "        -   **Agreement with Consensus Labels**: This component quantifies how frequently the labels provided by $LF_j$ match the consensus labels generated by CrowdLab. High agreement indicates that the LF is generally aligned with the aggregated wisdom of all sources.\n",
    "        -   **Prediction Confidence (or Alignment with Classifier)**: This component assesses how well the predictions of $LF_j$ align with the predictions made by the classifier component within CrowdLab. LFs that frequently agree with high-confidence predictions from the classifier are generally considered more reliable. *Note*: As mentioned previously, the exact method for quantifying \"prediction confidence\" may vary, but it generally involves assessing the extent to which an LF's outputs are in sync with the classifier's probabilistic predictions or similar confidence measures.\n",
    "    -   **Weighted Combination**: The final quality score $a_j$ is typically calculated as a weighted combination of these measures, allowing for tunable emphasis on either agreement or prediction confidence, as per the formula:\n",
    "\n",
    "        $$\n",
    "        a_j = \\alpha \\times \\text{Agreement}_j + (1 - \\alpha) \\times \\text{Confidence}_j\n",
    "        $$\n",
    "\n",
    "        Where $\\alpha$ is a weighting parameter (typically between 0 and 1) that determines the balance between these two aspects of LF quality.\n",
    "\n",
    "    -   **Outcome**: This step results in a quality score $a_j$ for each $LF_j$, providing a quantifiable measure of each LF's performance within the CrowdLab framework.\n",
    "\n",
    "2.  **Ranking Labeling Functions Based on Quality Scores**:\n",
    "\n",
    "    -   **Ordering**: Once quality scores are calculated for all LFs, the next step is to rank them in descending order based on these scores. This ranking helps to systematically identify which LFs are considered most reliable (higher scores) and which are potentially less reliable or noisy (lower scores).\n",
    "    -   **Identification of Noisy LFs**: LFs that appear at the lower end of this ranking, i.e., those with significantly lower quality scores, are flagged as potentially noisy or less effective. These are the primary candidates for removal or further scrutiny.\n",
    "    -   **Purpose of Ranking**: Ranking provides a clear, ordered view of LF performance, enabling informed decisions about which LFs to retain and which to consider removing to improve overall label quality.\n",
    "\n",
    "3.  **Thresholding Quality Scores to Filter LFs**:\n",
    "\n",
    "    -   **Threshold Definition**: To automate or semi-automate the process of noisy LF removal, a quality score threshold can be established. This threshold acts as a cutoff point below which LFs are considered insufficiently reliable.\n",
    "    -   **Filtering Process**: LFs with quality scores that fall below this predefined threshold are flagged as noisy. These LFs are then considered for exclusion from the subsequent label aggregation process.\n",
    "    -   **Setting the Threshold**: The selection of an appropriate threshold may involve experimentation and validation. It might be determined based on:\n",
    "        -   **Empirical Analysis**: Examining the distribution of quality scores and identifying natural breakpoints or lower-performing clusters.\n",
    "        -   **Performance Benchmarking**: Testing different threshold values and evaluating the impact on the quality of the consensus labels on a validation set or through cross-validation.\n",
    "        -   **Domain Knowledge**: Incorporating expert insights into what constitutes an acceptable level of LF reliability in the specific application context.\n",
    "\n",
    "4.  **Validation of Noisy LF Removal**:\n",
    "\n",
    "    -   **Re-evaluation of Consensus Labels**: After identifying and excluding LFs that fall below the quality threshold, it's crucial to re-evaluate the consensus labels. This involves re-running the CrowdLab aggregation process, but this time, *without* the excluded LFs.\n",
    "    -   **Quality Metric Measurement**: To objectively assess the impact of removing the noisy LFs, appropriate quality metrics should be measured. This could include:\n",
    "        -   **Agreement with a Gold Standard**: If a small, high-quality validation set is available, measure the agreement of the new consensus labels with these gold standard labels.\n",
    "        -   **Internal Consistency Metrics**: Evaluate metrics that reflect the internal consistency and confidence of the aggregated labels, such as entropy or variance in probabilistic label distributions.\n",
    "        -   **Downstream Task Performance**: Assess the performance of a model trained on the refined consensus labels in a downstream task (if applicable). Improved performance in the downstream task is a strong indicator of enhanced label quality.\n",
    "    -   **Threshold Adjustment**: Based on the validation results, it might be necessary to adjust the quality score threshold. If removing LFs based on the initial threshold does not yield the desired improvement (or even degrades performance), the threshold could be refined (e.g., made more or less strict) and the validation process repeated. This iterative refinement helps to find an optimal set of LFs that maximizes the quality of the consensus labels.\n",
    "\n",
    "CrowdLab offers a principled and effective method for identifying and mitigating the impact of noisy labeling functions, ultimately improving the quality of weakly supervised learning pipelines. This process allows for a more strong and reliable label aggregation, enhancing the potential of weak supervision in scenarios where labeled data is limited or expensive to obtain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    28.000000\n",
       "mean      0.840280\n",
       "std       0.145182\n",
       "min       0.309430\n",
       "5%        0.571423\n",
       "10%       0.669567\n",
       "15%       0.741797\n",
       "20%       0.816315\n",
       "25%       0.828912\n",
       "30%       0.842101\n",
       "40%       0.867522\n",
       "50%       0.879746\n",
       "60%       0.911009\n",
       "70%       0.923738\n",
       "75%       0.927615\n",
       "90%       0.941487\n",
       "max       0.957423\n",
       "Name: annotator_quality, dtype: float64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate descriptive statistics for the 'annotator_quality' column in the 'annotator_stats' DataFrame\n",
    "\n",
    "labels_quality_train[\"annotator_stats\"][\"annotator_quality\"].describe(\n",
    "    percentiles=[0.05, 0.10, 0.15, 0.20, 0.25, 0.3, 0.4, 0.5, 0.6, 0.7, 0.75, 0.9]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_predict, StratifiedKFold\n",
    "\n",
    "\n",
    "def remove_worst_annotators_by_quantile(\n",
    "    quantile: float,\n",
    "    labels_quality: dict,\n",
    "    X_train: np.ndarray,\n",
    "    L_train: np.ndarray,\n",
    "    labeling_functions: list,\n",
    ") -> tuple[list, np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Remove the worst annotators based on a given quantile of annotator quality.\n",
    "\n",
    "    Args:\n",
    "        quantile (float): The quantile threshold for removing bad annotators.\n",
    "        labels_quality (dict): Dictionary containing annotator statistics.\n",
    "        X_train (np.ndarray): Training feature matrix.\n",
    "        L_train (np.ndarray): Training label matrix.\n",
    "        labeling_functions (list): list of labeling functions.\n",
    "\n",
    "    Returns:\n",
    "        tuple[list, np.ndarray, np.ndarray]: A tuple containing the filtered list of labeling functions,\n",
    "                                             the filtered training label matrix, and the filtered training feature matrix.\n",
    "    \"\"\"\n",
    "    # Calculate the quality threshold for the given quantile\n",
    "    quality_threshold = labels_quality[\"annotator_stats\"][\"annotator_quality\"].quantile(\n",
    "        quantile\n",
    "    )\n",
    "\n",
    "    # Identify annotators whose quality is below or equal to the threshold\n",
    "    bad_annotators = labels_quality[\"annotator_stats\"][\n",
    "        labels_quality[\"annotator_stats\"][\"annotator_quality\"] <= quality_threshold\n",
    "    ].index.values\n",
    "\n",
    "    print(\n",
    "        f'Annotators to remove: {bad_annotators} - ({len(bad_annotators)} out of {len(labels_quality[\"annotator_stats\"])})'\n",
    "    )\n",
    "\n",
    "    # Filter out the bad annotators from the list of labeling functions\n",
    "    good_labeling_functions = [\n",
    "        lf\n",
    "        for lf, idx in zip(labeling_functions, range(len(labeling_functions)))\n",
    "        if idx not in bad_annotators\n",
    "    ]\n",
    "\n",
    "    # Filter out the bad annotators from the label matrix\n",
    "    L_train_filtered = L_train[\n",
    "        :, [idx for idx in range(len(labeling_functions)) if idx not in bad_annotators]\n",
    "    ].copy()\n",
    "\n",
    "    # Convert the filtered label matrix to float type\n",
    "    L_train_filtered = L_train_filtered.astype(float)\n",
    "\n",
    "    # Identify rows where all labeling functions abstained (-1 indicates abstain)\n",
    "    all_abstained_rows = np.all(L_train_filtered == -1, axis=1)\n",
    "\n",
    "    # Remove rows where all labeling functions abstained\n",
    "    L_train_filtered = L_train_filtered[~all_abstained_rows]\n",
    "    X_train_filtered = X_train[~all_abstained_rows]\n",
    "\n",
    "    # Replace abstain values (-1) with NaN\n",
    "    L_train_filtered[L_train_filtered == -1] = np.nan\n",
    "\n",
    "    return good_labeling_functions, L_train_filtered, X_train_filtered\n",
    "\n",
    "\n",
    "def get_crowdlab_results(\n",
    "    L_train_crowdlab: np.ndarray,\n",
    "    X_train_crowdlab: np.ndarray,\n",
    "    X_test: np.ndarray,\n",
    "    y_test: np.ndarray,\n",
    "    quantile: float,\n",
    "    initial_consensus_labels: np.ndarray | None = None,\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Train and evaluate a logistic regression model using filtered training data and consensus labels.\n",
    "\n",
    "    Args:\n",
    "        L_train_crowdlab (np.ndarray): Filtered training label matrix.\n",
    "        X_train_crowdlab (np.ndarray): Filtered training feature matrix.\n",
    "        X_test (np.ndarray): Test feature matrix.\n",
    "        y_test (np.ndarray): Test labels.\n",
    "        quantile (float): The quantile threshold for removing bad annotators.\n",
    "        initial_consensus_labels (Optional[np.ndarray]): Initial consensus labels. If None, majority vote is used.\n",
    "\n",
    "    Returns:\n",
    "        dict: Results of the model evaluation.\n",
    "    \"\"\"\n",
    "    if initial_consensus_labels is None:\n",
    "        # Obtain initial consensus labels using majority vote from the label matrix\n",
    "        initial_consensus_labels = get_majority_vote_label(L_train_crowdlab)\n",
    "\n",
    "    # Initialize a logistic regression model with specific parameters\n",
    "    logistic_model = LogisticRegression(\n",
    "        random_state=271828, n_jobs=-1, class_weight=\"balanced\", max_iter=1000\n",
    "    )\n",
    "\n",
    "    # Perform cross-validated prediction to obtain predicted probabilities\n",
    "    predicted_probabilities = cross_val_predict(\n",
    "        estimator=logistic_model,\n",
    "        X=X_train_crowdlab,\n",
    "        y=initial_consensus_labels,\n",
    "        cv=StratifiedKFold(n_splits=10, shuffle=True, random_state=271828),\n",
    "        method=\"predict_proba\",\n",
    "    )\n",
    "\n",
    "    # Calculate the quality of labels using the predicted probabilities\n",
    "    labels_quality = get_label_quality_multiannotator(\n",
    "        L_train_crowdlab, predicted_probabilities, verbose=False\n",
    "    )\n",
    "\n",
    "    # Extract the consensus labels from the label quality results\n",
    "    consensus_labels = labels_quality[\"label_quality\"][\"consensus_label\"].values\n",
    "\n",
    "    # Train and evaluate the model using the processed training data and consensus labels\n",
    "    evaluation_results = train_and_evaluate_model(\n",
    "        X_train_crowdlab,\n",
    "        consensus_labels,\n",
    "        X_test,\n",
    "        y_test,\n",
    "        f\"CrowdLab without {int(quantile * 100)}% worst LFs\",\n",
    "    )\n",
    "\n",
    "    return evaluation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotators to remove: [ 9 14] - (2 out of 28)\n",
      "\n",
      "\n",
      "Label Model name: CrowdLab without 5% worst LFs\n",
      "Metric                                   Score\n",
      "=============================================\n",
      "Accuracy Score:                        0.95917\n",
      "Balanced Accuracy Score:               0.94609\n",
      "F1 Score (weighted):                   0.95894\n",
      "Cohen Kappa Score:                     0.90208\n",
      "Matthews Correlation Coefficient:      0.90244\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.91      0.93      7050\n",
      "           1       0.96      0.98      0.97     16290\n",
      "\n",
      "    accuracy                           0.96     23340\n",
      "   macro avg       0.96      0.95      0.95     23340\n",
      "weighted avg       0.96      0.96      0.96     23340\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "Class 0 has 613 false negatives and 340 false positives.\n",
      "Class 1 has 340 false negatives and 613 false positives.\n",
      "The total number of errors is 953 out of 23340 samples (error rate: 0.0408).\n",
      "Predicted      0       1     All\n",
      "True                            \n",
      "0          6,437     613   7,050\n",
      "1            340  15,950  16,290\n",
      "All        6,777  16,563  23,340\n",
      "Annotators to remove: [ 9 14  8] - (3 out of 28)\n",
      "\n",
      "\n",
      "Label Model name: CrowdLab without 10% worst LFs\n",
      "Metric                                   Score\n",
      "=============================================\n",
      "Accuracy Score:                        0.95304\n",
      "Balanced Accuracy Score:               0.93571\n",
      "F1 Score (weighted):                   0.95261\n",
      "Cohen Kappa Score:                     0.88668\n",
      "Matthews Correlation Coefficient:      0.88755\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.89      0.92      7050\n",
      "           1       0.95      0.98      0.97     16290\n",
      "\n",
      "    accuracy                           0.95     23340\n",
      "   macro avg       0.95      0.94      0.94     23340\n",
      "weighted avg       0.95      0.95      0.95     23340\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "Class 0 has 762 false negatives and 334 false positives.\n",
      "Class 1 has 334 false negatives and 762 false positives.\n",
      "The total number of errors is 1096 out of 23340 samples (error rate: 0.0470).\n",
      "Predicted      0       1     All\n",
      "True                            \n",
      "0          6,288     762   7,050\n",
      "1            334  15,956  16,290\n",
      "All        6,622  16,718  23,340\n",
      "Annotators to remove: [ 9 14  8 13 23] - (5 out of 28)\n",
      "\n",
      "\n",
      "Label Model name: CrowdLab without 15% worst LFs\n",
      "Metric                                   Score\n",
      "=============================================\n",
      "Accuracy Score:                        0.95497\n",
      "Balanced Accuracy Score:               0.93387\n",
      "F1 Score (weighted):                   0.95434\n",
      "Cohen Kappa Score:                     0.89041\n",
      "Matthews Correlation Coefficient:      0.89236\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.88      0.92      7050\n",
      "           1       0.95      0.99      0.97     16290\n",
      "\n",
      "    accuracy                           0.95     23340\n",
      "   macro avg       0.96      0.93      0.95     23340\n",
      "weighted avg       0.96      0.95      0.95     23340\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "Class 0 has 842 false negatives and 209 false positives.\n",
      "Class 1 has 209 false negatives and 842 false positives.\n",
      "The total number of errors is 1051 out of 23340 samples (error rate: 0.0450).\n",
      "Predicted      0       1     All\n",
      "True                            \n",
      "0          6,208     842   7,050\n",
      "1            209  16,081  16,290\n",
      "All        6,417  16,923  23,340\n",
      "Annotators to remove: [ 9 14  8 13 23 18] - (6 out of 28)\n",
      "\n",
      "\n",
      "Label Model name: CrowdLab without 20% worst LFs\n",
      "Metric                                   Score\n",
      "=============================================\n",
      "Accuracy Score:                        0.96101\n",
      "Balanced Accuracy Score:               0.94974\n",
      "F1 Score (weighted):                   0.96085\n",
      "Cohen Kappa Score:                     0.90678\n",
      "Matthews Correlation Coefficient:      0.90697\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.93      7050\n",
      "           1       0.97      0.98      0.97     16290\n",
      "\n",
      "    accuracy                           0.96     23340\n",
      "   macro avg       0.96      0.95      0.95     23340\n",
      "weighted avg       0.96      0.96      0.96     23340\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "Class 0 has 555 false negatives and 355 false positives.\n",
      "Class 1 has 355 false negatives and 555 false positives.\n",
      "The total number of errors is 910 out of 23340 samples (error rate: 0.0390).\n",
      "Predicted      0       1     All\n",
      "True                            \n",
      "0          6,495     555   7,050\n",
      "1            355  15,935  16,290\n",
      "All        6,850  16,490  23,340\n",
      "Annotators to remove: [ 9 14  8 13 23 18 12] - (7 out of 28)\n",
      "\n",
      "\n",
      "Label Model name: CrowdLab without 25% worst LFs\n",
      "Metric                                   Score\n",
      "=============================================\n",
      "Accuracy Score:                        0.95338\n",
      "Balanced Accuracy Score:               0.93052\n",
      "F1 Score (weighted):                   0.95265\n",
      "Cohen Kappa Score:                     0.88621\n",
      "Matthews Correlation Coefficient:      0.88864\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.87      0.92      7050\n",
      "           1       0.95      0.99      0.97     16290\n",
      "\n",
      "    accuracy                           0.95     23340\n",
      "   macro avg       0.96      0.93      0.94     23340\n",
      "weighted avg       0.95      0.95      0.95     23340\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "Class 0 has 897 false negatives and 191 false positives.\n",
      "Class 1 has 191 false negatives and 897 false positives.\n",
      "The total number of errors is 1088 out of 23340 samples (error rate: 0.0466).\n",
      "Predicted      0       1     All\n",
      "True                            \n",
      "0          6,153     897   7,050\n",
      "1            191  16,099  16,290\n",
      "All        6,344  16,996  23,340\n"
     ]
    }
   ],
   "source": [
    "good_labeling_functions_dict = {}\n",
    "\n",
    "for alpha in [0.05, 0.10, 0.15, 0.20, 0.25]:\n",
    "\n",
    "    # Remove the worst annotators based on the specified quantile from the training data\n",
    "    # This function filters out the worst-performing annotators by their quality scores\n",
    "    good_labeling_functions, L_train_filtered, X_train_filtered = (\n",
    "        remove_worst_annotators_by_quantile(\n",
    "            alpha, labels_quality_train, X_train, L_train, lfs\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Get the results of the CrowdLab model after removing the worst annotators\n",
    "    # This function trains and evaluates a model using the filtered training data and the test set\n",
    "    good_labeling_functions_dict[alpha] = get_crowdlab_results(\n",
    "        L_train_filtered, X_train_filtered, X_test, y_test, alpha\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Label Model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Matthews Correlation",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Type",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "d3f25a34-dace-4f6d-a1c8-9b4fcdfe120c",
       "rows": [
        [
         "19",
         "CrowdLab without 20% worst LFs + End Model",
         "0.906970101468549",
         "LM + EM"
        ],
        [
         "4",
         "Full Supervision on Dev Set + End Model",
         "0.9062052593266651",
         "Full supervision"
        ],
        [
         "16",
         "CrowdLab without 5% worst LFs + End Model",
         "0.9024400065020299",
         "LM + EM"
        ],
        [
         "18",
         "CrowdLab without 15% worst LFs + End Model",
         "0.8923571944913029",
         "LM + EM"
        ],
        [
         "11",
         "Generative Model + End Model",
         "0.889410391987121",
         "LM + EM"
        ],
        [
         "2",
         "Snorkel MeTaL + End Model",
         "0.8889251584442059",
         "LM + EM"
        ],
        [
         "20",
         "CrowdLab without 25% worst LFs + End Model",
         "0.8886361371370817",
         "LM + EM"
        ],
        [
         "17",
         "CrowdLab without 10% worst LFs + End Model",
         "0.8875475870608098",
         "LM + EM"
        ],
        [
         "9",
         "Dawid-Skene + End Model",
         "0.8860193750293153",
         "LM + EM"
        ],
        [
         "15",
         "CrowdLab Model + End Model",
         "0.8859510151005762",
         "LM + EM"
        ],
        [
         "3",
         "Majority Label Voter + End Model",
         "0.8761199167917382",
         "LM + EM"
        ],
        [
         "5",
         "HyperLabelModel Unsupervised + End Model",
         "0.8443216796321857",
         "LM + EM"
        ],
        [
         "7",
         "HyperLabelModel Semi-Supervised + End Model",
         "0.8339443855395706",
         "LM + EM"
        ],
        [
         "10",
         "Dawid-Skene",
         "0.7249990758311258",
         "LM alone"
        ],
        [
         "13",
         "FlyingSquid + End Model",
         "0.7156224802187824",
         "LM + EM"
        ],
        [
         "6",
         "HyperLabelModel Unsupervised",
         "0.7040155349376804",
         "LM alone"
        ],
        [
         "8",
         "HyperLabelModel Semi-Supervised",
         "0.6897673717851329",
         "LM alone"
        ],
        [
         "0",
         "Snorkel MeTaL",
         "0.6857925272523081",
         "LM alone"
        ],
        [
         "1",
         "Majority Label Voter",
         "0.6712213834075154",
         "LM alone"
        ],
        [
         "12",
         "Generative Model",
         "0.6465167480320975",
         "LM alone"
        ],
        [
         "14",
         "FlyingSquid",
         "0.5912699244529404",
         "LM alone"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 21
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label Model</th>\n",
       "      <th>Matthews Correlation</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>CrowdLab without 20% worst LFs + End Model</td>\n",
       "      <td>0.906970</td>\n",
       "      <td>LM + EM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Full Supervision on Dev Set + End Model</td>\n",
       "      <td>0.906205</td>\n",
       "      <td>Full supervision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CrowdLab without 5% worst LFs + End Model</td>\n",
       "      <td>0.902440</td>\n",
       "      <td>LM + EM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>CrowdLab without 15% worst LFs + End Model</td>\n",
       "      <td>0.892357</td>\n",
       "      <td>LM + EM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Generative Model + End Model</td>\n",
       "      <td>0.889410</td>\n",
       "      <td>LM + EM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Snorkel MeTaL + End Model</td>\n",
       "      <td>0.888925</td>\n",
       "      <td>LM + EM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>CrowdLab without 25% worst LFs + End Model</td>\n",
       "      <td>0.888636</td>\n",
       "      <td>LM + EM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>CrowdLab without 10% worst LFs + End Model</td>\n",
       "      <td>0.887548</td>\n",
       "      <td>LM + EM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dawid-Skene + End Model</td>\n",
       "      <td>0.886019</td>\n",
       "      <td>LM + EM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>CrowdLab Model + End Model</td>\n",
       "      <td>0.885951</td>\n",
       "      <td>LM + EM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Majority Label Voter + End Model</td>\n",
       "      <td>0.876120</td>\n",
       "      <td>LM + EM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HyperLabelModel Unsupervised + End Model</td>\n",
       "      <td>0.844322</td>\n",
       "      <td>LM + EM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HyperLabelModel Semi-Supervised + End Model</td>\n",
       "      <td>0.833944</td>\n",
       "      <td>LM + EM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Dawid-Skene</td>\n",
       "      <td>0.724999</td>\n",
       "      <td>LM alone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>FlyingSquid + End Model</td>\n",
       "      <td>0.715622</td>\n",
       "      <td>LM + EM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HyperLabelModel Unsupervised</td>\n",
       "      <td>0.704016</td>\n",
       "      <td>LM alone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HyperLabelModel Semi-Supervised</td>\n",
       "      <td>0.689767</td>\n",
       "      <td>LM alone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Snorkel MeTaL</td>\n",
       "      <td>0.685793</td>\n",
       "      <td>LM alone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Majority Label Voter</td>\n",
       "      <td>0.671221</td>\n",
       "      <td>LM alone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Generative Model</td>\n",
       "      <td>0.646517</td>\n",
       "      <td>LM alone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>FlyingSquid</td>\n",
       "      <td>0.591270</td>\n",
       "      <td>LM alone</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Label Model  Matthews Correlation  \\\n",
       "19   CrowdLab without 20% worst LFs + End Model              0.906970   \n",
       "4       Full Supervision on Dev Set + End Model              0.906205   \n",
       "16    CrowdLab without 5% worst LFs + End Model              0.902440   \n",
       "18   CrowdLab without 15% worst LFs + End Model              0.892357   \n",
       "11                 Generative Model + End Model              0.889410   \n",
       "2                     Snorkel MeTaL + End Model              0.888925   \n",
       "20   CrowdLab without 25% worst LFs + End Model              0.888636   \n",
       "17   CrowdLab without 10% worst LFs + End Model              0.887548   \n",
       "9                       Dawid-Skene + End Model              0.886019   \n",
       "15                   CrowdLab Model + End Model              0.885951   \n",
       "3              Majority Label Voter + End Model              0.876120   \n",
       "5      HyperLabelModel Unsupervised + End Model              0.844322   \n",
       "7   HyperLabelModel Semi-Supervised + End Model              0.833944   \n",
       "10                                  Dawid-Skene              0.724999   \n",
       "13                      FlyingSquid + End Model              0.715622   \n",
       "6                  HyperLabelModel Unsupervised              0.704016   \n",
       "8               HyperLabelModel Semi-Supervised              0.689767   \n",
       "0                                 Snorkel MeTaL              0.685793   \n",
       "1                          Majority Label Voter              0.671221   \n",
       "12                             Generative Model              0.646517   \n",
       "14                                  FlyingSquid              0.591270   \n",
       "\n",
       "                Type  \n",
       "19           LM + EM  \n",
       "4   Full supervision  \n",
       "16           LM + EM  \n",
       "18           LM + EM  \n",
       "11           LM + EM  \n",
       "2            LM + EM  \n",
       "20           LM + EM  \n",
       "17           LM + EM  \n",
       "9            LM + EM  \n",
       "15           LM + EM  \n",
       "3            LM + EM  \n",
       "5            LM + EM  \n",
       "7            LM + EM  \n",
       "10          LM alone  \n",
       "13           LM + EM  \n",
       "6           LM alone  \n",
       "8           LM alone  \n",
       "0           LM alone  \n",
       "1           LM alone  \n",
       "12          LM alone  \n",
       "14          LM alone  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for alpha, result in good_labeling_functions_dict.items():\n",
    "    all_results.append(result)\n",
    "\n",
    "\n",
    "df_baseline = pd.DataFrame(all_results)\n",
    "df_baseline.sort_values(by=\"Matthews Correlation\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As previously noted, traditional label aggregation methods such as Dawid & Skene and Majority Voting can perform surprisingly well. However, contemporary models like HyperLM, FlyingSquid, and Crowdlab offer distinct advantages, especially concerning computational efficiency, adaptability, and scalability for sophisticated, large-scale weak supervision tasks. Crowdlab is particularly noteworthy due to its capacity to integrate the strengths of both label functions and classifier-based predictions, alongside its built-in ability to assess label function quality and generate high-quality consensus labels.\n",
    "\n",
    "The preceding table underscores a crucial insight: the necessity of pairing a label model with a downstream \"end model.\" While label models excel at capturing and deciphering the often complex relationships between labeling functions and the latent true labels, they may not be optimally designed for generalization to entirely new, unseen data instances.  Conversely, end models, often discriminative models like neural networks, are explicitly trained to generalize. By learning from the probabilistic or consensus labels generated by the label model, the end model can effectively generalize beyond the specific heuristics encoded in the labeling functions and perform robustly on novel, unseen examples.\n",
    "\n",
    "This strategic combination leverages the distinct strengths of each model type:\n",
    "\n",
    "-   **Label Model Strength**: Expertise in distilling and aggregating noisy signals from multiple weak sources (Labeling Functions), effectively capturing fundamental data patterns and LF inter-dependencies. It is adept at creating a refined, probabilistic label set from initially noisy inputs.\n",
    "-   **End Model Strength**: Capacity for strong generalization. Trained on the refined labels from the label model, the end model learns to make accurate predictions on new, unseen data, going beyond the limitations of individual LFs.\n",
    "\n",
    "This collaboration is cooperative; the label model refines the noisy input, and the end model ensures effective real-world applicability.  This pairing consistently leads to enhanced performance on downstream tasks compared to relying solely on either type of model in isolation.\n",
    "\n",
    "Besides, as previously discussed, the CrowdLab model offers an important additional benefit: the ability to identify and aid the removal of noisy Labeling Functions within weak supervision frameworks. CrowdLab employs confident-learning techniques to evaluate and score each LF's quality. This evaluation is based on the consistency of an LF's outputs with the overall consensus labels and the confidence of its predictions (or alignment with the classifier component). By providing a quantifiable measure of each LF's reliability, CrowdLab allows for the strategic filtering of less reliable label sources. Removing noisy LFs leads to a more refined and accurate label aggregation process, ultimately resulting in higher-quality training labels. Machine learning models trained on these improved weakly supervised datasets subsequently exhibit enhanced performance and robustness.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Addressing Noisy Examples Beyond Noisy Labeling Functions\n",
    "\n",
    "Building upon the strategy for managing noisy LFs, a natural extension arises: how to identify and mitigate the impact of not just noisy *labeling functions*, but also noisy or problematic *examples* within a weakly supervised dataset? Addressing noisy examples is crucial as individual data points can be inherently flawed, mislabeled even by consensus, or outliers that negatively impact model training and generalization.\n",
    "\n",
    "A powerful technique to tackle this challenge is the application of **Influence Functions**.  Moving beyond the issue of noisy LFs, Influence Functions provide a methodology to analyze the impact of individual *training examples* on a trained model's parameters and predictions.\n",
    "\n",
    "**Influence Functions: A Tool for Identifying Noisy Examples**\n",
    "\n",
    "Influence Functions, fundamentally, quantify how much a model's parameters and predictions would change if a particular training example were upweighted or removed from the training dataset. with respect to weak supervision and potentially noisy labels, Influence Functions become invaluable for:\n",
    "\n",
    "-   **Detecting Anomalous Influence**: Identifying training examples that exert disproportionately large influence on the model's behavior. Examples with unusually high influence are candidates for being noisy, incorrect, or outliers.\n",
    "-   **Pinpointing Detrimental Examples**: Determining if the influence of a specific example is *detrimental* to the model's performance, particularly on a validation set.  Negative influence on validation performance is a strong indicator of a noisy or problematic example.\n",
    "-   **Guiding Data Refinement**: By ranking training examples based on their influence scores, we can systematically identify and investigate the most influential examples. These examples become prime candidates for manual review, correction, or removal from the training set, leading to a more refined and higher-quality dataset.\n",
    "\n",
    "We will explore the steps involved in applying Influence Functions to address noisy examples in weak supervision in our next class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Takeaways\n",
    "- **Weak Supervision for Data Scarcity:**  Advanced label models are crucial for effectively employing weak supervision techniques to train models when labeled data is limited.\n",
    "\n",
    "- **Label Model Diversity:**  Different label models offer various approaches to label aggregation, each with its own strengths, assumptions, and computational properties. The choice of model depends on the specific needs of the task.\n",
    "\n",
    "- **Beyond Simple Aggregation:**  Moving beyond simple majority voting, advanced label models like HyperLM, Dawid & Skene, FlyingSquid, and Crowdlab offer more sophisticated methods to handle noisy and conflicting labels, leading to improved label quality.\n",
    "\n",
    "- **Quality over Quantity of LFs:** The quality and reliability of labeling functions are as important as the number of LFs. Identifying and removing noisy or less effective LFs (as demonstrated with Crowdlab) can improve the overall performance of the weak supervision pipeline.\n",
    "\n",
    "- **Interaction of Label and End Models:** Combining label models for noise reduction with discriminative end models for generalization is a powerful example in weak supervision. This two-stage approach leverages the strengths of both types of models for stable performance.\n",
    "\n",
    "- **Addressing Noisy Data Broadly:**  Noisy data can manifest in both labeling functions and individual data examples. Techniques like Crowdlab and Influence Functions are essential tools for identifying and mitigating different sources of noise in weakly supervised learning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions\n",
    "\n",
    "1. What is Programmatic Weak Supervision (PWS) and why is label aggregation critical challenge in this context?\n",
    "\n",
    "2. How does the Majority Label Voter model operate within weak supervision pipelines?\n",
    "\n",
    "3. What are the key components of the Hyper Label Model (HyperLM) and how do its unsupervised and semi-supervised training approaches differ?\n",
    "\n",
    "4. In what way does the Dawid & Skene model utilize the Expectation-Maximization (EM) algorithm to infer true labels from multiple labeling functions?\n",
    "\n",
    "5. How does the Snorkel Generative Model produce probabilistic labels from noisy labeling function outputs, and how does it contrast with the later MeTaL model?\n",
    "\n",
    "6. What is the central concept behind the FlyingSquid model and how is triplet decomposition used to efficiently estimate labeling function accuracies?\n",
    "\n",
    "7. How does Crowdlab combine labeling function outputs with classifier predictions to generate high-quality consensus labels?\n",
    "\n",
    "8. What preprocessing steps are applied to the label matrix (L_train) to handle abstentions and improve the overall quality of labeling function outputs?\n",
    "\n",
    "9. Why is it important to pair a label model with a downstream \"end model\" in weak supervision applications?\n",
    "\n",
    "10. How does Crowdlab enable the refinement of labeling function sets?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Answers are commented inside this cell.`\n",
    "\n",
    "\n",
    "<!-- \n",
    "1. Programmatic Weak Supervision (PWS) uses multiple labeling functions (LFs) to automatically generate noisy labels for training data. Label aggregation is critical because the outputs from various LFs are inherently noisy and may conflict, so combining them effectively is essential to obtain reliable labels.\n",
    "\n",
    "2. The Majority Label Voter model aggregates the outputs from multiple LFs by simply taking the majority vote for each data point. In cases of ties, a random tie-break policy is typically applied, making it a straightforward baseline for label aggregation.\n",
    "\n",
    "3. HyperLM utilizes a Graph Neural Network (GNN) to approximate the optimal aggregation of LF outputs. In its unsupervised mode, it is trained on synthetic data to learn how to aggregate LF signals without ground truth labels, while in the semi-supervised mode, it is fine-tuned with a small set of known labels to improve the inferred label quality.\n",
    "\n",
    "4. The Dawid & Skene model treats each LF as an annotator characterized by a confusion matrix that reflects its reliability. Using the EM algorithm, it alternates between estimating the posterior probabilities of the true labels (E-step) and updating the confusion matrices and class priors (M-step) to better model the noise and derive accurate label estimates.\n",
    "\n",
    "5. The Snorkel Generative Model estimates LF accuracies and correlations from noisy outputs by constructing a probabilistic factor graph that models the relationship between the true labels and LF outputs. Unlike the MeTaL model that introduces more advanced mechanisms and joint optimization strategies, the generative model primarily focuses on combining LF votes based on estimated accuracies.\n",
    "\n",
    "6. Facing the computational challenges of weak supervision, the FlyingSquid model uses a closed-form solution based on triplet decomposition, where agreements among triplets of LFs are analyzed to directly compute the accuracies of each LF. This approach avoids iterative optimization and significantly improves computational efficiency.\n",
    "\n",
    "7. Crowdlab integrates LF outputs with the predictions of a classifier through a weighted ensemble method. It assigns weights to each LF based on its quality (using measures like agreement with the consensus and prediction confidence) and fuses these with cross-validated classifier probabilities to produce reliable consensus labels.\n",
    "\n",
    "8. The notebook first removes LFs that abstain on all rows and then filters out rows where every LF abstains. Besides, it converts abstain signals (originally represented as -1) into NaN values to assist subsequent quality analyses and consensus label computation.\n",
    "\n",
    "9. Pairing a label model with a downstream end model is vital because label models excel at aggregating noisy signals from multiple LFs but are often not designed for generalizing to unseen data. In contrast, end models (e.g., discriminative classifiers) trained on refined labels can learn to generalize to new, real-world instances, using the strengths of both approaches.\n",
    "\n",
    "10. Crowdlab enables LF refinement by computing quality scores for each labeling function—based on their agreement with consensus labels and prediction confidence—and then ranking them. Label functions with scores below a selected quantile threshold are identified as noisy and can be removed, which in turn improves the overall quality of the aggregated labels. -->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imd3011-datacentric-ai-ZY2qswVr-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
