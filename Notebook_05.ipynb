{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annotation Error Detection\n",
    "## IMD3011 - Datacentric AI\n",
    "### [Dr. Elias Jacob de Menezes Neto](https://docente.ufrn.br/elias.jacob)\n",
    "\n",
    "\n",
    "> Parts of this notebook were adapted from the amazing [MIT Introduction to Data-Centric AI](https://dcai.csail.mit.edu) course taugh by the amazing folks from [Cleanlab](https://cleanlab.ai/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keypoints\n",
    "\n",
    "- **Annotation Error Detection (AED):** AED is a process for automatically identifying mislabeled or inconsistent examples in datasets. It employs two types of methods: binary flaggers that simply mark errors and scorers that assign confidence score indicating error likelihood.\n",
    "\n",
    "- **Types of Label Noise:** Label noise can occur in various forms:\n",
    "  - **Uniform (Symmetric) Noise:** Every mislabel is equally likely.\n",
    "  - **Systematic (Asymmetric) Noise:** Some classes are more likely to be confused than others.\n",
    "  - **Instance-Dependent Noise:** The probability of mislabeling varies with specific features of each instance.\n",
    "\n",
    "- **Label Noise Transition Matrix:** This matrix quantifies the probability of an observed noisy label given the true label. It is foundational to methods such as Confident Learning that adjust for label noise during training.\n",
    "\n",
    "- **Retagging Approach:** Retagging uses predictions from a held-out (out-of-sample) model to identify and correct potential mislabels. By comparing model outputs with existing labels, it refines the training data, reducing annotation errors and potentially improving overall model performance.\n",
    "\n",
    "- **Model Confidence and Thresholding:** Establishing class-specific confidence thresholds (using measures like calibration plots and averaged model predictions) allows the system to flag examples whose predicted probabilities deviate significantly from expectations. This helps isolate and quantify erroneous instances.\n",
    "\n",
    "- **Data- vs. Model-Centric Methods:** While model-centric methods address noise by modifying the loss function (e.g., importance reweighting and loss correction), data-centric methods focus on identifying and cleaning the training data, an approach that is especially valuable in weak supervision settings.\n",
    "\n",
    "- **Impact of Noisy Labels:** Noisy labels can significantly degrade model performance by misleading the learning process—models may learn incorrect associations, overfit on noise, and yield skewed performance metrics during evaluation.\n",
    "\n",
    "- **Uncertainty in Predictions:** The discussion distinguishes between aleatoric uncertainty (irreducible noise due to built-in data randomness) and epistemic uncertainty (stemming from the limitations of the model). Properly handling both types is key to diagnosing errors and refining labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning goals\n",
    "By the end of this class, you will be able to:\n",
    "\n",
    "1. **Explain** the key concepts of label noise and annotation error detection, including the distinctions between uniform, systematic (asymmetric), and instance-dependent noise.\n",
    "\n",
    "2. **Analyze** the mathematical frameworks basic noisy label modeling, such as joint probability distributions, label noise transition matrices, and confidence thresholding.\n",
    "\n",
    "3. **Apply** data-centric and model-centric methodologies—including retagging and confident learning approaches—to automatically identify, quantify, and correct mislabeled examples in datasets.\n",
    "\n",
    "4. **Apply** practical pipelines using tools like Scikit-learn, TfidVectorizer, and Cleanlab to preprocess data, compute calibration plots, and construct confusion matrices for evaluating AED techniques.\n",
    "\n",
    "5. **Evaluate** the effects of annotation errors on model performance and interpretation, and **propose** strategies that utilize thresholds, cross-validation, and error-set analysis to mitigate label noise in real-world scenarios.\n",
    "\n",
    "6. **Design** iterative data curation workflows that integrate AED, retagging, and confident learning methods to enhance the quality of datasets for training sturdy machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "<img src=\"images/wsl04_01.png\" width=\"80%\" height=\"80%\" />\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notation for Noisy Labels\n",
    "\n",
    "Understanding the notations used in discussions about noisy labels and their true counterparts is important for grasping the basic concepts. This section introduces key symbols and definitions that help describe the relationship between observed labels and true labels regarding label noise.\n",
    "\n",
    "### Key Notations and Definitions\n",
    "\n",
    "- **$\\tilde{y}$**  \n",
    "  This symbol represents the **observed label**, which might contain errors due to noise in the data collection process.\n",
    "\n",
    "- **$y^*$**  \n",
    "  This denotes the **true label** (also called the latent or correct label). The true label is what the observed label $\\tilde{y}$ should be if no mistakes occurred during data collection.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Sets and Counts\n",
    "\n",
    "The following notations help describe and quantify the relationship between noisy observed labels and true labels:\n",
    "\n",
    "- **$X_{\\tilde{y}=i,\\, y^*=j}$**  \n",
    "  This set contains all examples for which the observed label is $i$ and the true label is $j$. Analyzing these sets allows you to identify patterns of labeling errors.\n",
    "\n",
    "- **$C_{\\tilde{y}=i,\\, y^*=j}$**  \n",
    "  This count represents the number of instances in the set $X_{\\tilde{y}=i,\\, y^*=j}$. These counts are essential for calculating the distribution of label noise.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Probabilities and Distributions\n",
    "\n",
    "A statistical description of noisy labels requires modeling the probabilities of various label outcomes. Two key concepts are:\n",
    "\n",
    "- **Joint Probability Distribution**  \n",
    "  The joint probability $p(\\tilde{y}=i,\\, y^*=j)$ is defined as the probability that an instance is observed with label $i$ and its true label is $j$. This is computed by normalizing the counts:\n",
    "  \n",
    "  $$\n",
    "  p(\\tilde{y}=i,\\, y^*=j) = \\frac{C_{\\tilde{y}=i,\\, y^*=j}}{N}\n",
    "  $$\n",
    "  \n",
    "  where $N$ is the total number of instances in the dataset.\n",
    "\n",
    "- **Transition Probability**  \n",
    "  The conditional probability $p(\\tilde{y}=i \\mid y^*=j)$ indicates the probability that an instance with true label $j$ is observed as label $i$. It quantifies the chance of mislabeling:\n",
    "  \n",
    "  $$\n",
    "  p(\\tilde{y}=i \\mid y^*=j) = \\frac{C_{\\tilde{y}=i,\\, y^*=j}}{C_{y^*=j}}\n",
    "  $$\n",
    "  \n",
    "  where\n",
    "  \n",
    "  $$\n",
    "  C_{y^*=j} = \\sum_{k} C_{\\tilde{y}=k,\\, y^*=j}\n",
    "  $$\n",
    "  \n",
    "  represents the total number of instances with true label $j$.\n",
    "\n",
    "> **Important:**  \n",
    "> Distinguishing between $\\tilde{y}$ and $y^*$ allows us to adjust our models to account for label noise. Understanding and estimating the transition probability $p(\\tilde{y}=i \\mid y^*=j)$ is particularly useful for designing systems that can correct for or mitigate the impact of labeling errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Practical Example: Animal Image Classification\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"images/ai_cat_dog_meme.png\" width=\"40%\" height=\"40%\" />\n",
    "</p>\n",
    "\n",
    "Consider a dataset of images where each image is labeled with an animal category (e.g., cats, dogs, horses). Due to mislabeling during data collection, some images of cats might be labeled as dogs. Here’s how the notations apply:\n",
    "\n",
    "- **Noisy Label ($\\tilde{y}$)**: The label given during data collection (e.g., \"dog\" for a misclassified cat image).\n",
    "- **True Label ($y^*$)**: The actual category to which the image belongs (e.g., \"cat\").\n",
    "\n",
    "For an image of a cat that has been mislabeled:\n",
    "\n",
    "- **$X_{\\tilde{y}=\\text{dog},\\, y^*=\\text{cat}}$**: This set contains images that were observed as \"dog\" but are actually \"cat.\"\n",
    "- **$C_{\\tilde{y}=\\text{dog},\\, y^*=\\text{cat}}$**: This count is incremented for each instance where an image is misclassified from \"cat\" to \"dog.\"\n",
    "\n",
    "Using the counts across the entire dataset, you can compute the joint distribution\n",
    "\n",
    "$$\n",
    "p(\\tilde{y}=i,\\, y^*=j)\n",
    "$$\n",
    "\n",
    "and the transition probabilities\n",
    "\n",
    "$$\n",
    "p(\\tilde{y}=i \\mid y^*=j)\n",
    "$$\n",
    "\n",
    "This approach helps in quantifying the impact of noise, ultimately guiding improvements in model performance through techniques such as noise-aware training methods.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sources of Noisy Labels\n",
    "\n",
    "Noisy labels occur due to various issues that can arise during data collection, processing, or annotation. Understanding these sources is key to mitigating their impact on model performance. This section explores common causes of label noise in datasets and their consequences for machine learning applications.\n",
    "\n",
    "\n",
    "### 1. Human Error\n",
    "\n",
    "- **Accidental Mislabeling:**  \n",
    "  During the annotation process, an annotator might select the wrong label by mistake (e.g., clicking an incorrect button in the interface).\n",
    "\n",
    "- **Fatigue or Inattention:**  \n",
    "  Extended periods of labeling can lead to decreased concentration, resulting in oversight or mistakes.\n",
    "\n",
    "- **Lack of Domain Expertise:**  \n",
    "  Annotators who are not familiar with the specific subject matter may misclassify instances due to insufficient knowledge of the nuances involved.\n",
    "\n",
    "*Example:* In a clinical diagnosis dataset, non-expert annotators might confuse similar medical conditions, leading to noisy labels.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Measurement Issues\n",
    "\n",
    "- **Faulty Data Collection Tools:**  \n",
    "  Inaccurate or poorly calibrated instruments can compromise the quality of the gathered data, leading to erroneous labels.\n",
    "\n",
    "- **Inconsistent Measurement Approaches:**  \n",
    "  Variability in data collection protocols or methodologies can introduce discrepancies. For example, differing guidelines across locations or time periods can result in inconsistent labeling.\n",
    "\n",
    "*Example:* Temperature sensors with calibration issues may record incorrect values, affecting the labels in a weather dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Algorithmic Errors\n",
    "\n",
    "- **Error Propagation from Earlier Models:**  \n",
    "  When labels are generated or refined using machine learning models (e.g., within a weak supervision pipeline), mistakes made by those models can be carried forward. This phenomenon is often seen when predictions from a preliminary model are used to label large datasets.\n",
    "\n",
    "- **Biases in Automated Labeling:**  \n",
    "  Algorithms may have innate biases or flaws that lead to systematic mislabeling, particularly when the training data of the automated process is itself noisy or unrepresentative.\n",
    "\n",
    "*Example:* An automated system trained on biased historical data might over-represent certain categories while under-representing others, thus skewing the label distribution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Data Corruption\n",
    "\n",
    "- **Technical Glitches:**  \n",
    "  Errors during data storage, transfer, or processing (e.g., software bugs or hardware failures) can corrupt labels.\n",
    "\n",
    "- **Malicious Tampering:**  \n",
    "  In some scenarios, datasets may be intentionally manipulated, either for competitive advantage or due to security breaches, resulting in label inaccuracies.\n",
    "\n",
    "*Example:* A distributed database might experience data corruption during synchronization, leading to mismatches between the true state and the recorded labels.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Subjective Interpretations\n",
    "\n",
    "- **Ambiguity in Labeling:**  \n",
    "  Certain cases might not have a clear-cut category, and different annotators could assign different labels based on their interpretation. Such ambiguity can lead to inconsistent or noisy labels.\n",
    "\n",
    "- **Cultural or Contextual Variations:**  \n",
    "  Labelers from different cultural or contextual backgrounds might interpret data differently, especially in areas like sentiment analysis or image categorization.\n",
    "\n",
    "*Example:* When annotating social media posts for sentiment, one annotator might label a sarcastic remark as positive while another could interpret it as negative, leading to noise in the training labels.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Flipping and Noisy Labels\n",
    "\n",
    "Label flipping happens when an instance is assigned an incorrect label, effectively swapping its true class with another. This concept is key to understanding how label errors, or *noisy labels*, can influence machine learning models.\n",
    "\n",
    "### Examples of Label Flipping\n",
    "\n",
    "- **Visual Misclassification:** An image depicting a bus is incorrectly labeled as a car.\n",
    "- **Sentiment Analysis Error:** A review with a positive tone such as \"Muito bom, gostei bastante!\" is mistakenly tagged as negative.\n",
    "- **NER Mislabeling:** A named entity like \"Elias Jacob\" is sometimes left untagged or assigned an incorrect category.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Quantifying Label Noise\n",
    "\n",
    "One way to quantify label noise is by using a confusion matrix that compares the true labels, $ y^* $, with the observed, or noisy, labels, $ \\tilde{y} $.\n",
    "\n",
    "> **Confusion Matrix Interpretation:**\n",
    ">\n",
    "> - **Diagonal elements:** The count of instances correctly labeled.\n",
    "> - **Off-diagonal elements:** The count of label flips (mislabeled instances).\n",
    "\n",
    "Consider the following confusion matrix:\n",
    "\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "| $ C_{\\tilde{y}, y^*} $ | $ y^* = \\text{bus} $ | $ y^* = \\text{car} $ | $ y^* = \\text{bike} $ |\n",
    "|--------------------------|------------------------|------------------------|------------------------|\n",
    "| $ \\tilde{y} = \\text{bus} $   | 90                   | 35                   | 25                   |\n",
    "| $ \\tilde{y} = \\text{car} $   | 50                   | 70                   | 5                    |\n",
    "| $ \\tilde{y} = \\text{bike} $  | 30                   | 15                   | 75                   |\n",
    "</div>\n",
    "\n",
    "<br><br>\n",
    "For instance, notice that 50 instances with the true label \"bus\" have been misclassified as \"car\". This matrix helps in visualizing the extent and pattern of label noise in dataset labels.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Impact of Noisy Labels\n",
    "\n",
    "Noisy labels can negatively affect the training and performance of machine learning models in several ways:\n",
    "\n",
    "- **Model Performance:** Inaccurate labels can reduce model accuracy and hurt its ability to generalize to unseen data.\n",
    "- **Training Challenges:** The model may end up fitting the noise, making it difficult to identify true patterns in the data.\n",
    "- **Evaluation Concerns:** Test sets with noisy labels might lead to misleading assessments of model performance.\n",
    "- **Bias Introduction:** Systematic labeling errors can introduce or worsen bias within the model.\n",
    "- **Wasted Resources:** Training on datasets with label noise may result in inefficient use of computational time and resources.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Uncertainty in Predictions\n",
    "\n",
    "In machine learning, **uncertainty** indicates the extent to which a model lacks confidence in its predictions. It highlights the possibility of model errors and helps assess the reliability of outputs. Two primary types of uncertainty influence model predictions:\n",
    "\n",
    "### 1. Aleatoric Uncertainty\n",
    "\n",
    "- **Definition:** This uncertainty is due to innate randomness or noise present in the data. It is considered irreducible because it originates from the data-generation process.\n",
    "- **Example:** In predicting house prices, factors such as sudden market variations or minor differences in property features contribute to aleatoric uncertainty. Even with extensive data, predicting the exact price is challenging because of these unavoidable variations.\n",
    "\n",
    "### 2. Epistemic Uncertainty\n",
    "\n",
    "- **Definition:** This uncertainty comes from limitations in the model's understanding of the relationship between inputs and outputs. It reflects the gap in the model’s knowledge and can be reduced by improving the model, such as by including more extensive or diverse training examples.\n",
    "- **Example:** Consider a model trained primarily on images of adult cats and dogs. When faced with images of kittens or puppies, the model may show higher uncertainty because these examples were not well-represented in the training data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Disentangling Label Noise and Uncertainty\n",
    "\n",
    "In practical scenarios, distinguishing whether errors stem from label noise (related to aleatoric uncertainty) or from the model's limitations (linked to epistemic uncertainty) is not straightforward. To address this, researchers often introduce a **label noise process assumption**.\n",
    "\n",
    "### Class-Conditional Label Noise Model\n",
    "\n",
    "A common assumption is that the label noise depends only on the true class label and not on other features of the input. This assumption can be described by:\n",
    "\n",
    "$$\n",
    "p(\\tilde{y} \\mid y^*; x) = p(\\tilde{y} \\mid y^*)\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "- $ \\tilde{y} $ is the observed (possibly incorrect) label,\n",
    "- $ y^* $ is the true label,\n",
    "- $ x $ represents the input features.\n",
    "\n",
    "This model implies that for all data points belonging to the same true class, the probability of a label flip follows the same pattern, regardless of individual differences in the input features. The transition probabilities $ p(\\tilde{y} \\mid y^*) $ can be organized into a matrix similar to the confusion matrix shown earlier. This helps in isolating the effects of noisy labels from the shortcomings related to the model's current design or training data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of Label Noise in Machine Learning\n",
    "\n",
    "Label noise can considerably affect model performance. It is important to recognize the different types of label noise to build models that can handle or correct these errors. The three primary types are **uniform (symmetric) noise**, **systematic (asymmetric) class-conditional noise**, and **instance-dependent noise**.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Uniform (Symmetric) Label Noise\n",
    "\n",
    "**Definition:**  \n",
    "Uniform label noise assumes that for any instance with the true label $ y^* $, the probability of it being mislabeled as any other label is the same across all incorrect options. Formally, for any incorrect label $ i $ and true label $ j $:\n",
    "\n",
    "$$\n",
    "p(\\tilde{y} = i \\mid y^* = j) = \\epsilon, \\quad \\forall \\, i \\neq j\n",
    "$$\n",
    "\n",
    "where $ \\epsilon $ is the noise rate.\n",
    "\n",
    "**Characteristics:**\n",
    "\n",
    "- **Simplicity:** It is the most straightforward noise model.\n",
    "- **Uniform Distribution:** Errors are assumed to be uniformly distributed among all classes.\n",
    "- **Baseline Model:** Frequently used as a baseline in studies that focus on building noise-reliable techniques.\n",
    "\n",
    "**Consequences:**\n",
    "\n",
    "- **Modeling:** Easy to model and can serve as an initial test case.\n",
    "- **Limitations:** This model might not capture the error patterns observed in real-world datasets, where mislabeling often shows bias toward certain classes.\n",
    "\n",
    "> **Note:** Although common in research settings, this model may oversimplify the complexity of noise in practical applications.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Systematic (Asymmetric) Class-Conditional Label Noise\n",
    "\n",
    "**Definition:**  \n",
    "Systematic noise allows the mislabeling probabilities to vary between different class pairs. The probability of a mislabel depends on the true label $ y^* $ and can vary for each incorrect label $ i $:\n",
    "\n",
    "$$\n",
    "p(\\tilde{y} = i \\mid y^* = j) = \\epsilon_{ij}\n",
    "$$\n",
    "\n",
    "with different values of $ \\epsilon_{ij} $ for each pair $ (i, j) $.\n",
    "\n",
    "**Characteristics:**\n",
    "\n",
    "- **Realism:** More closely reflects actual noise in many datasets.\n",
    "- **Error Patterns:** Often represents common misclassification trends, such as confusion between visually similar classes.\n",
    "\n",
    "**Consequences:**\n",
    "\n",
    "- **Complexity:** Modeling these probabilities requires a more complex approach.\n",
    "- **Effectiveness:** Better captures the nuances in data labeling processes.\n",
    "  \n",
    "For example, in an animal image classification task, a cat might be more frequently misclassified as a dog rather than as a bird, reflecting a higher $p(\\tilde{y} = \\text{dog} \\mid y^* = \\text{cat})$ than $p(\\tilde{y} = \\text{bird} \\mid y^* = \\text{cat})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Instance-Dependent Label Noise\n",
    "\n",
    "**Definition:**  \n",
    "Instance-dependent noise takes into account both the true class $ y^* $ and the specific features $ x $ of the instance. The probability of an incorrect label is represented as:\n",
    "\n",
    "$$\n",
    "p(\\tilde{y} = i \\mid y^* = j, x)\n",
    "$$\n",
    "\n",
    "**Characteristics:**\n",
    "\n",
    "- **Detail-Oriented:** It considers the attributes of individual samples, meaning that noise levels can vary across instances from the same class.\n",
    "- **Complexity:** This model is the most detailed and can better mimic real-world scenarios where certain features make an instance more likely to be mislabeled.\n",
    "\n",
    "**Consequences:**\n",
    "\n",
    "- **Modeling Difficulty:** Requires strong assumptions about the distribution of both the features and the labels.\n",
    "- **Practicality:** While realistic, handling instance-dependent noise often proves challenging due to the added complexity.\n",
    "\n",
    "For example, in an image classification task, a blurry or occluded image (specific instance) of a cat may be much more likely to be mislabeled than a clear, well-lit image of the same cat.\n",
    "\n",
    "> **Important:** Although instance-dependent noise may fit actual label noise patterns more accurately, its complexity usually makes it less practical for many applications. Researchers often need to balance realism and tractability when choosing a noise model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparative Example: Image Classification Task\n",
    "\n",
    "Consider an animal classification problem with the following scenarios:\n",
    "\n",
    "1. **Uniform Noise:** A cat has an equal chance of being mislabeled as a dog, bird, or any other animal.\n",
    "2. **Asymmetric Noise:** A cat is more likely to be confused with a dog rather than a bird, reflecting visual similarities between cats and dogs.\n",
    "3. **Instance-Dependent Noise:** A poorly contrasted or blurry image of a cat is more likely to be mislabeled compared to a high-quality image of a cat.\n",
    "\n",
    "In real-world datasets like ImageNet, we often observe asymmetric label noise. For example, many images of **wild boars** are mislabeled as **pigs**, and vice versa. This is a clear example of systematic noise, where certain classes are more likely to be confused due to their visual similarities.\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"images/label_errors_pig.png\" width=\"100%\" height=\"100%\" alt=\"Wild Boar and Pig Label Errors\"/>\n",
    "</p>\n",
    "\n",
    "If label noise was uniform, we would expect the mislabeling to be evenly distributed across all classes. However, the systematic nature of the noise indicates that certain classes are more likely to be confused with specific others, leading to asymmetric noise patterns.\n",
    "\n",
    "> **Note**: Despite the prevalence of asymmetric label noise in real-world datasets, many noise-sturdy learning studies still rely on the uniform noise assumption due to its simplicity and ease of modeling. This usually results in myths like \"neural networks are reliable to label noise\" because they are often tested on datasets with uniform noise, which doesn't accurately reflect real-world scenarios. This discrepancy between research assumptions and real-world noise patterns highlights the importance of developing noise-handling techniques that can address more complex noise structures.\n",
    "\n",
    "For more examples, [check this website](https://labelerrors.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Sources of Noise in Machine Learning\n",
    "\n",
    "### Noise in Data vs. Noise in Labels\n",
    "\n",
    "Machine learning models deal with different types of noise. It is important to separate **noise in input data** from **noise in labels**.\n",
    "\n",
    "- **Noise in Input Data**  \n",
    "  Common types include:  \n",
    "  - **Visual Noise**: Distortion, blur, or occlusion in images.  \n",
    "    - *Example*: A low-resolution image of a sidewalk where details are smeared.  \n",
    "  - **Adversarial Examples**: Inputs that have been deliberately altered to trick models.  \n",
    "    - *Example*: A slightly modified image of a car that a model incorrectly identifies as a bicycle.  \n",
    "  - **Textual Noise**: Typos or grammatical errors in text, which can confuse language models.  \n",
    "    - *Example*: A sentence with misspelled words or misplaced commas.  \n",
    "  - **Audio Noise**: Unwanted background sounds or distortions in audio recordings.  \n",
    "    - *Example*: A conversation recorded with heavy traffic background noise.\n",
    "\n",
    "- **Annotator Label Noise**  \n",
    "  This type of noise occurs during the labeling process when annotators assign incorrect or inconsistent labels.  \n",
    "  - *Example*: An image of a toy car might receive the label \"Sports Car\" from one annotator and \"Toy Car\" from others.  \n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "  > \n",
    "  > **Key Assumptions in Confident Learning (CL):**\n",
    "  > 1. The noise exists in the labels rather than the data itself.\n",
    "  > 2. Each example is assumed to have a single annotation.\n",
    "  \n",
    "These assumptions simplify the analysis by isolating the label noise and allowing the methods to focus on reducing errors in class assignments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strategies for Handling Noisy Labels\n",
    "\n",
    "There are two main strategies to address label noise:\n",
    "\n",
    "### 1. Model-Centric Methods: \"Change the Loss\"\n",
    "\n",
    "These approaches modify the training process to account for noisy labels within the loss function.\n",
    "\n",
    "- **Using Loss from Another Network**  \n",
    "  In methods like *Co-Teaching*, multiple models are trained at the same time. Each model assists in identifying and reducing the impact of mislabeled examples on the other.  \n",
    "  *Example*: Two neural networks learn from the same dataset, but each selects a subset of examples it deems to have reliable labels for the partner network.\n",
    "\n",
    "- **Direct Loss Modification**  \n",
    "  Here, the standard loss function is modified to be less sensitive to label noise.  \n",
    "  - **Symmetric Cross Entropy (SCE) Loss** is one variant that combines cross entropy with a reverse cross entropy term:\n",
    "    $$\n",
    "    \\text{SCE Loss} = \\alpha \\cdot \\text{Cross Entropy} + \\beta \\cdot \\text{Reverse Cross Entropy}\n",
    "    $$\n",
    "    where $\\alpha$ and $\\beta$ control the balance between the two components.\n",
    "\n",
    "- **Importance Reweighting**  \n",
    "  This method assigns different weights to training examples based on the likelihood that each label is accurate.  \n",
    "  - One may modify the loss as:\n",
    "    $$\n",
    "    \\text{Loss} = \\sum_{i=1}^{N} w_i \\cdot L\\big(y_i, f(x_i)\\big)\n",
    "    $$\n",
    "    where $w_i$ represents the weight for example $i$, $L$ is the loss function (such as cross entropy), $y_i$ is the label, and $f(x_i)$ is the network’s prediction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 2. Data-Centric Methods: \"Change the Data\"\n",
    "\n",
    "These techniques address label noise by enhancing the quality of the training set.\n",
    "\n",
    "- **Identifying Label Errors**  \n",
    "  Techniques focus on detecting and flagging potential mislabeled examples. Methods include:\n",
    "  - **Statistical Analysis**: Checking for data points whose predicted labels deviate significantly from the provided labels.\n",
    "  - **Model Predictions**: Using trained models to identify samples with high disagreement between the prediction and the given label.\n",
    "  - **Manual Review**: Involving experts to inspect and confirm labels for ambiguous cases.\n",
    "\n",
    "- **Learning with Cleaned Data**  \n",
    "  Once candidate label errors are identified, the dataset can be adjusted by:\n",
    "  - Removing mislabeled examples.\n",
    "  - Correcting labels when possible.\n",
    "  - Assigning lower weights to examples suspected of being noisy during training.\n",
    "\n",
    "> **Our Focus:** Since you are in a Datacentric AI course, we will focus on data-centric methods, which emphasize improving the quality of training data to enhance model performance. These techniques are particularly relevant in weak supervision scenarios, where the training data may contain significant label noise.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Having established the importance of data-centric methods for handling noisy labels—particularly through the identification and correction of label errors—we now turn our attention to the specialized techniques that make this possible. Detecting mislabeled instances is a critical step in improving data quality, which directly impacts the performance and reliability of machine learning models.\n",
    "> \n",
    "> This brings us to `Annotation Error Detection (AED)`, a collection of methodologies designed to systematically identify potential errors in data annotations. AED plays a critical role in the data curation process by ensuring that models are trained on accurate and trustworthy data. Focusing on the annotations themselves, AED methods complement the data-centric approach by providing tools to clean and refine datasets effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Annotation Error Detection (AED)\n",
    "\n",
    "Even carefully curated datasets can contain errors or inconsistencies in their annotations. AED focuses on automatically identifying these potential errors, helping human annotators and dataset creators to improve data quality. \n",
    "\n",
    "## Types of Annotation Errors\n",
    "\n",
    "AED identifies several types of annotation mistakes:\n",
    "\n",
    "1. **Incorrect Labels:**  \n",
    "   These occur when the given label is wrong. For instance, a positive review might be labeled as negative in sentiment analysis.\n",
    "\n",
    "2. **Inconsistencies:**  \n",
    "   Similar items may be labeled differently across a dataset. In tasks like named entity recognition, the same person's name might be tagged as a person in some cases but not in others due to variable interpretations or changes in guidelines.\n",
    "\n",
    "3. **Ambiguities:**  \n",
    "   These arise when data can reasonably be interpreted in more than one way, but the annotation scheme permits only one label. An example is a sentence that could be seen as both sarcastic and sincere in sentiment analysis.\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"images/label_errors1.png\" width=\"100%\" height=\"100%\" />\n",
    "</p>\n",
    "<p align=\"center\">\n",
    "<a href=\"https://labelerrors.com\">Source</a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Categories and Techniques of AED Methods\n",
    "\n",
    "AED methods generally fall into two classes:\n",
    "\n",
    "1. **Flaggers:**  \n",
    "   These methods output a binary decision indicating whether an instance is likely correct or erroneous.\n",
    "   \n",
    "2. **Scorers:**  \n",
    "   These methods assign a probability score to each instance, indicating the likelihood that the annotation is in error. For example, instances with higher scores require more attention.\n",
    "\n",
    "Various techniques help in detecting annotation errors:\n",
    "\n",
    "- **Model-Based Methods:**  \n",
    "  A machine learning model (such as a classifier) is trained on a subset of data to assess the probability that an instance is misannotated.\n",
    "\n",
    "- **Variation-Based Methods:**  \n",
    "  These techniques compare similar items. If similar items receive different labels, it may signal an error in one of the annotations.\n",
    "\n",
    "- **Ensemble Methods:**  \n",
    "  Combining multiple AED methods can improve overall accuracy by taking advantage of the strengths of each approach.\n",
    "\n",
    "- **Vector Space Proximity Methods:**  \n",
    "  Dense embeddings are used to map instances into a vector space. If an instance with a certain label lies far from other similar instances, this anomaly can indicate an annotation error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Applications of AED\n",
    "\n",
    "AED has practical use cases across different machine learning tasks, such as:\n",
    "\n",
    "- **Document Classification:**  \n",
    "  Detecting misclassified documents.\n",
    "\n",
    "- **Named Entity Recognition:**  \n",
    "  Identifying inconsistent or incorrect entity tags.\n",
    "\n",
    "- **Image Classification:**  \n",
    "  Flagging images that might have wrong labels.\n",
    "\n",
    "- **Pixel-Wise Segmentation:**  \n",
    "  Highlighting image regions where annotations may be incorrect.\n",
    "\n",
    "- **Regression Tasks:**  \n",
    "  Detecting outliers or points with potentially misannotated values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Formal Definition and Mathematical Formulation\n",
    "\n",
    "Given an annotated dataset  \n",
    "$$\n",
    "D = \\{(x_i, \\tilde{y_i})\\}_{i=1}^{N},\n",
    "$$  \n",
    "where $x_i$ is an input (such as a sentence or token) and $\\tilde{y_i}$ is the observed label, the goal of AED is to identify a subset  \n",
    "$$\n",
    "E \\subseteq D\n",
    "$$  \n",
    "such that for each $(x_i, \\tilde{y_i}) \\in E$, the observed label $\\tilde{y_i}$ likely differs from the unknown true label $y_i^*$.\n",
    "\n",
    "Depending on the AED method, the operations are defined as:\n",
    "\n",
    "1. **For Flaggers:**  \n",
    "   $$\n",
    "   f(x_i, \\tilde{y_i}) = \n",
    "   \\begin{cases}\n",
    "   1 & \\text{if } (x_i, \\tilde{y_i}) \\text{ is likely erroneous}, \\\\\n",
    "   0 & \\text{otherwise.}\n",
    "   \\end{cases}\n",
    "   $$\n",
    "\n",
    "2. **For Scorers:**  \n",
    "   $$\n",
    "   f(x_i, \\tilde{y_i}) = s_i \\quad \\text{with} \\quad s_i \\in [0, 1],\n",
    "   $$\n",
    "   where a higher value of $s_i$ indicates a greater chance that $\\tilde{y_i}$ is incorrect.\n",
    "\n",
    "An objective of AED methods can be described as:\n",
    "$$\n",
    "\\max_f \\, F1\\left(\\{(x_i, \\tilde{y_i}) \\mid f(x_i, \\tilde{y_i}) = 1\\}, E_{\\text{true}}\\right),\n",
    "$$\n",
    "where $E_{\\text{true}}$ is the set of truly erroneous instances, generally unknown in practice.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Key Components of the AED Task\n",
    "\n",
    "AED tasks involve several components:\n",
    "\n",
    "1. **Input:**  \n",
    "   An annotated dataset is provided with only the observed labels $\\tilde{y_i}$. There is no direct access to the true labels $y_i^*$, making error detection a challenging weakly supervised task.\n",
    "\n",
    "2. **Output:**  \n",
    "   Depending on the method:\n",
    "   \n",
    "   - **Flaggers:**  \n",
    "     Provide a set of flagged instances:\n",
    "     $$\n",
    "     E = \\{(x_i, \\tilde{y_i}) \\mid \\text{is\\_error}(x_i, \\tilde{y_i}) = \\text{True}\\}.\n",
    "     $$\n",
    "   \n",
    "   - **Scorers:**  \n",
    "     Provide a ranked list:\n",
    "     $$\n",
    "     L = [(x_i, \\tilde{y_i}, s_i)],\n",
    "     $$\n",
    "     where higher $s_i$ indicates a greater likelihood of error.\n",
    "\n",
    "3. **Granularity:**  \n",
    "   AED can operate at different levels:\n",
    "   \n",
    "   - **Document or Sentence Level:** Suitable for text classification.\n",
    "   - **Token Level:** Common in tagging tasks such as part-of-speech tagging.\n",
    "   - **Span Level:** Relevant for tasks like named entity recognition.\n",
    "\n",
    "4. **Evaluation Metrics:**  \n",
    "   - **Flaggers:**  \n",
    "     Use metrics such as precision, recall, and F1 score.\n",
    "   \n",
    "   - **Scorers:**  \n",
    "     Focus on ranking metrics like average precision, Precision@k, and Recall@k.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenges in AED\n",
    "\n",
    "AED faces several challenges:\n",
    "\n",
    "- **Lack of Ground Truth:**  \n",
    "  The true labels $y_i^*$ are generally unknown, making it hard to measure the exact performance of AED methods.\n",
    "\n",
    "- **Class Imbalance:**  \n",
    "  Correct labels usually outnumber erroneous ones, which may lead to biased detection methods that miss the minority class.\n",
    "\n",
    "- **Task and Domain Specificity:**  \n",
    "  Techniques that work for one task (like sentiment analysis) may not transfer directly to another (such as named entity recognition).\n",
    "\n",
    "- **Distinguishing Errors from Valid Cases:**  \n",
    "  AED methods must separate true annotation errors from edge cases or ambiguous instances where multiple interpretations may be valid. Incorrectly flagging these instances can lead to wasted manual review effort.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Distinction from Related Data Quality Tasks\n",
    "\n",
    "AED is related to but distinct from tasks such as noise-strong learning and general data cleaning:\n",
    "\n",
    "- **Noise-Sturdy Learning:**  \n",
    "  Focuses on developing models that tolerate noisy data during training.\n",
    "\n",
    "- **Data Cleaning:**  \n",
    "  Involves directly correcting errors in the dataset.\n",
    "\n",
    "AED specifically targets discrepancies between the observed labels $\\tilde{y_i}$ and the latent true labels $y_i^*$. As such, it is a preparatory step in data curation processes, ensuring that model training and evaluation are based on more reliable data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Refining Weak Supervision with AED\n",
    "\n",
    "In weak supervision, the labels provided by a label model serve as probabilistic indicators rather than absolute truths. AED can be applied as a final step in the weak supervision pipeline to enhance label quality.\n",
    "\n",
    "### How AED Enhances Weak Supervision\n",
    "\n",
    "- **Using Weak Labels as Input:**  \n",
    "  The label model gives a weak label $\\tilde{y_i}$ along with a measure of confidence. AED accepts these probabilistic labels and evaluates them for consistency.\n",
    "\n",
    "- **Error Detection:**  \n",
    "  AED methods analyze the weak labels to spot instances where the probability suggests a deviation from the true latent label $y_i^*$.\n",
    "\n",
    "- **Dataset Refinement Strategies:**  \n",
    "  The insights provided by AED can guide further actions, such as:\n",
    "  \n",
    "  - **Manual Review and Correction:**  \n",
    "    Flagged instances can be examined by experts, who may correct the labels or offer additional clarification.\n",
    "  \n",
    "  - **Selective Data Exclusion:**  \n",
    "    Instances with a high error likelihood may be removed from the training dataset to avoid influencing the model with noisy data.\n",
    "\n",
    "### Benefits of Incorporating AED in Weak Supervision\n",
    "\n",
    "- **Improved Data Quality:**  \n",
    "  By detecting and correcting potential annotation errors, AED leads to a dataset that better represents the true basic labels.\n",
    "\n",
    "- **Higher Model Accuracy:**  \n",
    "  Models trained on an AED-refined dataset are less likely to learn from incorrect annotations, resulting in improved performance.\n",
    "\n",
    "- **Feedback on Weak Supervision:**  \n",
    "  AED can also reveal systematic issues with the weak supervision process, such as inconsistent or biased label assignments, which can guide further improvements.\n",
    "\n",
    "This detailed overview of AED provides a clear framework for understanding how to detect and manage annotation errors in machine learning datasets. The mathematical formulations, techniques, and real-case considerations outlined here serve to deepen comprehension and support further study in this area."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Typology of Model-Probing Mislabeled Example Detection Methods\n",
    "\n",
    "The paper [proposed here](https://arxiv.org/abs/2410.15772) presents a unifying framework that connects various methods for detecting mislabeled examples in datasets by considering them as ways to probe trained machine learning models. The framework is built around four essential components, offering a clear structure that can both explain existing methods and guide the design of new ones.\n",
    "\n",
    "### Defining Mislabeled Examples\n",
    "\n",
    "Before exploring the framework in detail, it is important to understand what is meant by a mislabeled example. The paper discusses the definition in two settings:\n",
    "\n",
    "#### 1. Deterministic Case\n",
    "\n",
    "- **Assumption:**  \n",
    "  There exists a true, fixed function  \n",
    "  $$\n",
    "  f: X \\rightarrow Y\n",
    "  $$  \n",
    "  that assigns a correct label $ y $ to every input $ x $.\n",
    "\n",
    "- **Ideal Situation:**  \n",
    "  A perfect dataset would be  \n",
    "  $$\n",
    "  D_{\\text{noiseless}} = \\{(x_i, y_i = f(x_i))\\}_{i=1}^n.\n",
    "  $$\n",
    "  \n",
    "- **Realistic Scenario:**  \n",
    "  In practice, the training data is given by  \n",
    "  $$\n",
    "  D_{\\text{train}} = \\{(x_i, \\tilde{y}_i)\\}_{i=1}^n,\n",
    "  $$  \n",
    "  where some examples have labels that do not match $ f(x_i) $; these are the mislabeled examples.\n",
    "\n",
    "- **Mislabeled Definition:**  \n",
    "  An example $(x_i, \\tilde{y}_i)$ is mislabeled if  \n",
    "  $$\n",
    "  \\tilde{y}_i \\neq f(x_i).\n",
    "  $$\n",
    "\n",
    "#### 2. Stochastic Case\n",
    "\n",
    "- **Assumption:**  \n",
    "  The true concept is represented by a conditional probability distribution  \n",
    "  $$\n",
    "  P(Y \\mid X).\n",
    "  $$  \n",
    "  This means that for a given input $ x $, multiple labels might have non-zero probabilities.\n",
    "\n",
    "- **Ideal Situation:**  \n",
    "  The ideal training dataset is sampled from the joint distribution  \n",
    "  $$\n",
    "  D_{\\text{ideal}} = \\{(x_i, y_i)\\}_{i=1}^n,\n",
    "  $$  \n",
    "  where the labels reflect the probabilities given by $ P(Y \\mid X) $.\n",
    "\n",
    "- **Realistic Scenario:**  \n",
    "  The available training data is drawn from a possibly altered distribution  \n",
    "  $$\n",
    "  P(X, \\tilde{Y}),\n",
    "  $$  \n",
    "  meaning that some labels could be reported with probabilities different from those in the true distribution.\n",
    "\n",
    "- **Mislabeled Definition with Threshold:**  \n",
    "  Defining a mislabeled example requires additional care. Consider a threshold $ \\tau $ (with $ 0 \\leq \\tau \\leq 1 $). An example $(x, y)$ is considered mislabeled if  \n",
    "  $$\n",
    "  P(Y = y \\mid X = x) < \\tau.\n",
    "  $$  \n",
    "  This approach accommodates situations where a label might be technically plausible but is unlikely compared to other possibilities. The deterministic case is simply a special situation where the conditional probability is concentrated entirely on one label.\n",
    "\n",
    "### Practical Relevance\n",
    "\n",
    "- **Trust Scores:**  \n",
    "  In practice, methods use trust scores that approximate the conditional probability $ P(Y = y \\mid X = x) $. These scores help identify examples whose labels are unlikely given the input data.\n",
    "\n",
    "- **Real Case Example:**  \n",
    "  Imagine a medical diagnosis system where $ X $ represents patient data and $ Y $ represents the diagnosis. In a deterministic view, each symptom profile would point to one correct diagnosis. However, in a more realistic stochastic view, there might be uncertainty because several diagnoses could explain the symptoms with different probabilities. If a patient's data shows a 99% chance for Diagnosis A and a 1% chance for Diagnosis B, and the label assigned is Diagnosis B, a threshold-based approach would mark this record as potentially mislabeled if $ \\tau $ is set above 1%.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our Dataset\n",
    "\n",
    "We'll load the dataset from our WSL Pipeline Notebook and perform Annotation Error Detection on it. We'll the weakly annotated dataset and apply AED techniques to identify potential errors or inconsistencies in the labels. This process will help refine the dataset and enhance the quality of the training data for downstream tasks.\n",
    "\n",
    "We'll compare the performance of different AED methods and evaluate their effectiveness producing a dataset that is more capable of training high-performing machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_test = pd.read_parquet(\"data/b2w/test_cleaned_with_labels.parquet\")\n",
    "df_train = pd.read_parquet(\"outputs/ws-pipeline/df_train_weakly_labeled.parquet\")\n",
    "df_dev = pd.read_parquet(\"data/b2w/dev.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "source",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "review_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "label_snorkel",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "label_majority_vote",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "226c2b4a-b3e9-4bb6-9321-f1fb2a9bab1f",
       "rows": [
        [
         "0",
         "b2w",
         "79d9a98a62d9adff5e2c8e2bed824e4d524695e0a1e2353a9bf995d8732dd7d3_18450635",
         "nao gostei do produto! - o acabamento e muito bom. mas a casa nao fica montada! encaixes frouxos! ja tentei colar com tudo! nao consegui! pelo preco esperava muito mais!",
         "1",
         "1"
        ],
        [
         "1",
         "b2w",
         "5177b7800f360f47ccd69afa43def2180777c1f6a3b26d6820808ac8b8a48903_32353831",
         "produto nao funciona - produto nao funcio, veio com problema na saida para instalar a camera de re e tem mais de uma semana que estou tentando trocar o produto e nao consigo, passam de uma empresa para outra e nao resolvem nada. nao recomendo nem comprar mais nesse site, pois nao oferece assistencia.",
         "0",
         "0"
        ],
        [
         "2",
         "b2w",
         "fc0cc6d9c2e4539762936bcb5b0e855df6b5e08229b00d0d40e75a47dc77e103_28697857",
         "nao recebi, portanto nao conheco o produto - paguei esse produto em 16-02 e ainda nao recebi. parece que houve problema nos correios, mas a vendedora nao me passa noticias do produto.",
         "0",
         "0"
        ],
        [
         "3",
         "b2w",
         "b3a8b907623ceece9aef15896c82a6ea3d932be9f8a856a581c8ecb89172ba05_132475745",
         "maravilhoso - parabens pela eficiencia na entrega,o produto tambem superou toda expectativa!",
         "1",
         "1"
        ],
        [
         "4",
         "b2w",
         "5e1611aae145617b04b247314421e2d65ef9d7800b2e955dde2d5d8656d0b421_24124006",
         "decepcionado - relogio com a mesma qualidade de uma casca de ovo! partes e pecas simplesmente soltaram-se com 5 minutos de uso! sinto-me traido pelas americanas.com por divulgar um produto de tao baixa qualidade, pois tenho certeza que ela nao quer ser um novo aliexpress.",
         "0",
         "0"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>review_id</th>\n",
       "      <th>text</th>\n",
       "      <th>label_snorkel</th>\n",
       "      <th>label_majority_vote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b2w</td>\n",
       "      <td>79d9a98a62d9adff5e2c8e2bed824e4d524695e0a1e235...</td>\n",
       "      <td>nao gostei do produto! - o acabamento e muito ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b2w</td>\n",
       "      <td>5177b7800f360f47ccd69afa43def2180777c1f6a3b26d...</td>\n",
       "      <td>produto nao funciona - produto nao funcio, vei...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b2w</td>\n",
       "      <td>fc0cc6d9c2e4539762936bcb5b0e855df6b5e08229b00d...</td>\n",
       "      <td>nao recebi, portanto nao conheco o produto - p...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b2w</td>\n",
       "      <td>b3a8b907623ceece9aef15896c82a6ea3d932be9f8a856...</td>\n",
       "      <td>maravilhoso - parabens pela eficiencia na entr...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b2w</td>\n",
       "      <td>5e1611aae145617b04b247314421e2d65ef9d7800b2e95...</td>\n",
       "      <td>decepcionado - relogio com a mesma qualidade d...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  source                                          review_id  \\\n",
       "0    b2w  79d9a98a62d9adff5e2c8e2bed824e4d524695e0a1e235...   \n",
       "1    b2w  5177b7800f360f47ccd69afa43def2180777c1f6a3b26d...   \n",
       "2    b2w  fc0cc6d9c2e4539762936bcb5b0e855df6b5e08229b00d...   \n",
       "3    b2w  b3a8b907623ceece9aef15896c82a6ea3d932be9f8a856...   \n",
       "4    b2w  5e1611aae145617b04b247314421e2d65ef9d7800b2e95...   \n",
       "\n",
       "                                                text  label_snorkel  \\\n",
       "0  nao gostei do produto! - o acabamento e muito ...              1   \n",
       "1  produto nao funciona - produto nao funcio, vei...              0   \n",
       "2  nao recebi, portanto nao conheco o produto - p...              0   \n",
       "3  maravilhoso - parabens pela eficiencia na entr...              1   \n",
       "4  decepcionado - relogio com a mesma qualidade d...              0   \n",
       "\n",
       "   label_majority_vote  \n",
       "0                    1  \n",
       "1                    0  \n",
       "2                    0  \n",
       "3                    1  \n",
       "4                    0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's estabilish a reference point for the dataset if it was trained with the weak labels and then evaluate the model performance after the AED process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import TfidfVectorizer from sklearn for converting text data into TF-IDF features\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.classification import (\n",
    "    train_and_evaluate_classification_models,\n",
    "    print_classification_metrics,\n",
    ")\n",
    "\n",
    "tfidf = TfidfVectorizer(\n",
    "    ngram_range=(1, 2),\n",
    "    strip_accents=\"unicode\",\n",
    "    lowercase=True,\n",
    "    max_features=1000,\n",
    "    min_df=3,\n",
    ")\n",
    "\n",
    "X_train = tfidf.fit_transform(df_train[\"text\"])\n",
    "y_train = df_train[\"label_majority_vote\"]\n",
    "\n",
    "X_dev = tfidf.transform(df_dev[\"text\"])\n",
    "y_dev = df_dev[\"label\"]\n",
    "\n",
    "X_test = tfidf.transform(df_test[\"text\"])\n",
    "y_test = df_test[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Calibrated-LSVC - F1: 0.9766 - Balanced Accuracy: 0.9704 - Accuracy: 0.9766 - Matthews Correlation Coefficient: 0.9410 - Elapsed time: 17.61s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96     27604\n",
      "           1       0.98      0.98      0.98     73857\n",
      "\n",
      "    accuracy                           0.98    101461\n",
      "   macro avg       0.97      0.97      0.97    101461\n",
      "weighted avg       0.98      0.98      0.98    101461\n",
      "\n",
      "[[26405  1199]\n",
      " [ 1171 72686]]\n",
      "******************** \n",
      "\n",
      "Model: Logistic Regression - F1: 0.9661 - Balanced Accuracy: 0.9702 - Accuracy: 0.9661 - Matthews Correlation Coefficient: 0.9180 - Elapsed time: 2.76s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.98      0.94     27604\n",
      "           1       0.99      0.96      0.98     73857\n",
      "\n",
      "    accuracy                           0.97    101461\n",
      "   macro avg       0.95      0.97      0.96    101461\n",
      "weighted avg       0.97      0.97      0.97    101461\n",
      "\n",
      "[[27024   580]\n",
      " [ 2857 71000]]\n",
      "******************** \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jacob/.cache/pypoetry/virtualenvs/imd3011-datacentric-ai-ZY2qswVr-py3.12/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning:\n",
      "\n",
      "A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Random Forest - F1: 0.9743 - Balanced Accuracy: 0.9642 - Accuracy: 0.9743 - Matthews Correlation Coefficient: 0.9348 - Elapsed time: 102.92s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95     27604\n",
      "           1       0.98      0.99      0.98     73857\n",
      "\n",
      "    accuracy                           0.97    101461\n",
      "   macro avg       0.97      0.96      0.97    101461\n",
      "weighted avg       0.97      0.97      0.97    101461\n",
      "\n",
      "[[26004  1600]\n",
      " [ 1008 72849]]\n",
      "******************** \n",
      "\n",
      "Model: XGBoost - F1: 0.9786 - Balanced Accuracy: 0.9720 - Accuracy: 0.9786 - Matthews Correlation Coefficient: 0.9459 - Elapsed time: 65.37s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96     27604\n",
      "           1       0.98      0.99      0.99     73857\n",
      "\n",
      "    accuracy                           0.98    101461\n",
      "   macro avg       0.97      0.97      0.97    101461\n",
      "weighted avg       0.98      0.98      0.98    101461\n",
      "\n",
      "[[26431  1173]\n",
      " [  999 72858]]\n",
      "******************** \n",
      "\n",
      "Could not generate calibration plot for SGD: This 'SGDClassifier' has no attribute 'predict_proba'\n",
      "Model: SGD - F1: 0.9598 - Balanced Accuracy: 0.9665 - Accuracy: 0.9598 - Matthews Correlation Coefficient: 0.9044 - Elapsed time: 1.20s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.98      0.93     27604\n",
      "           1       0.99      0.95      0.97     73857\n",
      "\n",
      "    accuracy                           0.96    101461\n",
      "   macro avg       0.94      0.97      0.95    101461\n",
      "weighted avg       0.96      0.96      0.96    101461\n",
      "\n",
      "[[27084   520]\n",
      " [ 3554 70303]]\n",
      "******************** \n",
      "\n",
      "Model: Naive Bayes - F1: 0.9473 - Balanced Accuracy: 0.9403 - Accuracy: 0.9473 - Matthews Correlation Coefficient: 0.8690 - Elapsed time: 1.68s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.92      0.91     27604\n",
      "           1       0.97      0.96      0.96     73857\n",
      "\n",
      "    accuracy                           0.95    101461\n",
      "   macro avg       0.93      0.94      0.93    101461\n",
      "weighted avg       0.95      0.95      0.95    101461\n",
      "\n",
      "[[25531  2073]\n",
      " [ 3277 70580]]\n",
      "******************** \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jacob/.cache/pypoetry/virtualenvs/imd3011-datacentric-ai-ZY2qswVr-py3.12/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning:\n",
      "\n",
      "A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: K-Nearest Neighbors - F1: 0.8400 - Balanced Accuracy: 0.7182 - Accuracy: 0.8400 - Matthews Correlation Coefficient: 0.5713 - Elapsed time: 181.45s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.45      0.61     27604\n",
      "           1       0.83      0.99      0.90     73857\n",
      "\n",
      "    accuracy                           0.84    101461\n",
      "   macro avg       0.87      0.72      0.75    101461\n",
      "weighted avg       0.85      0.84      0.82    101461\n",
      "\n",
      "[[12447 15157]\n",
      " [ 1077 72780]]\n",
      "******************** \n",
      "\n",
      "Model: Decision Tree - F1: 0.9537 - Balanced Accuracy: 0.9431 - Accuracy: 0.9537 - Matthews Correlation Coefficient: 0.8834 - Elapsed time: 324.53s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.92     27604\n",
      "           1       0.97      0.97      0.97     73857\n",
      "\n",
      "    accuracy                           0.95    101461\n",
      "   macro avg       0.94      0.94      0.94    101461\n",
      "weighted avg       0.95      0.95      0.95    101461\n",
      "\n",
      "[[25389  2215]\n",
      " [ 2484 71373]]\n",
      "******************** \n",
      "\n",
      "Model: Extra Trees - F1: 0.9768 - Balanced Accuracy: 0.9693 - Accuracy: 0.9768 - Matthews Correlation Coefficient: 0.9413 - Elapsed time: 159.61s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.96     27604\n",
      "           1       0.98      0.99      0.98     73857\n",
      "\n",
      "    accuracy                           0.98    101461\n",
      "   macro avg       0.97      0.97      0.97    101461\n",
      "weighted avg       0.98      0.98      0.98    101461\n",
      "\n",
      "[[26307  1297]\n",
      " [ 1058 72799]]\n",
      "******************** \n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_results, classification_reports, calibration_plot = (\n",
    "    train_and_evaluate_classification_models(X_train, y_train)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "F1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Balanced Accuracy",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Accuracy",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Matthews Correlation Coefficient",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Elapsed Time",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Confusion Matrix",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Classification Report",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "ff305385-a701-4d0b-ab99-fd3a941ba25a",
       "rows": [
        [
         "3",
         "XGBoost",
         "0.9785927597796198",
         "0.9719900100896597",
         "0.9785927597796198",
         "0.9458558004969122",
         "65.36631417274475",
         "[[26431  1173]\n [  999 72858]]",
         "              precision    recall  f1-score   support\n\n           0       0.96      0.96      0.96     27604\n           1       0.98      0.99      0.99     73857\n\n    accuracy                           0.98    101461\n   macro avg       0.97      0.97      0.97    101461\nweighted avg       0.98      0.98      0.98    101461\n"
        ],
        [
         "8",
         "Extra Trees",
         "0.9767891110870186",
         "0.9693445382909658",
         "0.9767891110870186",
         "0.9412576022527284",
         "159.61051392555237",
         "[[26307  1297]\n [ 1058 72799]]",
         "              precision    recall  f1-score   support\n\n           0       0.96      0.95      0.96     27604\n           1       0.98      0.99      0.98     73857\n\n    accuracy                           0.98    101461\n   macro avg       0.97      0.97      0.97    101461\nweighted avg       0.98      0.98      0.98    101461\n"
        ],
        [
         "0",
         "Calibrated-LSVC",
         "0.9766412710302481",
         "0.9703546515397091",
         "0.9766412710302481",
         "0.9410084121765575",
         "17.6076762676239",
         "[[26405  1199]\n [ 1171 72686]]",
         "              precision    recall  f1-score   support\n\n           0       0.96      0.96      0.96     27604\n           1       0.98      0.98      0.98     73857\n\n    accuracy                           0.98    101461\n   macro avg       0.97      0.97      0.97    101461\nweighted avg       0.98      0.98      0.98    101461\n"
        ],
        [
         "2",
         "Random Forest",
         "0.9742955421294882",
         "0.9641946952177176",
         "0.9742955421294882",
         "0.9347687921322199",
         "102.9247989654541",
         "[[26004  1600]\n [ 1008 72849]]",
         "              precision    recall  f1-score   support\n\n           0       0.96      0.94      0.95     27604\n           1       0.98      0.99      0.98     73857\n\n    accuracy                           0.97    101461\n   macro avg       0.97      0.96      0.97    101461\nweighted avg       0.97      0.97      0.97    101461\n"
        ],
        [
         "1",
         "Logistic Regression",
         "0.9661249149919674",
         "0.9701528461310631",
         "0.9661249149919674",
         "0.9180313141334473",
         "2.7616326808929443",
         "[[27024   580]\n [ 2857 71000]]",
         "              precision    recall  f1-score   support\n\n           0       0.90      0.98      0.94     27604\n           1       0.99      0.96      0.98     73857\n\n    accuracy                           0.97    101461\n   macro avg       0.95      0.97      0.96    101461\nweighted avg       0.97      0.97      0.97    101461\n"
        ],
        [
         "4",
         "SGD",
         "0.95984664058111",
         "0.9665210673534785",
         "0.95984664058111",
         "0.9044107829742621",
         "1.2049269676208496",
         "[[27084   520]\n [ 3554 70303]]",
         "              precision    recall  f1-score   support\n\n           0       0.88      0.98      0.93     27604\n           1       0.99      0.95      0.97     73857\n\n    accuracy                           0.96    101461\n   macro avg       0.94      0.97      0.95    101461\nweighted avg       0.96      0.96      0.96    101461\n"
        ],
        [
         "7",
         "Decision Tree",
         "0.9536866382156691",
         "0.9430627229341783",
         "0.9536866382156691",
         "0.8834494232135564",
         "324.5323483943939",
         "[[25389  2215]\n [ 2484 71373]]",
         "              precision    recall  f1-score   support\n\n           0       0.91      0.92      0.92     27604\n           1       0.97      0.97      0.97     73857\n\n    accuracy                           0.95    101461\n   macro avg       0.94      0.94      0.94    101461\nweighted avg       0.95      0.95      0.95    101461\n"
        ],
        [
         "5",
         "Naive Bayes",
         "0.9472703797518258",
         "0.9402663315979924",
         "0.9472703797518258",
         "0.8690484341678048",
         "1.6781938076019287",
         "[[25531  2073]\n [ 3277 70580]]",
         "              precision    recall  f1-score   support\n\n           0       0.89      0.92      0.91     27604\n           1       0.97      0.96      0.96     73857\n\n    accuracy                           0.95    101461\n   macro avg       0.93      0.94      0.93    101461\nweighted avg       0.95      0.95      0.95    101461\n"
        ],
        [
         "6",
         "K-Nearest Neighbors",
         "0.8399976345590917",
         "0.7181653389689001",
         "0.8399976345590917",
         "0.5712933725881209",
         "181.45147609710693",
         "[[12447 15157]\n [ 1077 72780]]",
         "              precision    recall  f1-score   support\n\n           0       0.92      0.45      0.61     27604\n           1       0.83      0.99      0.90     73857\n\n    accuracy                           0.84    101461\n   macro avg       0.87      0.72      0.75    101461\nweighted avg       0.85      0.84      0.82    101461\n"
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 9
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>F1</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Matthews Correlation Coefficient</th>\n",
       "      <th>Elapsed Time</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "      <th>Classification Report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.978593</td>\n",
       "      <td>0.971990</td>\n",
       "      <td>0.978593</td>\n",
       "      <td>0.945856</td>\n",
       "      <td>65.366314</td>\n",
       "      <td>[[26431  1173]\\n [  999 72858]]</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Extra Trees</td>\n",
       "      <td>0.976789</td>\n",
       "      <td>0.969345</td>\n",
       "      <td>0.976789</td>\n",
       "      <td>0.941258</td>\n",
       "      <td>159.610514</td>\n",
       "      <td>[[26307  1297]\\n [ 1058 72799]]</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Calibrated-LSVC</td>\n",
       "      <td>0.976641</td>\n",
       "      <td>0.970355</td>\n",
       "      <td>0.976641</td>\n",
       "      <td>0.941008</td>\n",
       "      <td>17.607676</td>\n",
       "      <td>[[26405  1199]\\n [ 1171 72686]]</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.974296</td>\n",
       "      <td>0.964195</td>\n",
       "      <td>0.974296</td>\n",
       "      <td>0.934769</td>\n",
       "      <td>102.924799</td>\n",
       "      <td>[[26004  1600]\\n [ 1008 72849]]</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.966125</td>\n",
       "      <td>0.970153</td>\n",
       "      <td>0.966125</td>\n",
       "      <td>0.918031</td>\n",
       "      <td>2.761633</td>\n",
       "      <td>[[27024   580]\\n [ 2857 71000]]</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SGD</td>\n",
       "      <td>0.959847</td>\n",
       "      <td>0.966521</td>\n",
       "      <td>0.959847</td>\n",
       "      <td>0.904411</td>\n",
       "      <td>1.204927</td>\n",
       "      <td>[[27084   520]\\n [ 3554 70303]]</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.953687</td>\n",
       "      <td>0.943063</td>\n",
       "      <td>0.953687</td>\n",
       "      <td>0.883449</td>\n",
       "      <td>324.532348</td>\n",
       "      <td>[[25389  2215]\\n [ 2484 71373]]</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.947270</td>\n",
       "      <td>0.940266</td>\n",
       "      <td>0.947270</td>\n",
       "      <td>0.869048</td>\n",
       "      <td>1.678194</td>\n",
       "      <td>[[25531  2073]\\n [ 3277 70580]]</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>0.839998</td>\n",
       "      <td>0.718165</td>\n",
       "      <td>0.839998</td>\n",
       "      <td>0.571293</td>\n",
       "      <td>181.451476</td>\n",
       "      <td>[[12447 15157]\\n [ 1077 72780]]</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model        F1  Balanced Accuracy  Accuracy  \\\n",
       "3              XGBoost  0.978593           0.971990  0.978593   \n",
       "8          Extra Trees  0.976789           0.969345  0.976789   \n",
       "0      Calibrated-LSVC  0.976641           0.970355  0.976641   \n",
       "2        Random Forest  0.974296           0.964195  0.974296   \n",
       "1  Logistic Regression  0.966125           0.970153  0.966125   \n",
       "4                  SGD  0.959847           0.966521  0.959847   \n",
       "7        Decision Tree  0.953687           0.943063  0.953687   \n",
       "5          Naive Bayes  0.947270           0.940266  0.947270   \n",
       "6  K-Nearest Neighbors  0.839998           0.718165  0.839998   \n",
       "\n",
       "   Matthews Correlation Coefficient  Elapsed Time  \\\n",
       "3                          0.945856     65.366314   \n",
       "8                          0.941258    159.610514   \n",
       "0                          0.941008     17.607676   \n",
       "2                          0.934769    102.924799   \n",
       "1                          0.918031      2.761633   \n",
       "4                          0.904411      1.204927   \n",
       "7                          0.883449    324.532348   \n",
       "5                          0.869048      1.678194   \n",
       "6                          0.571293    181.451476   \n",
       "\n",
       "                  Confusion Matrix  \\\n",
       "3  [[26431  1173]\\n [  999 72858]]   \n",
       "8  [[26307  1297]\\n [ 1058 72799]]   \n",
       "0  [[26405  1199]\\n [ 1171 72686]]   \n",
       "2  [[26004  1600]\\n [ 1008 72849]]   \n",
       "1  [[27024   580]\\n [ 2857 71000]]   \n",
       "4  [[27084   520]\\n [ 3554 70303]]   \n",
       "7  [[25389  2215]\\n [ 2484 71373]]   \n",
       "5  [[25531  2073]\\n [ 3277 70580]]   \n",
       "6  [[12447 15157]\\n [ 1077 72780]]   \n",
       "\n",
       "                               Classification Report  \n",
       "3                precision    recall  f1-score   ...  \n",
       "8                precision    recall  f1-score   ...  \n",
       "0                precision    recall  f1-score   ...  \n",
       "2                precision    recall  f1-score   ...  \n",
       "1                precision    recall  f1-score   ...  \n",
       "4                precision    recall  f1-score   ...  \n",
       "7                precision    recall  f1-score   ...  \n",
       "5                precision    recall  f1-score   ...  \n",
       "6                precision    recall  f1-score   ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.sort_values(by=\"Matthews Correlation Coefficient\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric                                   Score\n",
      "=============================================\n",
      "Accuracy Score:                        0.95679\n",
      "Balanced Accuracy Score:               0.94548\n",
      "F1 Score (weighted):                   0.95664\n",
      "Cohen Kappa Score:                     0.89684\n",
      "Matthews Correlation Coefficient:      0.89696\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93      7871\n",
      "           1       0.96      0.97      0.97     18187\n",
      "\n",
      "    accuracy                           0.96     26058\n",
      "   macro avg       0.95      0.95      0.95     26058\n",
      "weighted avg       0.96      0.96      0.96     26058\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "Class 0 has 654 false negatives and 472 false positives.\n",
      "Class 1 has 472 false negatives and 654 false positives.\n",
      "The total number of errors is 1126 out of 26058 samples (error rate: 0.0432).\n",
      "Predicted      0       1     All\n",
      "True                            \n",
      "0          7,217     654   7,871\n",
      "1            472  17,715  18,187\n",
      "All        7,689  18,369  26,058\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Initialize a Logistic Regression model with balanced class weights\n",
    "# 'random_state' ensures reproducibility, 'n_jobs=-1' uses all available processors\n",
    "model_lr = LogisticRegression(random_state=271828, n_jobs=-1, class_weight=\"balanced\")\n",
    "\n",
    "# Fit the Logistic Regression model on the training data\n",
    "model_lr.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels for the test set\n",
    "y_test_pred = model_lr.predict(X_test)\n",
    "\n",
    "print_classification_metrics(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.calibration import calibration_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "prob_pos = model_lr.predict_proba(X_test)[:, 1]\n",
    "fraction_of_positives, mean_predicted_value = calibration_curve(\n",
    "    y_test, prob_pos, n_bins=10\n",
    ")\n",
    "\n",
    "plt.plot(mean_predicted_value, fraction_of_positives, \"s-\")\n",
    "plt.plot([0, 1], [0, 1], \"--\", color=\"gray\")\n",
    "plt.xlabel(\"Mean predicted value\")\n",
    "plt.ylabel(\"Fraction of positives\")\n",
    "plt.title(\"Calibration plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retagging with End-Model Predictions\n",
    "\n",
    "Retagging uses predictions from an interim model—often trained on a portion of the data—to identify and correct annotation errors. By comparing these predictions with the existing labels, discrepancies can be flagged, which may indicate mislabeling or inconsistencies.\n",
    "\n",
    "### Importance of Retagging\n",
    "\n",
    "Weakly labeled data is common in tasks where high-quality annotations are difficult or expensive to obtain. Noisy labels can introduce errors in the training process and reduce model performance. Retagging improves label quality by:\n",
    "\n",
    "- **Reducing Noise:** Updating labels based on reliable predictions helps reveal the true patterns in the data.\n",
    "- **Improving Model Performance:** An enhanced dataset leads to better training for downstream models.\n",
    "- **Efficiency:** It offers a flexible approach when manual re-annotation for large datasets is impractical.\n",
    "\n",
    "> **Analogy:** Think of retagging like a spellchecker reviewing a document. The document (dataset) may have typos (label errors), and the spellchecker (model) suggests corrections. Reviewing these suggestions improves overall accuracy, much like retagging improves the quality of training data.\n",
    "\n",
    "The process can be summarized as correcting the dataset so that it more accurately represents the fundamental class structure, leading to a refined model training process.\n",
    "\n",
    "\n",
    "### Steps to Apply Retagging\n",
    "\n",
    "To carry out retagging, consider the following steps:\n",
    "\n",
    "1. **Train the Model on a Subset:**  \n",
    " Divide your dataset into subsets. Train the model using one subset to ensure that predictions for the remaining data are out-of-sample.\n",
    "\n",
    "2. **Obtain Out-of-Sample Predictions:**  \n",
    " Use the trained model to generate predictions on the data that was not used during training. This practice reduces the risk of overfitting.\n",
    "\n",
    "3. **Compare Predictions with Existing Labels:**  \n",
    " Identify instances where the model's predictions differ from the given labels. These differences signal potential annotation errors.\n",
    "\n",
    "4. **Flag and Review Discrepancies:**  \n",
    " Treat the identified differences as candidates for correction. A systematic review—or even an iterative re-evaluation—can help decide whether to update the label.  \n",
    "\n",
    "Mathematically, if $ y_i $ is the original label and $\\hat{y}_i $ is the model's predicted probability for class membership, a flag might be raised when:\n",
    "\n",
    "$$\n",
    "|\\hat{y}_i - y_i| > \\epsilon\n",
    "$$\n",
    "\n",
    "where $epsilon $ is a chosen threshold reflecting acceptable variance.\n",
    "\n",
    "\n",
    "\n",
    "### Practical Considerations\n",
    "\n",
    "- **Model Confidence:**  \n",
    " When updating a label, consider the prediction confidence. High-confidence predictions are more likely to indicate actual errors and are safer to use for retagging.\n",
    "\n",
    "- **Iterative Refinement:**  \n",
    " Retagging can be repeated. After updating labels, retrain the model and recompute predictions, which can further enhance the dataset quality.\n",
    "\n",
    "- **Threshold Setting:**  \n",
    " Define thresholds for flagging discrepancies. For instance, only consider changes where:\n",
    "\n",
    "  $$\n",
    "  \\hat{y}_i > p \\quad \\text{or} \\quad \\hat{y}_i <1-p\n",
    "  $$\n",
    "\n",
    "  with $ p $ as probability threshold (e.g., 0.9) to ensure adjustments are based on confident predictions.\n",
    "\n",
    "- **Domain Expertise:**  \n",
    " Engage domain experts to review critical discrepancies. Their insight is valuable in ensuring that the retagging process aligns with real-world interpretations of the data.\n",
    "\n",
    "- **Avoiding Overfitting:**  \n",
    " It is essential that the predictions used for retagging are out-of-sample. Cross-validation techniques are advisable, as they provide a more realistic model performance estimate across the entire dataset.\n",
    "\n",
    "> **Note:** Retagging should be viewed as complement to manual annotation rather than a complete replacement. While it can correct many mistakes, there remains a risk of introducing new errors if the model makes incorrect predictions.\n",
    "\n",
    "### Additional Resources\n",
    "\n",
    "- For comparisons with other techniques on improving weak labels, consider reading [this study](https://arxiv.org/abs/2206.02280).  \n",
    "- For a detailed description of the retagging approach and more background, refer to the original [Retag Paper](https://aclanthology.org/W00-1907/).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "\n",
    "# Initialize stratified k-fold cross-validation with 20 splits\n",
    "# StratifiedKFold ensures that each fold has the same proportion of classes as the original dataset\n",
    "cross_validation = StratifiedKFold(n_splits=20, shuffle=True, random_state=271828)\n",
    "\n",
    "# Initialize a Logistic Regression model with balanced class weights\n",
    "# 'random_state' ensures reproducibility, 'n_jobs=-1' uses all available processors\n",
    "model_retag = LogisticRegression(\n",
    "    random_state=271828, n_jobs=-1, class_weight=\"balanced\"\n",
    ")\n",
    "\n",
    "# Perform cross-validated predictions on the training data\n",
    "# 'method=\"predict\"' returns the predicted class labels for each fold\n",
    "# 'n_jobs=2' is a trick to use all available processors threads, as n_jobs in model_retag is already set to -1\n",
    "y_train_retag = cross_val_predict(\n",
    "    estimator=model_retag,\n",
    "    X=X_train,\n",
    "    y=y_train,\n",
    "    cv=cross_validation,\n",
    "    method=\"predict\",\n",
    "    n_jobs=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric                                   Score\n",
      "=============================================\n",
      "Accuracy Score:                        0.95817\n",
      "Balanced Accuracy Score:               0.95267\n",
      "F1 Score (weighted):                   0.95826\n",
      "Cohen Kappa Score:                     0.90124\n",
      "Matthews Correlation Coefficient:      0.90130\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93      7871\n",
      "           1       0.97      0.97      0.97     18187\n",
      "\n",
      "    accuracy                           0.96     26058\n",
      "   macro avg       0.95      0.95      0.95     26058\n",
      "weighted avg       0.96      0.96      0.96     26058\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "Class 0 has 482 false negatives and 608 false positives.\n",
      "Class 1 has 608 false negatives and 482 false positives.\n",
      "The total number of errors is 1090 out of 26058 samples (error rate: 0.0418).\n",
      "Predicted      0       1     All\n",
      "True                            \n",
      "0          7,389     482   7,871\n",
      "1            608  17,579  18,187\n",
      "All        7,997  18,061  26,058\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Initialize a Logistic Regression model with balanced class weights\n",
    "# 'random_state' ensures reproducibility, 'n_jobs=-1' uses all available processors\n",
    "model_lr = LogisticRegression(random_state=271828, n_jobs=-1, class_weight=\"balanced\")\n",
    "\n",
    "# Fit the Logistic Regression model on the training data\n",
    "# y_train_retag is the re-tagged training labels obtained from cross-validation\n",
    "model_lr.fit(X_train, y_train_retag)\n",
    "\n",
    "# Predict the labels for the test set\n",
    "y_test_pred = model_lr.predict(X_test)\n",
    "\n",
    "print_classification_metrics(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric                                   Score\n",
      "=============================================\n",
      "Accuracy Score:                        0.95875\n",
      "Balanced Accuracy Score:               0.94984\n",
      "F1 Score (weighted):                   0.95869\n",
      "Cohen Kappa Score:                     0.90191\n",
      "Matthews Correlation Coefficient:      0.90193\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.93      7871\n",
      "           1       0.97      0.97      0.97     18187\n",
      "\n",
      "    accuracy                           0.96     26058\n",
      "   macro avg       0.95      0.95      0.95     26058\n",
      "weighted avg       0.96      0.96      0.96     26058\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "Class 0 has 572 false negatives and 503 false positives.\n",
      "Class 1 has 503 false negatives and 572 false positives.\n",
      "The total number of errors is 1075 out of 26058 samples (error rate: 0.0413).\n",
      "Predicted      0       1     All\n",
      "True                            \n",
      "0          7,299     572   7,871\n",
      "1            503  17,684  18,187\n",
      "All        7,802  18,256  26,058\n"
     ]
    }
   ],
   "source": [
    "# Dropping indexes where y_train_retag is different from y_train\n",
    "# This step ensures that only the examples where the re-tagged labels match the original labels are kept\n",
    "keep_indexes = (y_train_retag == y_train).values\n",
    "X_train_retag = X_train[keep_indexes]\n",
    "y_train_retag = y_train[keep_indexes]\n",
    "\n",
    "# Initialize a Logistic Regression model with balanced class weights\n",
    "# 'random_state' ensures reproducibility, 'n_jobs=-1' uses all available processors\n",
    "model_lr = LogisticRegression(random_state=271828, n_jobs=-1, class_weight=\"balanced\")\n",
    "\n",
    "# Fit the Logistic Regression model on the filtered training data\n",
    "model_lr.fit(X_train_retag, y_train_retag)\n",
    "\n",
    "# Predict the labels for the test set\n",
    "y_test_pred = model_lr.predict(X_test)\n",
    "\n",
    "print_classification_metrics(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\\n",
    "The table below summarizes the reduction in annotation errors achieved by applying retagging to the dataset. The retagging process uses model predictions to drop instances in the weakly annotated dataset, leading to a cleaner and more consistent set of training data.\n",
    "\n",
    "| Dataset     | Errors | Improvement    |\n",
    "|-------------|--------|----------------|\n",
    " WS          |1126   |                |\n",
    "| WS + Retag  |1075   | **4.5%**       |\n",
    "\n",
    "We can see hat the retagging process has reduced the total number of errors by approximately 4.5%, a significant enhancement given the straightforward nature of the approach.\n",
    "\n",
    "\n",
    "### Retagging in Traditional Supervised Learning\n",
    "\n",
    "While commonly associated with weak supervision, **retagging** can also be a valuable technique in traditional supervised learning. In this context, it involves using the predictions of an intermediate model to refine the original training labels, ultimately improving the quality of the dataset used to train the final model.\n",
    "\n",
    "This process can be particularly helpful in addressing several common issues present in real-world datasets:\n",
    "\n",
    "- **Annotation Errors:** Human annotators can make mistakes. An intermediate model can help identify and potentially correct these errors, leading to a more accurate gold standard.\n",
    "- **Label Inconsistencies:** Large datasets annotated by multiple individuals can suffer from inconsistencies in label application. Retagging can help standardize labels and improve consistency.\n",
    "- **Ambiguities:** Some data points may be inherently ambiguous or fall into gray areas within the labeling schema. Retagging can capitalize on the intermediate model's learned representations to potentially resolve these ambiguities more consistently.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Confident Learning\n",
    "\n",
    "Confident Learning presents a systematic framework for training models in settings where data labels may be corrupted or noisy. Its central idea is to incorporate a **label noise transition matrix** that quantifies the likelihood of observed labels being different from the true labels. This technique improves model performance by explicitly accounting for mislabeled examples during training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Components of Confident Learning\n",
    "\n",
    "#### 1. Label Noise Transition Matrix\n",
    "\n",
    "- **Definition:**  \n",
    " The label noise transition matrix is a table that shows the probability of observing a specific label given the true basic label. In a binary classification task, for example, if the true label is \"positive,\" the matrix provides probabilities for both \"positive\" (correct) and \"negative\" (incorrect) labels.\n",
    "\n",
    "- **Mathematical Representation:**  \n",
    " Let $\\hat{Q}(\\tilde{y} \\mid y^*)$ represent the transition probability, where $\\tilde{y}$ is the observed (possibly noisy) label and $y^*$ is the true label. For example, the probability of correctly labeling a \"bus\" might be written as:\n",
    "  \n",
    " $$\n",
    "  \\hat{Q}(\\tilde{y}=\\text{bus} \\mid y^*=\\text{bus})\n",
    "  $$\n",
    "  \n",
    " and the probability of a mislabel as:\n",
    "  \n",
    " $$\n",
    "  \\hat{Q}(\\tilde{y}=\\text{car} \\mid y^*=\\text{bus})\n",
    "  $$\n",
    "\n",
    "- **Utility:**  \n",
    " By analyzing both diagonal elements (correct label assignments) and off-diagonal elements (mislabeling cases), this matrix provides insights into the nature of label errors. These insights allow for adjustments during training to reduce the negative impact of noise.\n",
    "\n",
    "#### 2. Confidence Thresholding\n",
    "\n",
    "- **Concept:**  \n",
    " Not every model prediction is equally reliable. Confidence thresholding sets a predetermined level, and only predictions exceeding this threshold are considered during training. This selective approach helps reduce the influence of data points that might be mislabeled.\n",
    "\n",
    "- **Benefit:**  \n",
    " The method improves the learning process by focusing on predictions that the model is most certain about. It minimizes the risk of propagating errors from uncertain or noisy labels.\n",
    "\n",
    "#### 3. Model-Agnostic Implementation\n",
    "\n",
    "- **Flexibility:**  \n",
    " The framework does not depend on a particular type of model. Whether the model is simple or complex, such as logistic regression or a deep neural network, Confident Learning can be applied as long as the model outputs valid class probability estimates.\n",
    "\n",
    "- **Implication:**  \n",
    " This broad applicability makes the method suitable for various domains and tasks, ensuring that the benefits from mitigating label noise can be reaped regardless of the model choice.\n",
    "\n",
    "#### 4. Data-Centric Approach\n",
    "\n",
    "- **Focus on Data Quality:**  \n",
    " Confident Learning emphasizes the improvement of data quality by directly addressing mislabeled instances. Correcting data quality at the source leads to models that generalize better and exhibit improved performance.\n",
    "\n",
    "- **Implementation:**  \n",
    " The strategy involves examining the dataset for inconsistencies and refining the labeling process. It can also suggest adjustments in the data collection pipeline to minimize future errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Detailed Example: Observed vs. True Labels\n",
    "\n",
    "#### Confusion Matrix Example\n",
    "\n",
    "Consider the following confusion matrix that represents counts of observed labels ($\\tilde{y}$) versus true basic labels ($y^*$):\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "| $C_{\\tilde{y}, y^*}$            | $y^*=\\text{bus}$ | $y^*=\\text{car}$ | $y^*=\\text{bike}$ |\n",
    "|--------------------------------|----------------|----------------|----------------|\n",
    " $\\tilde{y}=\\text{bus}$           |90                 |35                 |25                  |\n",
    "| $\\tilde{y}=\\text{car}$           |50                 |70                 |5                   |\n",
    "| $\\tilde{y}=\\text{bike}$          |30                 |15                 |75                  |\n",
    "\n",
    "</div>\n",
    "\n",
    "When these counts are normalized, we obtain the transition matrix:\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "| $\\hat{Q}(\\tilde{y} \\mid y^*)$    | $y^*=\\text{bus}$ | $y^*=\\text{car}$ | $y^*=\\text{bike}$ |\n",
    "|--------------------------------|----------------|----------------|----------------|\n",
    " $\\tilde{y}=\\text{bus}$           |0.22               |0.09               |0.06                |\n",
    "| $\\tilde{y}=\\text{car}$           |0.13               |0.18               |0.01                |\n",
    "| $\\tilde{y}=\\text{bike}$          |0.08               |0.04               |0.19                |\n",
    "\n",
    "\n",
    "</div>\n",
    "\n",
    "\n",
    "#### Important Points from the Matrix\n",
    "\n",
    "- **Diagonal Elements:**  \n",
    " Represent probabilities where the observed label equals the true label. For example, \n",
    " $$\n",
    "  \\hat{Q}(\\tilde{y}=\\text{bus} \\mid y^*=\\text{bus}) =0.22\n",
    "  $$\n",
    "  indicates the chance that a true \"bus\" remains correctly labeled.\n",
    "\n",
    "- **Off-Diagonal Elements:**  \n",
    " Represent mislabeling probabilities. For instance, \n",
    " $$\n",
    "  \\hat{Q}(\\tilde{y}=\\text{car} \\mid y^*=\\text{bus}) =0.13\n",
    "  $$\n",
    "  denotes a 13% chance that a \"bus\" is misobserved as \"car\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Applications of the Transition Matrix\n",
    "\n",
    "- **Error Detection:**  \n",
    " Analyzing off-diagonal entries clarifies which classes frequently get confused, guiding further review of the data labeling process.\n",
    "\n",
    "- **Model Training with Noisy Data:**  \n",
    " The transition matrix informs algorithms that adjust for noisy labels. This knowledge can be integrated into the objective function or used to weight training examples differentially.\n",
    "\n",
    "- **Data Quality Insight:**  \n",
    " Examining the probabilities helps to uncover fundamental issues in the dataset, such as overlapping classes or ambiguous definitions, prompting revisions to the labeling scheme.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Estimating the Joint Distribution $P(\\tilde{y}, y^*)$\n",
    "\n",
    "#### Components Needed\n",
    "\n",
    "- **Noisy labels ($\\tilde{y}$)**:  \n",
    " These are the observed labels found in the dataset.\n",
    "\n",
    "- **Predicted Probabilities ($\\hat{p}(\\tilde{y}; x, \\theta)$)**:  \n",
    " These are the probabilities provided by the model for each class. Here, $x$ denotes the input data and $\\theta$ represents the model parameters.\n",
    "\n",
    "#### Obtaining Reliable Predictions\n",
    "\n",
    "- **Out-of-Sample Predictions:**  \n",
    " It is important to obtain predictions from data that the model did not see during training. This can be done by applying cross-validation. The goal is to avoid overfitting the estimates of $\\hat{p}(\\tilde{y}; x, \\theta)\\ $ and ensure that the predictions are unbiased.\n",
    "\n",
    "- **Statistical Estimation:**  \n",
    " Using out-of-sample predictions, one can derive the joint distribution $P(\\tilde{y}, y^*)$ and subsequently compute marginal and conditional probabilities. For instance, the marginal probability of the observed label is given by:\n",
    "\n",
    "  $$\n",
    "  P(\\tilde{y}) = \\sum_{y^*} P(\\tilde{y}, y^*)\n",
    "  $$\n",
    "\n",
    "  while the conditional probability, which is equivalent to the transition probability, is obtained by:\n",
    "\n",
    "  $$\n",
    "  P(\\tilde{y} \\mid y^*) = \\frac{P(\\tilde{y}, y^*)}{P(y^*)}\n",
    "  $$\n",
    "\n",
    "> **Additional Insight:**  \n",
    "> Accurately estimating $P(\\tilde{y}, y^*)$ aids in making informed adjustments during model training, especially when different classes are affected by varying levels of label noise.\n",
    "\n",
    "\n",
    "For more detailed reading, refer to the [paper](https://arxiv.org/pdf191.00068)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.39681761e-01, 7.60318239e-01],\n",
       "       [9.99920616e-01, 7.93838838e-05],\n",
       "       [9.99949935e-01, 5.00646014e-05],\n",
       "       [1.15700446e-02, 9.88429955e-01],\n",
       "       [8.68763949e-01, 1.31236051e-01]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Initialize stratified k-fold cross-validation with 20 splits\n",
    "# StratifiedKFold ensures that each fold has the same proportion of classes as the original dataset\n",
    "cross_validation = StratifiedKFold(n_splits=20, shuffle=True, random_state=271828)\n",
    "\n",
    "# Initialize a Logistic Regression model with balanced class weights\n",
    "# 'random_state' ensures reproducibility, 'n_jobs=-1' uses all available processors\n",
    "model_lr = LogisticRegression(random_state=271828, n_jobs=-1, class_weight=\"balanced\")\n",
    "\n",
    "# Perform cross-validated predictions on the training data\n",
    "# 'method=\"predict_proba\"' returns the predicted probabilities for each class\n",
    "# 'n_jobs=2' uses 2 processors for parallel computation\n",
    "y_train_preds = cross_val_predict(\n",
    "    estimator=model_lr,\n",
    "    X=X_train,\n",
    "    y=y_train,\n",
    "    cv=cross_validation,\n",
    "    method=\"predict_proba\",\n",
    "    n_jobs=2,\n",
    ")\n",
    "\n",
    "# Display the first 5 rows of the predicted probabilities\n",
    "y_train_preds[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Computing Thresholded Confidences\n",
    "\n",
    "**Fundamental Idea:**  To gauge the machine's innate confidence level for each task or class $j$, we establish class-specific thresholds. These thresholds serve as a practical measure for the machine's average self-confidence in its predictions related to each class.\n",
    "\n",
    "The threshold $t_j$ for class $j$ is calculated using the following formula:\n",
    "\n",
    "$$ t_j = \\frac{1}{|X_{\\tilde{y}=j}|} \\sum_{x \\in X_{\\tilde{y}=j}} \\hat{p}(\\tilde{y} = j; x, \\theta) $$\n",
    "\n",
    "Let's break down each component of this formula to understand its meaning and purpose:\n",
    "\n",
    "- **$t_j$:** This represents the **confidence threshold** specifically for class $j$.  It's a scalar value that quantifies the average confidence of the model when it *deals with data points that have a noisy label* of class $j$. Think of it as a baseline confidence level associated with noisy labels of class $j$.\n",
    "\n",
    "- **$|X_{\\tilde{y}=j}|$:** This denotes the **count of data points** in the dataset $X$ that are given the **noisy label** $j$.  Here, $X$ represents the entire dataset under consideration, and $\\tilde{y}$ signifies the **noisy observed labels**. The notation $| \\cdot |$ represents the cardinality or size of the set. So, we are counting how many data points in the *noisy labeled* dataset are labeled as class $j$.\n",
    "\n",
    "- **$X_{\\tilde{y}=j}$:**  This is the **set of data points** from the dataset $X$ that are **observed to have the noisy label** $j$.  In other words, it's the collection of all data instances $x$ that are given the noisy label $\\tilde{y} = j$ in the dataset.\n",
    "\n",
    "- **$\\sum_{x \\in X_{\\tilde{y}=j}}$:** This is a **summation** performed over all data points $x$ within the set $X_{\\tilde{y}=j}$.  We are iterating through each data point that has the noisy label $j$.\n",
    "\n",
    "- **$\\hat{p}(\\tilde{y} = j; x, \\theta)$:** This represents the **predicted probability** that a data point $x$ *should have the noisy label* $j$, as estimated by the model. This probability is conditional on the input data $x$ and the model's parameters $\\theta$.  The model is trained on noisy labels $\\tilde{y}$, and it learns to predict the probability distribution over these noisy labels.  So, $\\hat{p}(\\tilde{y} = j; x, \\theta)$ is the model's assessment of how likely the noisy label should be $j$ for a given input $x$.\n",
    "\n",
    "\n",
    "The formula essentially computes the average of the predicted probabilities associated with the noisy label $j$, specifically for those data points that are *given* the noisy label $j$ in the dataset. Let's unpack the process:\n",
    "\n",
    "1. **Identify Data Points with Noisy Label $j$:** First, we gather all the data points that are *initially labeled as class $j$ in our noisy dataset*. This gives us the set $X_{\\tilde{y}=j}$.\n",
    "\n",
    "2. **Extract Confidence Scores for Noisy Label $j$:** For each data point in $X_{\\tilde{y}=j}$, we look at the predicted probability $\\hat{p}(\\tilde{y} = j; x, \\theta)$.  This value represents the model's \"confidence\" that the noisy label for this instance *should be* $j$, based on its training on the noisy dataset.\n",
    "\n",
    "3. **Sum the Confidence Scores:** We sum up all these individual confidence scores for all data points in $X_{\\tilde{y}=j}$. This provides a total confidence mass associated with noisy label $j$.\n",
    "\n",
    "4. **Average the Confidence Scores:** Finally, we divide this sum by the total number of data points in $X_{\\tilde{y}=j}$ (which is $|X_{\\tilde{y}=j}|$). This averaging process gives us $t_j$, the average confidence score associated with the noisy label $j$.\n",
    "\n",
    "\n",
    "##### Why Class-Specific Thresholds?\n",
    "\n",
    "We need to calculate thresholds *per class* rather than using a single global threshold. This is because machine learning models trained on noisy data might exhibit varying levels of average confidence across different noisy label classes.  The level of noise might also vary across classes.\n",
    "\n",
    "For example, consider image classification with noisy labels:\n",
    "\n",
    "- **Noisy Label \"Car\":** For data points *labeled as* \"car\" (even if some are actually not cars), the model might still learn some features of cars and assign relatively high probabilities to the noisy label \"car\" for instances in $X_{\\tilde{y}=\\text{car}}$. The average confidence $t_{\\text{car}}$ for the noisy label \"car\" will likely reflect the model's average confidence when dealing with data points *labeled* as \"car\".\n",
    "\n",
    "- **Noisy Label \"Bicycle\":** Similarly, for data points *labeled as* \"bicycle\", the average confidence $t_{\\text{bicycle}}$ for the noisy label \"bicycle\" will reflect the model's average confidence when dealing with data points *labeled* as \"bicycle\". This might be different from $t_{\\text{car}}$ if the noise characteristics are different for \"car\" and \"bicycle\" noisy labels.\n",
    "\n",
    "With class-specific thresholds, we account for these potential differences in model behavior and noise levels across different noisy labels.  This allows us to establish a more nuanced and accurate measure of the model's self-assessment for each noisy label class.\n",
    "\n",
    "##### Threshold as a Proxy for Self-Confidence concerning Noisy Labels\n",
    "\n",
    "It is important to understand that $t_j$ is a *proxy* for the machine's self-confidence *related to the noisy label $j$*. It's derived from the model's output probabilities when trained on noisy labels, and we interpret it as reflecting its average confidence level associated with each noisy label class. A higher $t_j$ suggests that, on average, the model is more \"confident\" in its predictions *related to the noisy label $j$*.\n",
    "\n",
    "This threshold $t_j$, calculated for each noisy label class, will be used in subsequent steps to identify and potentially correct noisy labels based on the concept of confident learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold for negative class: 0.9408\n",
      "Threshold for positive class: 0.9424\n"
     ]
    }
   ],
   "source": [
    "# Calculate the threshold for the negative class based on the mean probability when the given label is negative\n",
    "t_negative = y_train_preds[y_train == 0].mean(axis=0)[0]\n",
    "\n",
    "# Calculate the threshold for the positive class based on the mean probability when the given label is positive\n",
    "t_positive = y_train_preds[y_train == 1].mean(axis=0)[1]\n",
    "\n",
    "# Print the calculated thresholds\n",
    "print(f\"Threshold for negative class: {t_negative:.4f}\")\n",
    "print(f\"Threshold for positive class: {t_positive:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Step 3: Compute the Error Sets\n",
    "\n",
    "Following the computation of class-specific thresholds, the next  step is to pinpoint data points that are likely to be confidently misclassified *with respect to the observed noisy labels*. We achieve this by defining and computing **error sets**. These sets identify instances where the model's prediction suggests a different true class than the provided *noisy* label, and this suggestion is statistically significant based on our confidence thresholds.\n",
    "\n",
    "The error set, denoted as $\\hat{X}_{\\tilde{y}=i, y^*=j}$, is formally defined as:\n",
    "\n",
    "$$\n",
    "\\hat{X}_{\\tilde{y}=i, y^*=j} = \\{ x \\in X_{\\tilde{y}=i} : \\hat{p}(\\tilde{y} = j; x, \\theta) \\geq t_j \\}\n",
    "$$\n",
    "\n",
    "Let's dissect each component of this definition to fully grasp its meaning:\n",
    "\n",
    "- **$\\hat{X}_{\\tilde{y}=i, y^*=j}$**: This notation represents the **error set** itself. It is the set of data points $x$ that meet specific criteria indicative of a likely misclassification *where the noisy label is $i$ but the model suggests the true label might be $j$*. The subscripts $\\tilde{y}=i, y^*=j$ are used to specify the conditions under which we are identifying these error sets:\n",
    "    -  $\\tilde{y}=i$ indicates that the data point $x$ is **initially given the noisy label** $i$ in the dataset.\n",
    "    -  $y^*=j$ suggests that, despite the noisy label being $i$, there is strong evidence from the model pointing towards class $j$ being the *potential true* class label.  We use $y^*$ to conceptually represent the \"true\" label, although we don't know it directly in a noisy label scenario.\n",
    "\n",
    "- **$X_{\\tilde{y}=i}$**: This is the set of data points from Step 2, which comprises all data instances $x$ that are **initially labeled with the noisy label** $i$.  We are filtering data points *within* this set to identify potential noisy labels.\n",
    "\n",
    "- **$\\{ x \\in X_{\\tilde{y}=i} : \\dots \\}$**: This is set-builder notation. It reads as \"the set of all $x$ belonging to $X_{\\tilde{y}=i}$ such that the condition following the colon is true\". In our case, the condition is:\n",
    "\n",
    "    - **$\\hat{p}(\\tilde{y} = j; x, \\theta) \\geq t_j$**: This is the central condition for identifying potentially noisy labels. It states that for a data point $x$ (which has a *noisy label* $i$), we examine the predicted probability $\\hat{p}(\\tilde{y} = j; x, \\theta)$. This probability is the model's estimation of how likely the *noisy label* should be $j$ for input $x$.  If this probability is greater than or equal to the threshold $t_j$ (computed for noisy label class $j$ in Step 2), then the condition is met.\n",
    "\n",
    "##### Confident Indication of a Different True Class (Despite Noisy Label)\n",
    "\n",
    "The condition $\\hat{p}(\\tilde{y} = j; x, \\theta) \\geq t_j$ is key to understanding how we identify potential noisy labels.\n",
    "\n",
    "Let's break it down:\n",
    "\n",
    "1.  **Starting with Noisy Label $i$:** We begin with data points that are *initially given the noisy label* $i$ in the dataset.\n",
    "\n",
    "2.  **Considering a Different Potential True Class $j$:** For each of these instances with noisy label $i$, we look at the model's predicted probability $\\hat{p}(\\tilde{y} = j; x, \\theta)$.  This represents the model's assessment of how likely the *noisy label* should be $j$ for the same input $x$. We are essentially asking: \"Even though the noisy label is $i$, how likely, according to the model trained on noisy data, is it that the *noisy label should have been* $j$?\".\n",
    "\n",
    "3.  **Threshold Comparison: Confidence Check for Noisy Label $j$**: We then compare this probability $\\hat{p}(\\tilde{y} = j; x, \\theta)$ with the threshold $t_j$. Recall that $t_j$ is the average confidence the model exhibits when dealing with data points that have the noisy label $j$.\n",
    "\n",
    "4.  **Confident Suggestion of True Class $j$ (When Noisy Label is $i$)**: If $\\hat{p}(\\tilde{y} = j; x, \\theta) \\geq t_j$, it means that for a data point with *noisy label* $i$, the model assigns a probability to the *noisy label* $j$ that is *at least as high as* its average confidence associated with noisy label $j$.  This suggests that even though the provided noisy label is $i$, the model is indicating with significant confidence that the *true* label might actually correspond to class $j$.\n",
    "\n",
    "##### Purpose of Error Sets\n",
    "\n",
    "The primary purpose of computing these error sets is to:\n",
    "\n",
    "- **Identify Likely Noisy Labels:** By finding data points that are *given* a noisy label ($i$) but for which the model indicates a high probability related to a *different* noisy label class ($j$), we pinpoint instances that are strong candidates for having incorrect noisy labels. These are not definitively mislabeled points, but rather data points that warrant closer inspection as potential sources of label noise. We suspect the provided noisy label $i$ might be incorrect and the true label is more likely to be associated with class $j$.\n",
    "\n",
    "- **Estimate Noise Transitions:**  Error sets are needed for estimating the label noise transition matrix. Each error set $\\hat{X}_{\\tilde{y}=i, y^*=j}$ gives us an empirical count of how often instances *labeled as* class $i$ (noisy label) might actually have a true label corresponding to class $j$. By analyzing the sizes and compositions of these error sets for all pairs of classes $(i, j)$, we can begin to approximate the probabilities of transitioning from a true label to a noisy label (or more precisely, the relationship between noisy labels and true labels).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index([4, 17, 19, 59, 86], dtype='int64'),\n",
       " Index([0, 9, 20, 24, 26], dtype='int64'),\n",
       " [1, 2, 3, 5, 6, 7, 8, 10, 11, 12])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create boolean masks for negative and positive examples in the training data\n",
    "negative_mask = y_train == 0  # Mask for negative examples (class 0)\n",
    "positive_mask = y_train == 1  # Mask for positive examples (class 1)\n",
    "\n",
    "# Get the indices of negative and positive examples using the masks\n",
    "negative_indices = y_train[negative_mask].index  # Indices of negative examples\n",
    "positive_indices = y_train[positive_mask].index  # Indices of positive examples\n",
    "\n",
    "# Create boolean masks for negative and positive examples below their respective thresholds\n",
    "# y_train_preds[negative_indices][:, 0] extracts the predicted probabilities for class 0 for negative examples\n",
    "negative_below_threshold_mask = (\n",
    "    y_train_preds[negative_indices][:, 0] < t_negative\n",
    ")  # Mask for negative examples below threshold\n",
    "# y_train_preds[positive_indices][:, 1] extracts the predicted probabilities for class 1 for positive examples\n",
    "positive_below_threshold_mask = (\n",
    "    y_train_preds[positive_indices][:, 1] < t_positive\n",
    ")  # Mask for positive examples below threshold\n",
    "\n",
    "# Get the indices of negative and positive examples that are below the threshold\n",
    "negative_below_threshold_indices = negative_indices[\n",
    "    negative_below_threshold_mask\n",
    "]  # Indices of negative examples below threshold\n",
    "positive_below_threshold_indices = positive_indices[\n",
    "    positive_below_threshold_mask\n",
    "]  # Indices of positive examples below threshold\n",
    "\n",
    "# Get the indices of examples that are above the threshold for both classes\n",
    "# This includes all indices that are not in negative_below_threshold_indices or positive_below_threshold_indices\n",
    "above_threshold_indices = [\n",
    "    i\n",
    "    for i in range(len(y_train))\n",
    "    if i not in negative_below_threshold_indices\n",
    "    and i not in positive_below_threshold_indices\n",
    "]\n",
    "\n",
    "# Display the first 5 indices of negative examples below the threshold, positive examples below the threshold, and examples above the threshold\n",
    "negative_below_threshold_indices[:5], positive_below_threshold_indices[\n",
    "    :5\n",
    "], above_threshold_indices[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the indices of negative examples below the threshold for class 0 but above the threshold for class 1\n",
    "# This includes examples that are misclassified as negative examples\n",
    "negative_misclassified_indices = [\n",
    "    i for i in negative_below_threshold_indices if y_train_preds[i][1] > t_positive\n",
    "]\n",
    "\n",
    "# Create the indices of positive examples below the threshold for class 1 but above the threshold for class 0\n",
    "# This includes examples that are misclassified as positive examples\n",
    "positive_misclassified_indices = [\n",
    "    i for i in positive_below_threshold_indices if y_train_preds[i][0] > t_negative\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[21038,    22],\n",
       "       [  173, 61555]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cleanlab\n",
    "\n",
    "# Define mappings between integer labels and their string representations\n",
    "int_to_str = {0: \"Negative\", 1: \"Positive\"}\n",
    "str_to_int = {\n",
    "    v: k for k, v in int_to_str.items()\n",
    "}  # Reverse mapping from string to integer\n",
    "\n",
    "num_classes = len(int_to_str)\n",
    "\n",
    "# Calculate the threshold for each class based on the mean predicted probabilities\n",
    "# This threshold will be used to determine the predicted class\n",
    "thresholds = np.zeros(num_classes)\n",
    "for k in range(num_classes):\n",
    "    thresholds[k] = np.mean(y_train_preds[:, k][y_train == k])  # P(label^=k|label=k)\n",
    "\n",
    "\n",
    "# Initialize a counts matrix to keep track of true vs predicted class counts\n",
    "confident_joint_matrix = np.zeros((num_classes, num_classes))\n",
    "\n",
    "# Iterate over each example to populate the confident joint matrix\n",
    "for i, prob_row in enumerate(y_train_preds):\n",
    "    observed_label = y_train[i]\n",
    "\n",
    "    # Determine which classes the example is confidently labeled as\n",
    "    confident_bins = prob_row >= thresholds - 1e-6\n",
    "    num_confident_bins = sum(confident_bins)\n",
    "\n",
    "    # If exactly one confident class, increment the count for that class\n",
    "    if num_confident_bins == 1:\n",
    "        confident_joint_matrix[observed_label][np.argmax(confident_bins)] += 1\n",
    "\n",
    "    # If more than one confident class, increment the count for the class with the highest probability\n",
    "    elif num_confident_bins > 1:\n",
    "        confident_joint_matrix[observed_label][np.argmax(prob_row)] += 1\n",
    "\n",
    "# Print the confident_joint_matrix without using scientific notation\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "confident_joint_matrix.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82788, 101461)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We you can see, the number of confident predictions is much lower than the total number of examples. This is expected, as the model is not confident about all predictions, several instances are not confidently classified as either positive or negative.\n",
    "\n",
    "int(confident_joint_matrix.sum()), len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[27575,    29],\n",
       "       [  207, 73650]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize the confident joint matrix using Cleanlab's calibration function\n",
    "# This function forces the confident joint to have the true noisy prior p(labels) (summed over columns for each row), making it a valid counts estimate of the actual joint of noisy and true labels\n",
    "\n",
    "confident_joint_matrix = cleanlab.count.calibrate_confident_joint(\n",
    "    confident_joint_matrix, y_train\n",
    ")\n",
    "\n",
    "# Display the normalized confident joint matrix\n",
    "confident_joint_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101461"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(\n",
    "    confident_joint_matrix.sum()\n",
    ")  # Now the sum of the confident joint matrix is equal to the number of examples in the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold for class \u001b[31mNegative\u001b[0m: 0.9408\n",
      "Threshold for class \u001b[32mPositive\u001b[0m: 0.9424\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "Index: 1505\n",
      "Text: \"otima - esta querendo enganar a quem e golpe golpe golpe golpe golpe\"\n",
      "Given Label: \u001b[31mNegative\u001b[0m\n",
      "Confidence score for class Negative: 0.0239 (Threshold not met)\n",
      "Confidence score for class Positive: 0.9761 (Threshold met)\n",
      "Predicted class: \u001b[32mPositive\u001b[0m\n",
      "\n",
      "--------------------------------------------------\n",
      "Index: 16382\n",
      "Text: \"potente e leve - o tamanho e grande, porem bastante leve, tem processamento muito rapido, muito espaco na memoria interna, rom de 64 gb, sobra uns 52gb com o sistema instalado, alem dos 4 gb de ram mais que da, sobra, o corpo do aparelho passa uma certa impressao de fragilidade do material e a bateria poderia ser de pelo menos uns 4.000 ma, mas o carregamento rapido dela faz a sua compensacao.\"\n",
      "Given Label: \u001b[31mNegative\u001b[0m\n",
      "Confidence score for class Negative: 0.0489 (Threshold not met)\n",
      "Confidence score for class Positive: 0.9511 (Threshold met)\n",
      "Predicted class: \u001b[32mPositive\u001b[0m\n",
      "\n",
      "--------------------------------------------------\n",
      "Index: 16898\n",
      "Text: \"boa tv so tem um problema! - tv muito boa facil de manusear, o sistema web os e muito bom rapido, so tem um problema, os leds estao se soltando com mais de um ano de uso, ficando uma mancha branca na tela tem varios leds da minha ja cairam 3, pessimo!\"\n",
      "Given Label: \u001b[31mNegative\u001b[0m\n",
      "Confidence score for class Negative: 0.0210 (Threshold not met)\n",
      "Confidence score for class Positive: 0.9790 (Threshold met)\n",
      "Predicted class: \u001b[32mPositive\u001b[0m\n",
      "\n",
      "--------------------------------------------------\n",
      "Index: 19220\n",
      "Text: \"entrega enganosa - na proxima vez coloquem 60 dias para entrega tudo que compro pela internet e chega antes do tempo previsto avaliarei como excelente obrigado.\"\n",
      "Given Label: \u001b[31mNegative\u001b[0m\n",
      "Confidence score for class Negative: 0.0467 (Threshold not met)\n",
      "Confidence score for class Positive: 0.9533 (Threshold met)\n",
      "Predicted class: \u001b[32mPositive\u001b[0m\n",
      "\n",
      "--------------------------------------------------\n",
      "Index: 24370\n",
      "Text: \"produto entregue bem antes do tempo, so uma dica, proteger um pouco mais a embalagem, , chegou amassado e e um medicamento\"\n",
      "Given Label: \u001b[31mNegative\u001b[0m\n",
      "Confidence score for class Negative: 0.0282 (Threshold not met)\n",
      "Confidence score for class Positive: 0.9718 (Threshold met)\n",
      "Predicted class: \u001b[32mPositive\u001b[0m\n",
      "\n",
      "--------------------------------------------------\n",
      "Index: 413\n",
      "Text: \"ola, infelizmente o produto nao veio conforme o anuncio. se tratava de um capacho, mas o que chegou e praticamente uma borracha, nao tem utilidade de um tapete. gostaria de realizar a devolucao\"\n",
      "Given Label: \u001b[32mPositive\u001b[0m\n",
      "Confidence score for class Negative: 0.9754 (Threshold met)\n",
      "Confidence score for class Positive: 0.0246 (Threshold not met)\n",
      "Predicted class: \u001b[31mNegative\u001b[0m\n",
      "\n",
      "--------------------------------------------------\n",
      "Index: 1270\n",
      "Text: \"desatenciosos com problema de produto \"empacado\" no correio por 10 dias. quero meu produto\"\n",
      "Given Label: \u001b[32mPositive\u001b[0m\n",
      "Confidence score for class Negative: 0.9532 (Threshold met)\n",
      "Confidence score for class Positive: 0.0468 (Threshold not met)\n",
      "Predicted class: \u001b[31mNegative\u001b[0m\n",
      "\n",
      "--------------------------------------------------\n",
      "Index: 1281\n",
      "Text: \"produto errado - comprei o kit total e o que me entregaram foi uma capa maior do que a qual eu havia solitado, meu tablet e o t560 e quando coloco a capa fica sobrando uns 3cm. (nao serve no tablet). a qualidade da capa e boa nao veio no meu pedido a pelicula de vidro. a caneta veio corretamente e tem a qualidade esperada.\"\n",
      "Given Label: \u001b[32mPositive\u001b[0m\n",
      "Confidence score for class Negative: 0.9612 (Threshold met)\n",
      "Confidence score for class Positive: 0.0388 (Threshold not met)\n",
      "Predicted class: \u001b[31mNegative\u001b[0m\n",
      "\n",
      "--------------------------------------------------\n",
      "Index: 1311\n",
      "Text: \"veio faltando acdessorio - produto otimo! recomendo o produto sim, mas nao a loja! nao mandaram manual nem a flanela que acompanha a embalagem, no lugara mandaram um spinner para me agradar algo que nao tenho interesse.\"\n",
      "Given Label: \u001b[32mPositive\u001b[0m\n",
      "Confidence score for class Negative: 0.9427 (Threshold met)\n",
      "Confidence score for class Positive: 0.0573 (Threshold not met)\n",
      "Predicted class: \u001b[31mNegative\u001b[0m\n",
      "\n",
      "--------------------------------------------------\n",
      "Index: 2475\n",
      "Text: \"producto no recomiendo - producto pouco recomendable. fraco de mais. -\"\n",
      "Given Label: \u001b[32mPositive\u001b[0m\n",
      "Confidence score for class Negative: 0.9696 (Threshold met)\n",
      "Confidence score for class Positive: 0.0304 (Threshold not met)\n",
      "Predicted class: \u001b[31mNegative\u001b[0m\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Define ANSI color codes\n",
    "RED = \"\\033[31m\"\n",
    "GREEN = \"\\033[32m\"\n",
    "RESET = \"\\033[0m\"\n",
    "\n",
    "# Combine indices of examples below the threshold and above the threshold\n",
    "# Select the first 5 examples from each category for demonstration\n",
    "example_indices = list(negative_misclassified_indices[:5]) + list(\n",
    "    positive_misclassified_indices[:5]\n",
    ")\n",
    "\n",
    "# Print the threshold for each class\n",
    "for class_idx, class_name in int_to_str.items():\n",
    "    if class_name == \"Negative\":\n",
    "        colored_name = f\"{RED}{class_name}{RESET}\"\n",
    "    elif class_name == \"Positive\":\n",
    "        colored_name = f\"{GREEN}{class_name}{RESET}\"\n",
    "    else:\n",
    "        colored_name = class_name\n",
    "    print(f\"Threshold for class {colored_name}: {thresholds[class_idx]:.4f}\")\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Iterate over the selected example indices\n",
    "for idx in example_indices:\n",
    "    # Get the true label and predicted confidence scores for the current example\n",
    "    observed_label = y_train[idx]\n",
    "    confidence_scores = y_train_preds[idx]\n",
    "\n",
    "    # Print the index and text of the current example\n",
    "    print(f\"Index: {idx}\")\n",
    "    print(f'Text: \"{df_train.loc[idx, \"text\"]}\"')\n",
    "\n",
    "    if int_to_str[observed_label] == \"Negative\":\n",
    "        label = f\"{RED}{int_to_str[observed_label]}{RESET}\"\n",
    "    elif int_to_str[observed_label] == \"Positive\":\n",
    "        label = f\"{GREEN}{int_to_str[observed_label]}{RESET}\"\n",
    "    else:\n",
    "        label = int_to_str[observed_label]\n",
    "\n",
    "    print(f\"Given Label: {label}\")\n",
    "\n",
    "    predicted_class = None\n",
    "\n",
    "    # Print confidence scores for each class and determine the predicted class\n",
    "    for i, confidence_score in enumerate(confidence_scores):\n",
    "        class_name = int_to_str[i]\n",
    "        if class_name == \"Negative\":\n",
    "            colored_class = f\"{RED}{class_name}{RESET}\"\n",
    "        elif class_name == \"Positive\":\n",
    "            colored_class = f\"{GREEN}{class_name}{RESET}\"\n",
    "        else:\n",
    "            colored_class = class_name\n",
    "\n",
    "        output_str = f\"Confidence score for class {class_name}: {confidence_score:.4f}\"\n",
    "        if confidence_score >= thresholds[i]:\n",
    "            predicted_class = i\n",
    "            output_str += \" (Threshold met)\"\n",
    "        else:\n",
    "            output_str += \" (Threshold not met)\"\n",
    "        print(output_str)\n",
    "\n",
    "    # Print the predicted class\n",
    "    if predicted_class is not None:\n",
    "        pred_class_name = int_to_str[predicted_class]\n",
    "        if pred_class_name == \"Negative\":\n",
    "            pred_class = f\"{RED}{pred_class_name}{RESET}\"\n",
    "        elif pred_class_name == \"Positive\":\n",
    "            pred_class = f\"{GREEN}{pred_class_name}{RESET}\"\n",
    "        else:\n",
    "            pred_class = pred_class_name\n",
    "        print(f\"Predicted class: {pred_class}\\n\")\n",
    "    else:\n",
    "        print(\"Predicted class: None\\n\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "C_{ŷ,y*}",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "negative",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "positive",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "17e47214-718b-4396-afff-8a876e450500",
       "rows": [
        [
         "negative",
         "27575",
         "29"
        ],
        [
         "positive",
         "207",
         "73650"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_{ŷ,y*}</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>27575</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>207</td>\n",
       "      <td>73650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          negative  positive\n",
       "C_{ŷ,y*}                    \n",
       "negative     27575        29\n",
       "positive       207     73650"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def counts_matrix_to_dataframe(confusion_matrix, labels, name=\"C_{ŷ,y*}\"):\n",
    "    # Convert the confusion matrix (a numpy array) into a pandas DataFrame\n",
    "    df = pd.DataFrame(confusion_matrix, index=labels, columns=labels)\n",
    "    # Set the name of the index to the provided name (default is 'C_{ŷ,y*}')\n",
    "    df.index.name = name\n",
    "    return df\n",
    "\n",
    "\n",
    "# Define the labels for the confusion matrix, corresponding to the classes\n",
    "labels = [\"negative\", \"positive\"]\n",
    "\n",
    "# Convert the counts matrix (confusion matrix) to a pandas DataFrame for better readability\n",
    "df_counts_matrix = counts_matrix_to_dataframe(confident_joint_matrix, labels)\n",
    "\n",
    "# Display the DataFrame to visualize the confusion matrix\n",
    "df_counts_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "Q̂_{ŷ,y*}",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "negative",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "positive",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "0fb4848e-8520-43a9-8063-125464c6aa59",
       "rows": [
        [
         "negative",
         "0.27177930436325287",
         "0.00028582410975645816"
        ],
        [
         "positive",
         "0.0020401927834340287",
         "0.7258946787435566"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q̂_{ŷ,y*}</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>0.271779</td>\n",
       "      <td>0.000286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>0.002040</td>\n",
       "      <td>0.725895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           negative  positive\n",
       "Q̂_{ŷ,y*}                    \n",
       "negative   0.271779  0.000286\n",
       "positive   0.002040  0.725895"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts_matrix_to_dataframe(\n",
    "    confident_joint_matrix / confident_joint_matrix.sum(), labels, name=\"Q̂_{ŷ,y*}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Pervasiveness and Impact of Label Noise in Real-World Datasets\n",
    "\n",
    "Label noise refers to errors or inaccuracies the assigned labels within a dataset. Research by [Northcutt et al., 2021](http://arxiv.org/abs/2103.14749) highlights that label noise is common in both training and test sets, and it can significantly affect the performance of machine learning models. A method known as **Confident Learning** was used in the study to estimate the amount of mislabeled data and to assess its impact.\n",
    "\n",
    "### Prevalence of Label Noise in Popular Datasets\n",
    "\n",
    "The study examined several widely used datasets and found a range of noise levels. The table below summarizes key findings:\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "| Dataset        | CL Guessed | MTurk Checked | Validated Errors | Estimated Errors | % Error |\n",
    "|----------------|------------|----------------|----------------|----------------|----------|\n",
    " MNIST          |100        |100 (100%)     |15               | —                |0.15%    |\n",
    "| CIFAR-10       |275        |275 (100%)     |54               | —                |0.54%    |\n",
    "| CIFAR-100      |2,235      |2,235 (100%)   |585              | —                |5.85%    |\n",
    "| Caltech-256    |4,643      |400 (8.6%)     |65               |754              |2.46%    |\n",
    "| ImageNet\\*     |5,440      |5,440 (100%)   |2,916            | —                |5.83%    |\n",
    "| QuickDraw      |6,825,383  |2,500 (0.04%)  |1,870            |5,105,386        |10.12%   |\n",
    "| 20news         |93         |93 (100%)      |82               | —                |1.11%    |\n",
    "| IMDB           |1,310      |1,310 (100%)   |725              | —                |2.90%    |\n",
    "| Amazon         |533,249    |1,000 (0.2%)   |732              |390,338          |3.90%    |\n",
    "| AudioSet       |307        |307 (100%)     |275              | —                |1.35%    |\n",
    "\n",
    "</div>\n",
    "\n",
    "*Notes:*\n",
    "- **CL Guessed:** Number of samples suspected to be mislabeled by the Confident Learning method.\n",
    "- **MTurk Checked:** Number of samples verified by human annotators using Amazon Mechanical Turk.\n",
    "\n",
    "**Key Points:**\n",
    "\n",
    "- Even datasets viewed as highly reliable, such as MNIST, contain mislabeled samples.\n",
    "- The percentage of label noise varies sharply across different datasets, ranging from0.15% to over10%.\n",
    "- In larger datasets, the absolute number of label errors can be very high even if the percentage appears moderate.\n",
    "\n",
    "\n",
    "### Impact on Model Performance\n",
    "\n",
    "Label noise can significantly influence a model’s behavior:\n",
    "\n",
    "- **Learning Incorrect Associations:** When incorrect labels are present, models may develop erroneous relationships between features and labels.\n",
    "- **Reduced Prediction Accuracy:** The presence of mislabeled examples can lower accuracy on both the training set and unseen data.\n",
    "- **Overfitting on Noise:** Models may start fitting the noise instead of learning meaningful patterns, which is particularly harmful when the training data is noisy.\n",
    "\n",
    "*Example:* If images of cats are mistakenly labeled as dogs, the model might learn features for dogs that do not represent the true characteristics of the class, leading to poor classification performance when encountering new images.\n",
    "\n",
    "### Repercussions of Label Noise in Test Sets\n",
    "\n",
    "Label noise affects test data and has several drawbacks:\n",
    "\n",
    "- **Skewed Performance Metrics:** Evaluation metrics like accuracy or F1 score become less reliable when the test set contains labeling errors.\n",
    "- **Faulty Model Comparisons:** Using noisy test data for model comparisons might result in favoring models that perform well on mislabeled samples rather than those that capture true basic patterns.\n",
    "- **Misleading Assessment:** Relying on test results with significant noise might lead to an inflated sense of the model’s capabilities.\n",
    "\n",
    "*Analogy:* Consider an exam where some of the answer choices are incorrectly marked. A student’s score measured against such an answer key would not accurately reflect their true mastery of the subject.\n",
    "\n",
    "### Common Misconceptions\n",
    "\n",
    "- **Significance of Minor Noise:** Even a small percentage of mislabeled data can have a large impact, especially in critical applications such as medical diagnosis.\n",
    "- **Model Robustness:** While some algorithms may exhibit strength to random noise, they can still be misled if the noise is non-random or systematic. Real-world label noise often follows non-random patterns.\n",
    "- **Cost of Data Cleaning:** Investing resources in improving data quality through cleaning and validation typically reduces overall effort later in the modeling process by decreasing the need for compensatory mechanisms in model training.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Takeaways\n",
    "\n",
    "- High-quality, accurately labeled data is essential for building effective machine learning models. Investing in techniques like AED and retagging can dramatically improve model reliability.\n",
    "\n",
    "- Recognizing that label noise can be uniform, systematic, or instance-dependent encourages the use of tailored noise mitigation strategies. A nuanced approach to noise allows for better design of cleaning and training pipelines.\n",
    "\n",
    "- Incorporating measures of model confidence and calibration into noise detection provides a quantitative basis for flagging potential errors. This helps automate the data refinement process and informs decisions about manual review.\n",
    "\n",
    "- Rather than solely relying on more complex models to overcome noise, improving the training data through methods such as retagging and confident learning can lead to better model performance and more informative evaluation metrics.\n",
    "\n",
    "- The process of identifying, correcting, and re-evaluating noisy labels should be viewed as iterative. Continually refining the dataset helps ensure that both training and test data accurately reflect the true basic patterns.\n",
    "\n",
    "- Even highly regarded datasets (e.g., MNIST, ImageNet) can suffer from label noise, which means that reliable noise-handling methods are vital for realistic, generalizable models. Correcting these errors not only boosts performance but also leads to more trustworthy model evaluations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions\n",
    "\n",
    "1. What is Annotation Error Detection (AED) and why is it important in improving dataset quality?\n",
    "\n",
    "2. What are the three main types of label noise discussed in the notebook, and how do they differ?\n",
    "\n",
    "3. How is the label noise transition matrix defined, and what is its role in handling noisy labels?\n",
    "\n",
    "4. What is the retagging approach, and how does it help in refining the quality of training data?\n",
    "\n",
    "5. How does the notebook explain the use of model confidence and class-specific thresholds for flagging annotation errors?\n",
    "\n",
    "6. What are the key differences between data-centric methods and model-centric methods for handling label noise?\n",
    "\n",
    "7. How are calibration plots used in this notebook to assess the reliability of model predictions?\n",
    "\n",
    "8. What challenges does AED face in detecting annotation errors according to the notebook?\n",
    "\n",
    "9. How does the notebook mathematically define an error set using predicted probabilities and thresholds?\n",
    "\n",
    "10. What is Confident Learning, and how does the transition matrix factor into mitigating the impact of label noise?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Answers are commented inside this cell.`\n",
    "<!-- \n",
    "\n",
    "1. AED is the process of systematically identifying mislabeled or inconsistent examples in a dataset. It is crucial because it helps improve the quality of training data by detecting and correcting annotation errors, ultimately leading to more reliable and accurate machine learning models.\n",
    "\n",
    "2. The notebook discusses three types of label noise: Uniform (Symmetric) noise where each mislabel is equally likely, Systematic (Asymmetric) noise where some classes are more likely to be confused than others, and Instance-Dependent noise where the probability of mislabeling depends on specific attributes of each instance.\n",
    "\n",
    "3. The label noise transition matrix quantifies the probability of observing a noisy label given the true label. Mathematically, it is defined as p(𝑦̃ = i | y* = j) = C₍𝑦̃=i, y*=j₎ / C₍y*=j₎. This matrix is essential for methods like Confident Learning as it aids in adjusting for label noise during model training.\n",
    "\n",
    "4. Retagging is an approach that uses predictions from an out-of-sample model to verify and potentially correct the existing labels. By comparing model outputs with the given (weak) labels, instances with high discrepancies are flagged, resulting in a refined and cleaner training dataset.\n",
    "\n",
    "5. In the notebook, model confidence is quantified through predicted probabilities. Class-specific thresholds are computed as the average predicted probability for data points with a given noisy label. These thresholds help to flag instances when the model's confidence for a different label exceeds the average, indicating potential mislabeling.\n",
    "\n",
    "6. Data-centric methods focus on improving the quality of the training data itself by identifying and cleaning mislabeled examples, whereas model-centric methods modify the model’s training process—for example, by changing the loss function—to be reliable to noise.\n",
    "\n",
    "7. Calibration plots are used to compare the model’s predicted probabilities against the actual fraction of positives. By plotting mean predicted values against the actual positive fraction, one can visually assess how well the model's confidence scores are calibrated to reflect true likelihoods.\n",
    "\n",
    "8. AED faces several challenges including the lack of ground truth labels, class imbalance (since correct labels typically outnumber label errors), domain-specific complexities, and the difficulty of distinguishing true errors from ambiguous cases.\n",
    "\n",
    "9. The notebook defines an error set mathematically as 𝑋̂₍𝑦̃=i, y*=j₎ = { x ∈ X₍𝑦̃=i₎ : p̂(𝑦̃ = j; x, θ) ≥ t_j }, where t_j is the class-specific threshold. This set contains instances that are labeled as class i but for which the model's predicted probability for class j meets or exceeds the threshold, suggesting a likely mislabel.\n",
    "\n",
    "10. Confident Learning is a framework that uses estimated joint probabilities and label noise transition matrices to account for and mitigate label noise. The transition matrix, which provides the likelihood of each observed label given the true label, is used to adjust training processes and improve the reliability of the model by systematically targeting mislabeled instances. -->"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imd3011-datacentric-ai-ZY2qswVr-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
